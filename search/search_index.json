{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Welcome to RickDb RickDb is a SQL database layer for Python3. It includes connection management, Object Mapper, Query Builder, and a Repository pattern implementation. Features Object Mapper Fluent SQL Query builder with schema support High level connectors for PostgreSQL, SQLite Pluggable SQL query profiler Grid helper Migration Manager Purpose RickDb was designed to be used in schema-first scenarios: Database schema is built and managed directly with SQL DDL commands, and there is a clear segregation of concerns - the application layer has no responsibility on the structure of the database. This approach is the direct opposite of most available ORMS, but allows complete control over how the database is queried and how results are processed within the application, favoring cache-friendly multi-tier/service-oriented implementations. However, it can also be used to consume information from existing databases, implement lightweight middleware services, or to perform some quick application prototyping. Please note, RickDb does not implement any async functionality, and there are no plans to support it in the near future. TL;DR; example A simple bookstore DTO and Repository example, with a custom query via QueryBuilder: from rick_db import fieldmapper , Repository from rick_db.conn.pg import PgConnection from rick_db.sql import Select , Literal @fieldmapper ( tablename = 'publisher' , pk = 'id_publisher' ) class Publisher : id = 'id_publisher' name = 'name' @fieldmapper ( tablename = 'book' , pk = 'id_book' ) class Book : id = 'id_book' title = 'title' total_pages = 'total_pages' rating = 'rating' isbn = 'isbn' published = 'published_date' fk_publisher = 'fk_publisher' @fieldmapper ( tablename = 'author' , pk = 'id_author' ) class Author : id = 'id_author' first_name = 'first_name' middle_name = 'middle_name' last_name = 'last_name' @fieldmapper ( tablename = 'book_author' , pk = 'id_book_author' ) class BookAuthor : id = 'id_book_author' fk_book = 'fk_book' fk_author = 'fk_author' class AuthorRepository ( Repository ): def __init__ ( self , db ): super () . __init__ ( db , Author ) def calc_avg_rating ( self , id_author : int ): \"\"\" Calculate average rating for a given author :param id_author: author id :return: average rating, if any \"\"\" # generated query: # SELECT avg(rating) AS \"rating\" FROM \"book\" INNER JOIN \"book_author\" ON # \"book\".\"id_book\"=\"book_author\".\"fk_book\" WHERE (\"fk_author\" = %s) qry = Select ( self . _dialect ) . \\ from_ ( Book , { Literal ( \"avg( {} )\" . format ( Book . rating )): 'rating' }) . \\ join ( BookAuthor , BookAuthor . fk_book , Book , Book . id ) . \\ where ( BookAuthor . fk_author , '=' , id_author ) # retrieve result as list of type Book (to get the rating field) rset = self . fetch ( qry , cls = Book ) if len ( rset ) > 0 : return rset . pop ( 0 ) . rating return 0 def books ( self , id_author : int ) -> list [ Book ]: \"\"\" Retrieve all books for the given author :return: list[Book] \"\"\" qry = Select ( self . _dialect ) . \\ from_ ( Book ) . \\ join ( BookAuthor , BookAuthor . fk_book , Book , Book . id ) . \\ where ( BookAuthor . fk_author , '=' , id_author ) return self . fetch ( qry , cls = Book ) def dump_author_rating ( repo : AuthorRepository ): for author in repo . fetch_all (): # calculate average rating = repo . calc_avg_rating ( author . id ) # print book list print ( \"Books by {firstname} {lastname} :\" . format ( firstname = author . first_name , lastname = author . last_name )) for book in repo . books ( author . id ): print ( book . title ) # print average rating print ( \"Average rating for {firstname} {lastname} is {rating} \" . format ( firstname = author . first_name , lastname = author . last_name , rating = rating )) if __name__ == '__main__' : db_cfg = { 'dbname' : \"rickdb-bookstore\" , 'user' : \"rickdb_user\" , 'password' : \"rickdb_pass\" , 'host' : \"localhost\" , 'port' : 5432 , 'sslmode' : 'require' } conn = PgConnection ( ** db_cfg ) repo = AuthorRepository ( conn ) dump_author_rating ( repo )","title":"Overview"},{"location":"#welcome-to-rickdb","text":"RickDb is a SQL database layer for Python3. It includes connection management, Object Mapper, Query Builder, and a Repository pattern implementation.","title":"Welcome to RickDb"},{"location":"#features","text":"Object Mapper Fluent SQL Query builder with schema support High level connectors for PostgreSQL, SQLite Pluggable SQL query profiler Grid helper Migration Manager","title":"Features"},{"location":"#purpose","text":"RickDb was designed to be used in schema-first scenarios: Database schema is built and managed directly with SQL DDL commands, and there is a clear segregation of concerns - the application layer has no responsibility on the structure of the database. This approach is the direct opposite of most available ORMS, but allows complete control over how the database is queried and how results are processed within the application, favoring cache-friendly multi-tier/service-oriented implementations. However, it can also be used to consume information from existing databases, implement lightweight middleware services, or to perform some quick application prototyping. Please note, RickDb does not implement any async functionality, and there are no plans to support it in the near future.","title":"Purpose"},{"location":"#tldr-example","text":"A simple bookstore DTO and Repository example, with a custom query via QueryBuilder: from rick_db import fieldmapper , Repository from rick_db.conn.pg import PgConnection from rick_db.sql import Select , Literal @fieldmapper ( tablename = 'publisher' , pk = 'id_publisher' ) class Publisher : id = 'id_publisher' name = 'name' @fieldmapper ( tablename = 'book' , pk = 'id_book' ) class Book : id = 'id_book' title = 'title' total_pages = 'total_pages' rating = 'rating' isbn = 'isbn' published = 'published_date' fk_publisher = 'fk_publisher' @fieldmapper ( tablename = 'author' , pk = 'id_author' ) class Author : id = 'id_author' first_name = 'first_name' middle_name = 'middle_name' last_name = 'last_name' @fieldmapper ( tablename = 'book_author' , pk = 'id_book_author' ) class BookAuthor : id = 'id_book_author' fk_book = 'fk_book' fk_author = 'fk_author' class AuthorRepository ( Repository ): def __init__ ( self , db ): super () . __init__ ( db , Author ) def calc_avg_rating ( self , id_author : int ): \"\"\" Calculate average rating for a given author :param id_author: author id :return: average rating, if any \"\"\" # generated query: # SELECT avg(rating) AS \"rating\" FROM \"book\" INNER JOIN \"book_author\" ON # \"book\".\"id_book\"=\"book_author\".\"fk_book\" WHERE (\"fk_author\" = %s) qry = Select ( self . _dialect ) . \\ from_ ( Book , { Literal ( \"avg( {} )\" . format ( Book . rating )): 'rating' }) . \\ join ( BookAuthor , BookAuthor . fk_book , Book , Book . id ) . \\ where ( BookAuthor . fk_author , '=' , id_author ) # retrieve result as list of type Book (to get the rating field) rset = self . fetch ( qry , cls = Book ) if len ( rset ) > 0 : return rset . pop ( 0 ) . rating return 0 def books ( self , id_author : int ) -> list [ Book ]: \"\"\" Retrieve all books for the given author :return: list[Book] \"\"\" qry = Select ( self . _dialect ) . \\ from_ ( Book ) . \\ join ( BookAuthor , BookAuthor . fk_book , Book , Book . id ) . \\ where ( BookAuthor . fk_author , '=' , id_author ) return self . fetch ( qry , cls = Book ) def dump_author_rating ( repo : AuthorRepository ): for author in repo . fetch_all (): # calculate average rating = repo . calc_avg_rating ( author . id ) # print book list print ( \"Books by {firstname} {lastname} :\" . format ( firstname = author . first_name , lastname = author . last_name )) for book in repo . books ( author . id ): print ( book . title ) # print average rating print ( \"Average rating for {firstname} {lastname} is {rating} \" . format ( firstname = author . first_name , lastname = author . last_name , rating = rating )) if __name__ == '__main__' : db_cfg = { 'dbname' : \"rickdb-bookstore\" , 'user' : \"rickdb_user\" , 'password' : \"rickdb_pass\" , 'host' : \"localhost\" , 'port' : 5432 , 'sslmode' : 'require' } conn = PgConnection ( ** db_cfg ) repo = AuthorRepository ( conn ) dump_author_rating ( repo )","title":"TL;DR; example"},{"location":"building_queries/","text":"Building Queries RickDb's Query Builder can generate SELECT, INSERT, DELETE and UPDATE queries. It also provides schema support (including cross-schema operations), JOIN support and recognizes Record objects for table and schema identification. The query builder provides SQL generation using a fluent interface, suitable for most cases. Different database support is handled via dialect objects (extending from SqlDialect). The query builder itself will only generate a SQL string and a parameter value list; it is up to the developer to use the generated SQL in the appropriate database context. Select Selects are by far the most common statements, and can be easily built using a Select query builder object. Check the class documentation for more details on all available methods. Simple Select() examples: from rick_db.sql import Select , PgSqlDialect # SELECT ALL qry , _ = Select ( PgSqlDialect ()) . from_ ( 'table' ) . assemble () # output: SELECT \"table\".* FROM \"table\" print ( qry ) # SELECT from 2 tables, with specific columns qry , _ = Select ( PgSqlDialect ()) . from_ ( 'table1' , [ 'table1_field' ]) \\ . from_ ( 'table2' , [ 'table2_field' ]) \\ . assemble () # output: SELECT \"table1_field\",\"table2_field\" FROM \"table1\", \"table2\" print ( qry ) # SELECT WHERE qry , values = Select ( PgSqlDialect ()) . from_ ( 'table' ) . \\ where ( 'id' , '=' , 7 ) . \\ assemble () # output: SELECT \"table\".* FROM \"table\" WHERE (\"id\" = %s) print ( qry ) Table aliasing is also supported, as well as schema names: from rick_db.sql import Select , PgSqlDialect # SELECT w/ table alias and schema qry , _ = Select ( PgSqlDialect ()) . from_ ({ 'table' : 't1' }, schema = 'data' ) . assemble () # output: SELECT \"t1\".* FROM \"data\".\"table\" AS \"t1\" print ( qry ) And, of course, columns can be aliased too: from rick_db.sql import Select , PgSqlDialect # SELECT w/ column alias qry , _ = Select ( PgSqlDialect ()) . from_ ( 'table' , { 'id' : 'id_table' }) . assemble () # output: SELECT \"id\" AS \"id_table\" FROM \"table\" print ( qry ) # SELECT w/ column alias, and non aliased field qry , _ = Select ( PgSqlDialect ()) . from_ ( 'table' , { 'id' : 'id_table' , 'name' : None }) . assemble () # output: SELECT \"id\" AS \"id_table\",\"name\" FROM \"table\" print ( qry ) The query builder also fully supports Record classes or objects as table and schema identifiers: from rick_db import fieldmapper from rick_db.sql import Select , PgSqlDialect @fieldmapper ( tablename = 'publisher' , pk = 'id_publisher' ) class Publisher : id = 'id_publisher' name = 'name' @fieldmapper ( tablename = 'book' , pk = 'id_book' ) class Book : id = 'id_book' title = 'title' total_pages = 'total_pages' rating = 'rating' isbn = 'isbn' published = 'published_date' fk_publisher = 'fk_publisher' # simple SELECT qry , values = Select ( PgSqlDialect ()) . from_ ( Publisher ) . assemble () # output: SELECT \"publisher\".* FROM \"publisher\" print ( qry ) # SELECT... WHERE qry , values = Select ( PgSqlDialect ()) . from_ ( Book , [ Book . title , Book . rating ]) . \\ where ( Book . id , '=' , 5 ) . \\ assemble () # output: SELECT \"title\",\"rating\" FROM \"book\" WHERE (\"id_book\" = %s) print ( qry ) # SELECT... JOIN qry , values = Select ( PgSqlDialect ()) . from_ ( Book ) . \\ join ( Publisher , Publisher . id , Book , Book . fk_publisher , cols = { Publisher . name : 'publisher_name' }) . \\ assemble () # output: SELECT \"book\".*,\"publisher\".\"name\" AS \"publisher_name\" FROM \"book\" INNER JOIN \"publisher\" ON \"book\".\"fk_publisher\"=\"publisher\".\"id_publisher\" print ( qry ) The Select Object also supports both AND and OR WHERE clauses, as well as nested parenthesis: from rick_db.sql import Select , PgSqlDialect # SELECT... WHERE <cond> OR <cond> qry , values = Select ( PgSqlDialect ()) . from_ ( Book ) . \\ where ( Book . title , 'ILIKE' , '%SQL%' ) . \\ orwhere ( Book . rating , '>' , 4 ) . \\ assemble () # output: SELECT \"book\".* FROM \"book\" WHERE (\"title\" ILIKE %s) OR (\"rating\" > %s) print ( qry ) # SELECT... WHERE <cond> OR (<cond> AND <cond>) qry , values = Select ( PgSqlDialect ()) . from_ ( Book ) . \\ where ( Book . title , 'ILIKE' , '%SQL%' ) . \\ where_or () . \\ where ( Book . rating , '>' , 4 ) . \\ where ( Book . total_pages , '>' , 150 ) . \\ where_end () . \\ assemble () # output: SELECT \"book\".* FROM \"book\" WHERE (\"title\" ILIKE %s) OR ( (\"rating\" > %s) AND (\"total_pages\" > %s) ) print ( qry ) Select Object supports LEFT JOIN , RIGHT JOIN , FULL JOIN , CROSS JOIN and NATURAL JOIN : from rick_db.sql import Select , PgSqlDialect # LEFT JOIN qry , values = Select ( PgSqlDialect ()) . from_ ( 'table1' ) . \\ join ( 'table2' , 'id' , 'table1' , 'fk_table2' ) . \\ assemble () # output: SELECT \"table1\".* FROM \"table1\" INNER JOIN \"table2\" ON \"table1\".\"fk_table2\"=\"table2\".\"id\" print ( qry ) # RIGHT JOIN qry , values = Select ( PgSqlDialect ()) . from_ ( 'table1' ) . \\ join_right ( 'table2' , 'id' , 'table1' , 'fk_table2' ) . \\ assemble () # output: SELECT \"table1\".* FROM \"table1\" RIGHT JOIN \"table2\" ON \"table1\".\"fk_table2\"=\"table2\".\"id\" print ( qry ) # FULL JOIN qry , values = Select ( PgSqlDialect ()) . from_ ( 'table1' ) . \\ join_full ( 'table2' , 'id' , 'table1' , 'fk_table2' ) . \\ assemble () # output: SELECT \"table1\".* FROM \"table1\" FULL JOIN \"table2\" ON \"table1\".\"fk_table2\"=\"table2\".\"id\" print ( qry ) # CROSS JOIN qry , values = Select ( PgSqlDialect ()) . from_ ( 'table1' ) . \\ join_cross ( 'table2' ) . \\ assemble () # output: SELECT \"table1\".* FROM \"table1\" CROSS JOIN \"table2\" print ( qry ) # NATURAL JOIN qry , values = Select ( PgSqlDialect ()) . from_ ( 'table1' ) . \\ join_natural ( 'table2' ) . \\ assemble () # output: SELECT \"table1\".* FROM \"table1\" NATURAL JOIN \"table2\" print ( qry ) # mixed example qry , values = Select ( PgSqlDialect ()) . from_ ( 'table1' ) . \\ join_right ( 'table2' , 'id' , 'table1' , 'fk_table2' ) . \\ join ( 'table3' , 'id' , 'table2' , 'fk_table3' ) . \\ join ( 'table4' , 'id' , 'table3' , 'fk_table4' ) . \\ assemble () # output: SELECT \"table1\".* FROM \"table1\" RIGHT JOIN \"table2\" ON \"table1\".\"fk_table2\"=\"table2\".\"id\" INNER JOIN \"table3\" ON \"table2\".\"fk_table3\"=\"table3\".\"id\" INNER JOIN \"table4\" ON \"table3\".\"fk_table4\"=\"table4\".\"id\" print ( qry ) It is also possible to use subselects: from rick_db.sql import Select , PgSqlDialect subselect = Select ( PgSqlDialect ()) . from_ ( 'some_table' , [ 'id' ]) . where ( 'field' , '>' , 32 ) qry , _ = Select ( PgSqlDialect ()) . from_ ( 'table' ) . \\ where ( 'field' , 'IN' , subselect ) . \\ assemble () # output: SELECT \"table\".* FROM \"table\" WHERE (\"field\" IN (SELECT \"id\" FROM \"some_table\" WHERE (\"field\" > %s))) print ( qry ) Also, custom SQL expressions are supported: from rick_db.sql import Select , PgSqlDialect , Literal # using a simple expression qry , _ = Select ( PgSqlDialect ()) . expr ([ 1 ]) . assemble () # output: SELECT 1 print ( qry ) # using a simple expression qry , _ = Select ( PgSqlDialect ()) . expr ([ 1 , 2 , 3 ]) . assemble () # output: SELECT 1,2,3 print ( qry ) # using LITERAL qry , _ = Select ( PgSqlDialect ()) . from_ ( 'table' , { Literal ( 'COUNT(*)' ): 'total' }) . assemble () # output: SELECT COUNT(*) AS \"total\" FROM \"table\" print ( qry ) Insert Insert objects can be used to generate SQL INSERT statements, with optional RETURNING clause, and with full support for Record objects: from rick_db.sql import Insert , PgSqlDialect from rick_db import fieldmapper @fieldmapper ( tablename = 'publisher' , pk = 'id_publisher' ) class Publisher : id = 'id_publisher' name = 'name' # simple INSERT example qry = Insert ( PgSqlDialect ()) . into ( 'table' ) . fields ([ 'field' ]) . values ([ 'value' ]) # output: ('INSERT INTO \"table\" (\"field\") VALUES (%s)', ['value']) print ( qry . assemble ()) # INSERT w/ Record object record = Publisher ( name = 'some publisher name' ) qry = Insert ( PgSqlDialect ()) . into ( record ) # output: ('INSERT INTO \"publisher\" (\"name\") VALUES (%s)', ['some publisher name']) print ( qry . assemble ()) It is possible to build an INSERT query to perform multiple inserts: from rick_db.sql import Insert , PgSqlDialect data = [ [ 'john' , 'connor' ], [ 'sarah' , 'connor' ] ] sql = [] qry = Insert ( PgSqlDialect ()) . into ( 'table' ) . fields ([ 'name' , 'surname' ]) for v in data : qry . values ( v ) sql . append ( qry . assemble ()) # output: # [('INSERT INTO \"table\" (\"name\", \"surname\") VALUES (%s, %s)', ['john', 'connor']), # ('INSERT INTO \"table\" (\"name\", \"surname\") VALUES (%s, %s)', ['sarah', 'connor'])] print ( sql ) Update Update objects can be used to generate SQL UPDATE WHERE statements, with Record object support: from rick_db.sql import Update , PgSqlDialect @fieldmapper ( tablename = 'publisher' , pk = 'id_publisher' ) class Publisher : id = 'id_publisher' name = 'name' # simple UPDATE example qry = Update ( PgSqlDialect ()) . table ( 'table' ) . fields ([ 'field' ]) . values ([ 'value' ]) # output: ('UPDATE \"table\" SET \"field\"=%s', ['value']) print ( qry . assemble ()) # INSERT w/ Record object record = Publisher ( name = 'some publisher name' ) qry = Update ( PgSqlDialect ()) . table ( 'tablename' ) . values ( record ) # output: ('UPDATE \"tablename\" SET \"name\"=%s', ['some publisher name']) print ( qry . assemble ()) WHERE clause support: from rick_db.sql import Update , PgSqlDialect # UPDATE WHERE... common usage qry = Update ( PgSqlDialect ()) . table ( 'table' ) . \\ values ({ 'field' : 'value' }) . \\ where ( 'id' , '=' , 7 ) # output: ('UPDATE \"table\" SET \"field\"=%s WHERE \"id\" = %s', ['value', 7]) print ( qry . assemble ()) # UPDATE WHERE... no value qry = Update ( PgSqlDialect ()) . table ( 'table' ) . \\ values ({ 'field' : 'value' }) . \\ where ( 'id' , 'IS NOT NULL' ) # output: ('UPDATE \"table\" SET \"field\"=%s WHERE \"id\" IS NOT NULL', ['value']) print ( qry . assemble ()) # UPDATE WHERE... with multiple clauses qry = Update ( PgSqlDialect ()) . table ( 'table' ) . \\ values ({ 'field' : 'value' }) . \\ where ( 'id' , '=' , 7 ) . \\ where ( 'name' , 'ILIKE' , 'john%' ) # output: ('UPDATE \"table\" SET \"field\"=%s WHERE \"id\" = %s AND \"name\" ILIKE %s', ['value', 7, 'john%']) print ( qry . assemble ()) Delete Delete objects can be used to generate SQL DELETE statements: from rick_db.sql import Delete , PgSqlDialect # DELETE WHERE... common usage qry = Delete ( PgSqlDialect ()) . from_ ( 'table' ) . \\ where ( 'id' , '=' , 7 ) # output: ('DELETE FROM \"table\" WHERE \"id\" = %s', [7]) print ( qry . assemble ()) # DELETE WHERE... no value qry = Delete ( PgSqlDialect ()) . from_ ( 'table' ) . \\ where ( 'id' , 'IS NOT NULL' ) # output: ('DELETE FROM \"table\" WHERE \"id\" IS NOT NULL', []) print ( qry . assemble ()) # DELETE WHERE... with multiple clauses qry = Delete ( PgSqlDialect ()) . from_ ( 'table' ) . \\ where ( 'id' , '=' , 7 ) . \\ where ( 'name' , 'ILIKE' , 'john%' ) # output: ('DELETE FROM \"table\" WHERE \"id\" = %s AND \"name\" ILIKE %s', [7, 'john%']) print ( qry . assemble ())","title":"Query Builder"},{"location":"building_queries/#building-queries","text":"RickDb's Query Builder can generate SELECT, INSERT, DELETE and UPDATE queries. It also provides schema support (including cross-schema operations), JOIN support and recognizes Record objects for table and schema identification. The query builder provides SQL generation using a fluent interface, suitable for most cases. Different database support is handled via dialect objects (extending from SqlDialect). The query builder itself will only generate a SQL string and a parameter value list; it is up to the developer to use the generated SQL in the appropriate database context.","title":"Building Queries"},{"location":"building_queries/#select","text":"Selects are by far the most common statements, and can be easily built using a Select query builder object. Check the class documentation for more details on all available methods. Simple Select() examples: from rick_db.sql import Select , PgSqlDialect # SELECT ALL qry , _ = Select ( PgSqlDialect ()) . from_ ( 'table' ) . assemble () # output: SELECT \"table\".* FROM \"table\" print ( qry ) # SELECT from 2 tables, with specific columns qry , _ = Select ( PgSqlDialect ()) . from_ ( 'table1' , [ 'table1_field' ]) \\ . from_ ( 'table2' , [ 'table2_field' ]) \\ . assemble () # output: SELECT \"table1_field\",\"table2_field\" FROM \"table1\", \"table2\" print ( qry ) # SELECT WHERE qry , values = Select ( PgSqlDialect ()) . from_ ( 'table' ) . \\ where ( 'id' , '=' , 7 ) . \\ assemble () # output: SELECT \"table\".* FROM \"table\" WHERE (\"id\" = %s) print ( qry ) Table aliasing is also supported, as well as schema names: from rick_db.sql import Select , PgSqlDialect # SELECT w/ table alias and schema qry , _ = Select ( PgSqlDialect ()) . from_ ({ 'table' : 't1' }, schema = 'data' ) . assemble () # output: SELECT \"t1\".* FROM \"data\".\"table\" AS \"t1\" print ( qry ) And, of course, columns can be aliased too: from rick_db.sql import Select , PgSqlDialect # SELECT w/ column alias qry , _ = Select ( PgSqlDialect ()) . from_ ( 'table' , { 'id' : 'id_table' }) . assemble () # output: SELECT \"id\" AS \"id_table\" FROM \"table\" print ( qry ) # SELECT w/ column alias, and non aliased field qry , _ = Select ( PgSqlDialect ()) . from_ ( 'table' , { 'id' : 'id_table' , 'name' : None }) . assemble () # output: SELECT \"id\" AS \"id_table\",\"name\" FROM \"table\" print ( qry ) The query builder also fully supports Record classes or objects as table and schema identifiers: from rick_db import fieldmapper from rick_db.sql import Select , PgSqlDialect @fieldmapper ( tablename = 'publisher' , pk = 'id_publisher' ) class Publisher : id = 'id_publisher' name = 'name' @fieldmapper ( tablename = 'book' , pk = 'id_book' ) class Book : id = 'id_book' title = 'title' total_pages = 'total_pages' rating = 'rating' isbn = 'isbn' published = 'published_date' fk_publisher = 'fk_publisher' # simple SELECT qry , values = Select ( PgSqlDialect ()) . from_ ( Publisher ) . assemble () # output: SELECT \"publisher\".* FROM \"publisher\" print ( qry ) # SELECT... WHERE qry , values = Select ( PgSqlDialect ()) . from_ ( Book , [ Book . title , Book . rating ]) . \\ where ( Book . id , '=' , 5 ) . \\ assemble () # output: SELECT \"title\",\"rating\" FROM \"book\" WHERE (\"id_book\" = %s) print ( qry ) # SELECT... JOIN qry , values = Select ( PgSqlDialect ()) . from_ ( Book ) . \\ join ( Publisher , Publisher . id , Book , Book . fk_publisher , cols = { Publisher . name : 'publisher_name' }) . \\ assemble () # output: SELECT \"book\".*,\"publisher\".\"name\" AS \"publisher_name\" FROM \"book\" INNER JOIN \"publisher\" ON \"book\".\"fk_publisher\"=\"publisher\".\"id_publisher\" print ( qry ) The Select Object also supports both AND and OR WHERE clauses, as well as nested parenthesis: from rick_db.sql import Select , PgSqlDialect # SELECT... WHERE <cond> OR <cond> qry , values = Select ( PgSqlDialect ()) . from_ ( Book ) . \\ where ( Book . title , 'ILIKE' , '%SQL%' ) . \\ orwhere ( Book . rating , '>' , 4 ) . \\ assemble () # output: SELECT \"book\".* FROM \"book\" WHERE (\"title\" ILIKE %s) OR (\"rating\" > %s) print ( qry ) # SELECT... WHERE <cond> OR (<cond> AND <cond>) qry , values = Select ( PgSqlDialect ()) . from_ ( Book ) . \\ where ( Book . title , 'ILIKE' , '%SQL%' ) . \\ where_or () . \\ where ( Book . rating , '>' , 4 ) . \\ where ( Book . total_pages , '>' , 150 ) . \\ where_end () . \\ assemble () # output: SELECT \"book\".* FROM \"book\" WHERE (\"title\" ILIKE %s) OR ( (\"rating\" > %s) AND (\"total_pages\" > %s) ) print ( qry ) Select Object supports LEFT JOIN , RIGHT JOIN , FULL JOIN , CROSS JOIN and NATURAL JOIN : from rick_db.sql import Select , PgSqlDialect # LEFT JOIN qry , values = Select ( PgSqlDialect ()) . from_ ( 'table1' ) . \\ join ( 'table2' , 'id' , 'table1' , 'fk_table2' ) . \\ assemble () # output: SELECT \"table1\".* FROM \"table1\" INNER JOIN \"table2\" ON \"table1\".\"fk_table2\"=\"table2\".\"id\" print ( qry ) # RIGHT JOIN qry , values = Select ( PgSqlDialect ()) . from_ ( 'table1' ) . \\ join_right ( 'table2' , 'id' , 'table1' , 'fk_table2' ) . \\ assemble () # output: SELECT \"table1\".* FROM \"table1\" RIGHT JOIN \"table2\" ON \"table1\".\"fk_table2\"=\"table2\".\"id\" print ( qry ) # FULL JOIN qry , values = Select ( PgSqlDialect ()) . from_ ( 'table1' ) . \\ join_full ( 'table2' , 'id' , 'table1' , 'fk_table2' ) . \\ assemble () # output: SELECT \"table1\".* FROM \"table1\" FULL JOIN \"table2\" ON \"table1\".\"fk_table2\"=\"table2\".\"id\" print ( qry ) # CROSS JOIN qry , values = Select ( PgSqlDialect ()) . from_ ( 'table1' ) . \\ join_cross ( 'table2' ) . \\ assemble () # output: SELECT \"table1\".* FROM \"table1\" CROSS JOIN \"table2\" print ( qry ) # NATURAL JOIN qry , values = Select ( PgSqlDialect ()) . from_ ( 'table1' ) . \\ join_natural ( 'table2' ) . \\ assemble () # output: SELECT \"table1\".* FROM \"table1\" NATURAL JOIN \"table2\" print ( qry ) # mixed example qry , values = Select ( PgSqlDialect ()) . from_ ( 'table1' ) . \\ join_right ( 'table2' , 'id' , 'table1' , 'fk_table2' ) . \\ join ( 'table3' , 'id' , 'table2' , 'fk_table3' ) . \\ join ( 'table4' , 'id' , 'table3' , 'fk_table4' ) . \\ assemble () # output: SELECT \"table1\".* FROM \"table1\" RIGHT JOIN \"table2\" ON \"table1\".\"fk_table2\"=\"table2\".\"id\" INNER JOIN \"table3\" ON \"table2\".\"fk_table3\"=\"table3\".\"id\" INNER JOIN \"table4\" ON \"table3\".\"fk_table4\"=\"table4\".\"id\" print ( qry ) It is also possible to use subselects: from rick_db.sql import Select , PgSqlDialect subselect = Select ( PgSqlDialect ()) . from_ ( 'some_table' , [ 'id' ]) . where ( 'field' , '>' , 32 ) qry , _ = Select ( PgSqlDialect ()) . from_ ( 'table' ) . \\ where ( 'field' , 'IN' , subselect ) . \\ assemble () # output: SELECT \"table\".* FROM \"table\" WHERE (\"field\" IN (SELECT \"id\" FROM \"some_table\" WHERE (\"field\" > %s))) print ( qry ) Also, custom SQL expressions are supported: from rick_db.sql import Select , PgSqlDialect , Literal # using a simple expression qry , _ = Select ( PgSqlDialect ()) . expr ([ 1 ]) . assemble () # output: SELECT 1 print ( qry ) # using a simple expression qry , _ = Select ( PgSqlDialect ()) . expr ([ 1 , 2 , 3 ]) . assemble () # output: SELECT 1,2,3 print ( qry ) # using LITERAL qry , _ = Select ( PgSqlDialect ()) . from_ ( 'table' , { Literal ( 'COUNT(*)' ): 'total' }) . assemble () # output: SELECT COUNT(*) AS \"total\" FROM \"table\" print ( qry )","title":"Select"},{"location":"building_queries/#insert","text":"Insert objects can be used to generate SQL INSERT statements, with optional RETURNING clause, and with full support for Record objects: from rick_db.sql import Insert , PgSqlDialect from rick_db import fieldmapper @fieldmapper ( tablename = 'publisher' , pk = 'id_publisher' ) class Publisher : id = 'id_publisher' name = 'name' # simple INSERT example qry = Insert ( PgSqlDialect ()) . into ( 'table' ) . fields ([ 'field' ]) . values ([ 'value' ]) # output: ('INSERT INTO \"table\" (\"field\") VALUES (%s)', ['value']) print ( qry . assemble ()) # INSERT w/ Record object record = Publisher ( name = 'some publisher name' ) qry = Insert ( PgSqlDialect ()) . into ( record ) # output: ('INSERT INTO \"publisher\" (\"name\") VALUES (%s)', ['some publisher name']) print ( qry . assemble ()) It is possible to build an INSERT query to perform multiple inserts: from rick_db.sql import Insert , PgSqlDialect data = [ [ 'john' , 'connor' ], [ 'sarah' , 'connor' ] ] sql = [] qry = Insert ( PgSqlDialect ()) . into ( 'table' ) . fields ([ 'name' , 'surname' ]) for v in data : qry . values ( v ) sql . append ( qry . assemble ()) # output: # [('INSERT INTO \"table\" (\"name\", \"surname\") VALUES (%s, %s)', ['john', 'connor']), # ('INSERT INTO \"table\" (\"name\", \"surname\") VALUES (%s, %s)', ['sarah', 'connor'])] print ( sql )","title":"Insert"},{"location":"building_queries/#update","text":"Update objects can be used to generate SQL UPDATE WHERE statements, with Record object support: from rick_db.sql import Update , PgSqlDialect @fieldmapper ( tablename = 'publisher' , pk = 'id_publisher' ) class Publisher : id = 'id_publisher' name = 'name' # simple UPDATE example qry = Update ( PgSqlDialect ()) . table ( 'table' ) . fields ([ 'field' ]) . values ([ 'value' ]) # output: ('UPDATE \"table\" SET \"field\"=%s', ['value']) print ( qry . assemble ()) # INSERT w/ Record object record = Publisher ( name = 'some publisher name' ) qry = Update ( PgSqlDialect ()) . table ( 'tablename' ) . values ( record ) # output: ('UPDATE \"tablename\" SET \"name\"=%s', ['some publisher name']) print ( qry . assemble ()) WHERE clause support: from rick_db.sql import Update , PgSqlDialect # UPDATE WHERE... common usage qry = Update ( PgSqlDialect ()) . table ( 'table' ) . \\ values ({ 'field' : 'value' }) . \\ where ( 'id' , '=' , 7 ) # output: ('UPDATE \"table\" SET \"field\"=%s WHERE \"id\" = %s', ['value', 7]) print ( qry . assemble ()) # UPDATE WHERE... no value qry = Update ( PgSqlDialect ()) . table ( 'table' ) . \\ values ({ 'field' : 'value' }) . \\ where ( 'id' , 'IS NOT NULL' ) # output: ('UPDATE \"table\" SET \"field\"=%s WHERE \"id\" IS NOT NULL', ['value']) print ( qry . assemble ()) # UPDATE WHERE... with multiple clauses qry = Update ( PgSqlDialect ()) . table ( 'table' ) . \\ values ({ 'field' : 'value' }) . \\ where ( 'id' , '=' , 7 ) . \\ where ( 'name' , 'ILIKE' , 'john%' ) # output: ('UPDATE \"table\" SET \"field\"=%s WHERE \"id\" = %s AND \"name\" ILIKE %s', ['value', 7, 'john%']) print ( qry . assemble ())","title":"Update"},{"location":"building_queries/#delete","text":"Delete objects can be used to generate SQL DELETE statements: from rick_db.sql import Delete , PgSqlDialect # DELETE WHERE... common usage qry = Delete ( PgSqlDialect ()) . from_ ( 'table' ) . \\ where ( 'id' , '=' , 7 ) # output: ('DELETE FROM \"table\" WHERE \"id\" = %s', [7]) print ( qry . assemble ()) # DELETE WHERE... no value qry = Delete ( PgSqlDialect ()) . from_ ( 'table' ) . \\ where ( 'id' , 'IS NOT NULL' ) # output: ('DELETE FROM \"table\" WHERE \"id\" IS NOT NULL', []) print ( qry . assemble ()) # DELETE WHERE... with multiple clauses qry = Delete ( PgSqlDialect ()) . from_ ( 'table' ) . \\ where ( 'id' , '=' , 7 ) . \\ where ( 'name' , 'ILIKE' , 'john%' ) # output: ('DELETE FROM \"table\" WHERE \"id\" = %s AND \"name\" ILIKE %s', [7, 'john%']) print ( qry . assemble ())","title":"Delete"},{"location":"changelog/","text":"","title":"Changelog"},{"location":"connection/","text":"Connection The connection object provides high-level methods to interact with the database, including cursor and transaction support, as well as a profiler. For more information on available methods, see Connection . Connecting to PostgreSQL There are three PostgreSQL connectors available; however, it is advisable to use the regular PgConnection with an external connection pool, such as pgpool or equivalent. Available connection parameters: Field Connector Description dbname All Database Name user All User name used to authenticate password All Password used to authenticate host All Database host (defaults to UNIX socket if not provided port All Connection port (defaults to 5432 if not provided sslmode All *SSL negotiation type: disable, allow, prefer, require minconn PgConnectionPool, PgThreadedConnectionPool Minimum number of connections to keep, defaults to 5 if not provided maxconn PgConnectionPool, PgThreadedConnectionPool Maximum number of connections to keep, defaults to 5 if not provided *More details on sslmode operation are available in the libpq documentation . Using PgConnection: from rick_db.conn.pg import PgConnection config = { 'dbname' : 'my_database' , 'user' : '<some_user>' , 'password' : '<some_password>' , 'host' : 'localhost' , 'port' : 5432 , 'sslmode' : 'require' } # create connection conn = PgConnection ( ** config ) Using PgConnectionPool: from rick_db.conn.pg import PgConnectionPool config = { 'dbname' : 'my_database' , 'user' : '<some_user>' , 'password' : '<some_password>' , 'host' : 'localhost' , 'port' : 5432 , 'minconn' : 4 , } # create connection conn = PgConnectionPool ( ** config ) Using PgThreadedConnectionPool: from rick_db.conn.pg import PgThreadedConnectionPool config = { 'dbname' : 'my_database' , 'user' : '<some_user>' , 'password' : '<some_password>' , 'host' : 'localhost' , 'port' : 5432 , 'minconn' : 4 , } # create connection conn = PgThreadedConnectionPool ( ** config ) Connecting to SQLite Available connection parameters: Field Description db_file Database file isolation_level Optional isolation level; defaults to empty if not provided timeout Timeout in seconds; defaults to 5.0 if not provided Example: from rick_db.conn.sqlite import Sqlite3Connection # create or open a sqlite database conn = Sqlite3Connection ( 'my_database.db' ) Using a profiler RickDb provides a simple profiler interface that allows logging of queries, parameters and execution times, as well as a simple in-memory profiler implementation, DefaultProfiler . To use a DefaultProfiler instance on a connection, just assign the desired instance to the profiler property: from rick_db.conn.pg import PgConnection from rick_db.profiler import DefaultProfiler db_cfg = { 'dbname' : \"rick_test\" , 'user' : \"rickdb_user\" , 'password' : \"rickdb_password\" , 'sslmode' : 'require' } conn = PgConnection ( ** db_cfg ) # instantiate profiler, and use it on conn object conn . profiler = DefaultProfiler () # perform some queries we can profile with conn . cursor () as c : c . exec ( \"SELECT 1\" ) # output: SELECT 1 0.00012579001486301422 for evt in conn . profiler . get_events (): print ( evt . query , evt . elapsed )","title":"Connection"},{"location":"connection/#connection","text":"The connection object provides high-level methods to interact with the database, including cursor and transaction support, as well as a profiler. For more information on available methods, see Connection .","title":"Connection"},{"location":"connection/#connecting-to-postgresql","text":"There are three PostgreSQL connectors available; however, it is advisable to use the regular PgConnection with an external connection pool, such as pgpool or equivalent. Available connection parameters: Field Connector Description dbname All Database Name user All User name used to authenticate password All Password used to authenticate host All Database host (defaults to UNIX socket if not provided port All Connection port (defaults to 5432 if not provided sslmode All *SSL negotiation type: disable, allow, prefer, require minconn PgConnectionPool, PgThreadedConnectionPool Minimum number of connections to keep, defaults to 5 if not provided maxconn PgConnectionPool, PgThreadedConnectionPool Maximum number of connections to keep, defaults to 5 if not provided *More details on sslmode operation are available in the libpq documentation . Using PgConnection: from rick_db.conn.pg import PgConnection config = { 'dbname' : 'my_database' , 'user' : '<some_user>' , 'password' : '<some_password>' , 'host' : 'localhost' , 'port' : 5432 , 'sslmode' : 'require' } # create connection conn = PgConnection ( ** config ) Using PgConnectionPool: from rick_db.conn.pg import PgConnectionPool config = { 'dbname' : 'my_database' , 'user' : '<some_user>' , 'password' : '<some_password>' , 'host' : 'localhost' , 'port' : 5432 , 'minconn' : 4 , } # create connection conn = PgConnectionPool ( ** config ) Using PgThreadedConnectionPool: from rick_db.conn.pg import PgThreadedConnectionPool config = { 'dbname' : 'my_database' , 'user' : '<some_user>' , 'password' : '<some_password>' , 'host' : 'localhost' , 'port' : 5432 , 'minconn' : 4 , } # create connection conn = PgThreadedConnectionPool ( ** config )","title":"Connecting to PostgreSQL"},{"location":"connection/#connecting-to-sqlite","text":"Available connection parameters: Field Description db_file Database file isolation_level Optional isolation level; defaults to empty if not provided timeout Timeout in seconds; defaults to 5.0 if not provided Example: from rick_db.conn.sqlite import Sqlite3Connection # create or open a sqlite database conn = Sqlite3Connection ( 'my_database.db' )","title":"Connecting to SQLite"},{"location":"connection/#using-a-profiler","text":"RickDb provides a simple profiler interface that allows logging of queries, parameters and execution times, as well as a simple in-memory profiler implementation, DefaultProfiler . To use a DefaultProfiler instance on a connection, just assign the desired instance to the profiler property: from rick_db.conn.pg import PgConnection from rick_db.profiler import DefaultProfiler db_cfg = { 'dbname' : \"rick_test\" , 'user' : \"rickdb_user\" , 'password' : \"rickdb_password\" , 'sslmode' : 'require' } conn = PgConnection ( ** db_cfg ) # instantiate profiler, and use it on conn object conn . profiler = DefaultProfiler () # perform some queries we can profile with conn . cursor () as c : c . exec ( \"SELECT 1\" ) # output: SELECT 1 0.00012579001486301422 for evt in conn . profiler . get_events (): print ( evt . query , evt . elapsed )","title":"Using a profiler"},{"location":"grid/","text":"DbGrid DbGrid is a helper class to aid the creation of table-like listings(grids). It provides a clean, programmatic way of searching a given database object (or use a custom query) with string search, exact matching and pagination. It returns the total row count (without applying pagination), and the filtered row subset matching the pagination results. Example: from rick_db import fieldmapper , Repository , DbGrid from rick_db.conn.pg import PgConnection @fieldmapper ( tablename = 'product' , pk = 'id_product' ) class Product : id = 'id_product' short_description = 'short_description' brand = 'brand_id' db_config = { \"dbname\" : \"products\" , \"user\" : \"someUser\" , \"password\" : \"somePassword\" , \"host\" : \"localhost\" , \"port\" : 5432 } # create connection conn = PgConnection ( ** db_config ) # create a repository repo = Repository ( conn , Product ) # create a grid grid = DbGrid ( repo , # repository to use [ Product . short_description ], # fields to perform text search DbGrid . SEARCH_ANY # type of search ) # retrieve first 10 results # total will have the total row count that matches the filters, without limit total , rows = grid . run ( search_text = 'bag' , match_fields = { Product . brand : 12 }, limit = 10 ) print ( \"total matches:\" , total ) for r in rows : print ( r . id , r . short_description ) # retrieve second page of results total , rows = grid . run ( search_text = 'bag' , match_fields = { Product . brand : 12 }, limit = 10 , offset = 10 ) for r in rows : print ( r . id , r . short_description ) Limitations: Sqlite3 On Sqlite3, case-insensitive search is done via UPPER(), since no ILIKE equivalent is available. This is may trigger a full table scan and will not use indexes if they are available for the specific field. Additionally, this method only works with ASCII chars. It its therefore recommended to avoid the usage of case-sensitive search with this driver. As an option, one can instead use COLLATE NOCASE on the creation of the required fields, and use DbGrid with case_sensitive=True. This way, search will be case insensitive on the fields created with the COLLATE NOCASE option.","title":"DbGrid"},{"location":"grid/#dbgrid","text":"DbGrid is a helper class to aid the creation of table-like listings(grids). It provides a clean, programmatic way of searching a given database object (or use a custom query) with string search, exact matching and pagination. It returns the total row count (without applying pagination), and the filtered row subset matching the pagination results. Example: from rick_db import fieldmapper , Repository , DbGrid from rick_db.conn.pg import PgConnection @fieldmapper ( tablename = 'product' , pk = 'id_product' ) class Product : id = 'id_product' short_description = 'short_description' brand = 'brand_id' db_config = { \"dbname\" : \"products\" , \"user\" : \"someUser\" , \"password\" : \"somePassword\" , \"host\" : \"localhost\" , \"port\" : 5432 } # create connection conn = PgConnection ( ** db_config ) # create a repository repo = Repository ( conn , Product ) # create a grid grid = DbGrid ( repo , # repository to use [ Product . short_description ], # fields to perform text search DbGrid . SEARCH_ANY # type of search ) # retrieve first 10 results # total will have the total row count that matches the filters, without limit total , rows = grid . run ( search_text = 'bag' , match_fields = { Product . brand : 12 }, limit = 10 ) print ( \"total matches:\" , total ) for r in rows : print ( r . id , r . short_description ) # retrieve second page of results total , rows = grid . run ( search_text = 'bag' , match_fields = { Product . brand : 12 }, limit = 10 , offset = 10 ) for r in rows : print ( r . id , r . short_description )","title":"DbGrid"},{"location":"grid/#limitations","text":"Sqlite3 On Sqlite3, case-insensitive search is done via UPPER(), since no ILIKE equivalent is available. This is may trigger a full table scan and will not use indexes if they are available for the specific field. Additionally, this method only works with ASCII chars. It its therefore recommended to avoid the usage of case-sensitive search with this driver. As an option, one can instead use COLLATE NOCASE on the creation of the required fields, and use DbGrid with case_sensitive=True. This way, search will be case insensitive on the fields created with the COLLATE NOCASE option.","title":"Limitations:"},{"location":"install/","text":"Installation The recommended instalation procedure is to use the available pip package. Make sure you have psycopg2 and setuptools installed before proceeding. Required dependencies RickDb requires the following dependencies: pytest psycopg2 toml setuptools Please note, most platforms have both psycopg2 and setuptools available as a separate, binary installed package. Installing psycopg2 and setuptools in Ubuntu (>=18): $ sudo apt install python3-setuptools python3-psycopg2 Installing from package RickDb is available in PyPi as a package, an can easily be installed using pip: $ pip install rick-db Installing from source clone the repository to a folder: $ git clone https://github.com/oddbit-project/rick_db.git $ cd rick_db rick_db$ install missing dependencies rick_db$ pip install -r requirements.txt run setuptools from the repository folder: rick_db$ python3 setup.py install","title":"Installation"},{"location":"install/#installation","text":"The recommended instalation procedure is to use the available pip package. Make sure you have psycopg2 and setuptools installed before proceeding.","title":"Installation"},{"location":"install/#required-dependencies","text":"RickDb requires the following dependencies: pytest psycopg2 toml setuptools Please note, most platforms have both psycopg2 and setuptools available as a separate, binary installed package. Installing psycopg2 and setuptools in Ubuntu (>=18): $ sudo apt install python3-setuptools python3-psycopg2","title":"Required dependencies"},{"location":"install/#installing-from-package","text":"RickDb is available in PyPi as a package, an can easily be installed using pip: $ pip install rick-db","title":"Installing from package"},{"location":"install/#installing-from-source","text":"clone the repository to a folder: $ git clone https://github.com/oddbit-project/rick_db.git $ cd rick_db rick_db$ install missing dependencies rick_db$ pip install -r requirements.txt run setuptools from the repository folder: rick_db$ python3 setup.py install","title":"Installing from source"},{"location":"migrations/","text":"Migrations RickDb is a schema-first library - there is no automatic generation of database objects; instead they are usually modeled using raw SQL, and kept in files separated from application code. While there are plenty of tools to manage migration, RickDb provides a simple, forward-only migration manager cli utility that can be used to manage these SQL files, rickdb . Why forward-only? Many database migration tools provide mechanisms to create and remove database objects, with the purpose of rolling back schema changes. However, rolling back schema changes can lead to the truncation of relevant data; adding a field, then removing it will effectively truncate the stored information; however, adding a row with an automatic identity field, then removing it will not rollback the underlying identity sequence value. While this kind of rollback capability is quite popular, it is obvious most SGBDs can't actually perform rollbacks the way they were conceptualized. Instead of this approach, RickDb's Migration Manager only supports \"forward-only\" migrations - a sequence of SQL files with the desired changes for a given database. These changes can be additive (e.g. creating tables and views), transformational (e.g. adding fields or indexes) or destructive (e.g. removing tables, views, fields, etc). Configuration The bundled Migration Manager requires a TOML configuration file, called by default rickdb.toml , containing the database connection details. The file usually resides in the project root directory, but can also have a custom location, specified by the environment variable RICKDB_CONFIG . The TOML config file can have one or more database configuration keys. These keys may be a single default key db (for single database applications), or multiple, name-based keys prefixed with db_ : Simple single-database configuration example: # single database, no name [db] engine = \"pgsql\" host = \"localhost\" port = 5432 user = \"myuser\" password = \"mypassword\" dbname = \"myschema\" Multiple database configuration example: # administration database [db_admin] engine = \"pgsql\" host = \"localhost\" port = 5432 user = \"myuser\" password = \"mypassword\" dbname = \"admin_schema\" # application database [db_app] engine = \"pgsql\" host = \"localhost\" port = 5432 user = \"myuser\" dbname = \"app_schema\" passfile = \"/var/run/super_secret_pwd\" # test database [db_test] engine = \"sqlite\" db_file = \"/tmp/test.db\" If a [db] section exists, it will be used when no database is specified in the cli arguments; db_<name> configurations can be invoked by providing <name> as the first argument: # use [db] database $ rickdb list 14 /12/2021 18 :28:56 001 .sql 15 /12/2021 19 :32:58 002 .sql 15 /12/2021 19 :33:42 003 .sql # use [db_app] database $ rickdb app list 15 /12/2021 19 :15:00 001_schema.sql In addition to the parameters required by the connection object, there are two additional parameters: Parameter Mandatory Description engine yes Database engine to use (currently \"pgsql\" or \"sqlite\") passfile no Optional password file containing the database password Engine is a mandatory field that specifies which database Connection object will be used. Currently, its value can be either 'pgsql' or 'sqlite'. Passfile is an optional parameter indicating that the password should be read from an existing file instead. When passfile is used, the file is read into a password parameter automatically. Keep in mind, if both password and passfile are used, passfile overrides the password contents. Installation The Migration Manager requires a database table to record executed migration information. This database table can be easily created via command-line: Single database configuration: $ rickdb init Migration Manager installed sucessfully! $ Multiple database configuration, in this case for db_app: $ rickdb app init Migration Manager installed sucessfully! $ Creating migrations To create a migration, just create a directory with a set of SQL files. It is good practice to name the files sequentially, as migrations are executed ordered by name. The naming format is free-form, as long as the file has an .sql extension in lowercase. Common migration naming examples: # sequence number 0001 .sql 0002 .sql # sequence number & description 0001 -base_schema.sql 0002 -index_change_users.sql # ticket name & description TICKET001-some_stuff.sql TICKET002-other_stuff.sql # date 20210101 -something.sql 20210102 -something_else.sql Keep in mind, each migration file should be treated as immutable - each file is only applied/executed once. Subsequent changes to the file will be ignored; any desired changes to the file after it has been run should be made on a separate migration. Applying migrations The migration manager provides two useful commands to manage pending migrations - check and migrate. rickdb check <path> This command compares all migration names in the specified path with the already applied ones, indicating which ones were already applied: $ rickdb check migrations/ Checking 001 .sql... already applied Checking 002 .sql... already applied Checking 003 .sql... new migration $ rickdb migrate <path> This command executes the new migrations, one by one, from the specified directory, ordered by file name. If any error occurs, execution is aborted. The migrations are not executed within a transaction, due to varying transaction support in database engines; any required transaction blocks must be explicit, or there is always the possibility of failure in the middle of a multi-statement migration. Partially failed migrations are not registered (because execution is aborted), and should be handled manually. $ rickdb migrate migrations/ Executing 001 .sql... skipping, already applied Executing 002 .sql... skipping, already applied Executing 003 .sql... success $ Flattening migrations During a schema-first application lifecycle, it is common to periodically combine all the migrations in a single sql file, or to replace them with a clean schema dump instead. This way, the number of migration files is kept to a sane level while assuming a certain schema state (either from a backup or from a plain file). When this is done, it is necessary to \"notify\" the migration manager that all the applied migrations ceased to exist, and now reside on a specific file to be ignored (except on clean deploys), as migrations have already been applied. To remove all those applied migration names and replace them with a single entry with a custom name, we use the flatten command: $ rickdb flatten schema.sql Flattening all migrations to schema.sql... success In the above example, the migration manager will remove all information of applied migrations, and create a single entry with schema.sql as migration name. Generating DTOs In addition to the Migration Manager functionalities, rickdb cli also provides basic code-generation capabilities based on the object mapper - specifically, the capability of generating field mapper class definitions from database objects - tables and views: $ rickdb dto page page . py DAO written to file page . py $ cat page . py from rick_db import fieldmapper @fieldmapper ( tablename = 'page' , pk = 'id_page' ) class Page : id = 'id_page' crawled = 'crawled' url = 'url' type = 'type' title = 'title' description = 'description' breadcrumbs = 'breadcrumbs' And, of course, PostgreSQL schemas are supported out-of-the-box, too: $ rickdb dto test . some_page page . py DAO written to file page . py $ cat page . py from rick_db import fieldmapper @fieldmapper ( tablename = 'some_page' , schema = 'test' , pk = 'id_page' ) class SomePage : id = 'id_page' crawled = 'crawled' url = 'url' type = 'type' title = 'title' description = 'description' breadcrumbs = 'breadcrumbs'","title":"Migrations"},{"location":"migrations/#migrations","text":"RickDb is a schema-first library - there is no automatic generation of database objects; instead they are usually modeled using raw SQL, and kept in files separated from application code. While there are plenty of tools to manage migration, RickDb provides a simple, forward-only migration manager cli utility that can be used to manage these SQL files, rickdb .","title":"Migrations"},{"location":"migrations/#why-forward-only","text":"Many database migration tools provide mechanisms to create and remove database objects, with the purpose of rolling back schema changes. However, rolling back schema changes can lead to the truncation of relevant data; adding a field, then removing it will effectively truncate the stored information; however, adding a row with an automatic identity field, then removing it will not rollback the underlying identity sequence value. While this kind of rollback capability is quite popular, it is obvious most SGBDs can't actually perform rollbacks the way they were conceptualized. Instead of this approach, RickDb's Migration Manager only supports \"forward-only\" migrations - a sequence of SQL files with the desired changes for a given database. These changes can be additive (e.g. creating tables and views), transformational (e.g. adding fields or indexes) or destructive (e.g. removing tables, views, fields, etc).","title":"Why forward-only?"},{"location":"migrations/#configuration","text":"The bundled Migration Manager requires a TOML configuration file, called by default rickdb.toml , containing the database connection details. The file usually resides in the project root directory, but can also have a custom location, specified by the environment variable RICKDB_CONFIG . The TOML config file can have one or more database configuration keys. These keys may be a single default key db (for single database applications), or multiple, name-based keys prefixed with db_ : Simple single-database configuration example: # single database, no name [db] engine = \"pgsql\" host = \"localhost\" port = 5432 user = \"myuser\" password = \"mypassword\" dbname = \"myschema\" Multiple database configuration example: # administration database [db_admin] engine = \"pgsql\" host = \"localhost\" port = 5432 user = \"myuser\" password = \"mypassword\" dbname = \"admin_schema\" # application database [db_app] engine = \"pgsql\" host = \"localhost\" port = 5432 user = \"myuser\" dbname = \"app_schema\" passfile = \"/var/run/super_secret_pwd\" # test database [db_test] engine = \"sqlite\" db_file = \"/tmp/test.db\" If a [db] section exists, it will be used when no database is specified in the cli arguments; db_<name> configurations can be invoked by providing <name> as the first argument: # use [db] database $ rickdb list 14 /12/2021 18 :28:56 001 .sql 15 /12/2021 19 :32:58 002 .sql 15 /12/2021 19 :33:42 003 .sql # use [db_app] database $ rickdb app list 15 /12/2021 19 :15:00 001_schema.sql In addition to the parameters required by the connection object, there are two additional parameters: Parameter Mandatory Description engine yes Database engine to use (currently \"pgsql\" or \"sqlite\") passfile no Optional password file containing the database password Engine is a mandatory field that specifies which database Connection object will be used. Currently, its value can be either 'pgsql' or 'sqlite'. Passfile is an optional parameter indicating that the password should be read from an existing file instead. When passfile is used, the file is read into a password parameter automatically. Keep in mind, if both password and passfile are used, passfile overrides the password contents.","title":"Configuration"},{"location":"migrations/#installation","text":"The Migration Manager requires a database table to record executed migration information. This database table can be easily created via command-line: Single database configuration: $ rickdb init Migration Manager installed sucessfully! $ Multiple database configuration, in this case for db_app: $ rickdb app init Migration Manager installed sucessfully! $","title":"Installation"},{"location":"migrations/#creating-migrations","text":"To create a migration, just create a directory with a set of SQL files. It is good practice to name the files sequentially, as migrations are executed ordered by name. The naming format is free-form, as long as the file has an .sql extension in lowercase. Common migration naming examples: # sequence number 0001 .sql 0002 .sql # sequence number & description 0001 -base_schema.sql 0002 -index_change_users.sql # ticket name & description TICKET001-some_stuff.sql TICKET002-other_stuff.sql # date 20210101 -something.sql 20210102 -something_else.sql Keep in mind, each migration file should be treated as immutable - each file is only applied/executed once. Subsequent changes to the file will be ignored; any desired changes to the file after it has been run should be made on a separate migration.","title":"Creating migrations"},{"location":"migrations/#applying-migrations","text":"The migration manager provides two useful commands to manage pending migrations - check and migrate.","title":"Applying migrations"},{"location":"migrations/#rickdb-check-path","text":"This command compares all migration names in the specified path with the already applied ones, indicating which ones were already applied: $ rickdb check migrations/ Checking 001 .sql... already applied Checking 002 .sql... already applied Checking 003 .sql... new migration $","title":"rickdb check &lt;path&gt;"},{"location":"migrations/#rickdb-migrate-path","text":"This command executes the new migrations, one by one, from the specified directory, ordered by file name. If any error occurs, execution is aborted. The migrations are not executed within a transaction, due to varying transaction support in database engines; any required transaction blocks must be explicit, or there is always the possibility of failure in the middle of a multi-statement migration. Partially failed migrations are not registered (because execution is aborted), and should be handled manually. $ rickdb migrate migrations/ Executing 001 .sql... skipping, already applied Executing 002 .sql... skipping, already applied Executing 003 .sql... success $","title":"rickdb migrate &lt;path&gt;"},{"location":"migrations/#flattening-migrations","text":"During a schema-first application lifecycle, it is common to periodically combine all the migrations in a single sql file, or to replace them with a clean schema dump instead. This way, the number of migration files is kept to a sane level while assuming a certain schema state (either from a backup or from a plain file). When this is done, it is necessary to \"notify\" the migration manager that all the applied migrations ceased to exist, and now reside on a specific file to be ignored (except on clean deploys), as migrations have already been applied. To remove all those applied migration names and replace them with a single entry with a custom name, we use the flatten command: $ rickdb flatten schema.sql Flattening all migrations to schema.sql... success In the above example, the migration manager will remove all information of applied migrations, and create a single entry with schema.sql as migration name.","title":"Flattening migrations"},{"location":"migrations/#generating-dtos","text":"In addition to the Migration Manager functionalities, rickdb cli also provides basic code-generation capabilities based on the object mapper - specifically, the capability of generating field mapper class definitions from database objects - tables and views: $ rickdb dto page page . py DAO written to file page . py $ cat page . py from rick_db import fieldmapper @fieldmapper ( tablename = 'page' , pk = 'id_page' ) class Page : id = 'id_page' crawled = 'crawled' url = 'url' type = 'type' title = 'title' description = 'description' breadcrumbs = 'breadcrumbs' And, of course, PostgreSQL schemas are supported out-of-the-box, too: $ rickdb dto test . some_page page . py DAO written to file page . py $ cat page . py from rick_db import fieldmapper @fieldmapper ( tablename = 'some_page' , schema = 'test' , pk = 'id_page' ) class SomePage : id = 'id_page' crawled = 'crawled' url = 'url' type = 'type' title = 'title' description = 'description' breadcrumbs = 'breadcrumbs'","title":"Generating DTOs"},{"location":"object_mapper/","text":"Object Mapper DTO Records The RickDb object mapper allows the declaration of DTO (data transfer objects) classes, generically known as Records. A record contains a set of attributes and their corresponding field names in the database scope, and some optional additional details such as table name, schema and primary key information. The object mapper purpose is to manage the translation of database fields to object attributes, and vice-versa. RickDb Records are pure data objects, as they don't depend on or reference any database-specific resource; they only hold attributes and values representing a result row from a given database operation. Attribute names are also independent of their database representation - the mapping between an attribute and the underlying field name is explicit, and performed in the declaration of the class. It is possible to declare Record objects that map only a subset of fields from a given query result; the additional fields will be ignored. These properties make Records a suitable format to carry data between architectural boundaries, not only due to their decoupling from the underlying table structure, but also because they can be easily serialized and deserialized. To achieve better performance, the internal mapping of attributes to database field names is performed at load time within the class declaration context; a decorator patches the class definition with the required internal structures when the file is loaded, instead of handling it in runtime. Declaring Records Record classes are declared using the @fieldmapper decorator: from rick_db import fieldmapper @fieldmapper class Customer : id = 'id_customer' # attribute 'id' maps to field 'id_customer' name = 'name' # attribute 'name' maps to field 'name' address = 'address' # attribute 'address' maps to field 'address' city = 'city' # attribute 'city' maps to field 'city' id_country = 'fk_country' # attribute 'id_country' maps to field 'fk_country' # access class-level attributes print ( Customer . name ) # outputs 'name' # access object-level attributes # customer data is loaded via __init__; The key names must match the defined attributes customer = Customer ( id = 3 , name = \"John Doe\" , address = \"Obere Str.\" , city = \"Berlin\" ) # output: John Doe print ( customer . name ) # output: 'None' print ( customer . id_country ) # output: {'address': 'Obere Str.', 'city': 'Berlin', 'id': 3, 'name': 'John Doe'} print ( customer . asdict ()) # output: {'id_customer': 3, 'name': 'John Doe', 'address': 'Obere Str.', 'city': 'Berlin'} print ( customer . asrecord ()) As mentioned previously, it is possible to also provide optional details, such as table or view name, schema and primary key name; these details are quite useful when using RickDb's Repository or Query Builder to provide context for operations. This is probably the most common usage scenario, when designing a multi-tier application: from rick_db import fieldmapper @fieldmapper ( tablename = 'customers' , pk = 'id_customer' , schema = 'public' ) class Customer : id = 'id_customer' # attribute 'id' maps to field 'id_customer' name = 'name' # attribute 'name' maps to field 'name' address = 'address' # attribute 'address' maps to field 'address' city = 'city' # attribute 'city' maps to field 'city' id_country = 'fk_country' # attribute 'id_country' maps to field 'fk_country' # access class-level attributes print ( Customer . name ) # outputs 'name' # access object-level attributes # customer data is loaded via __init__; The key names must match the defined attributes customer = Customer ( id = 3 , name = \"John Doe\" , address = \"Obere Str.\" , city = \"Berlin\" ) # output: John Doe print ( customer . name ) # output: 'None' print ( customer . id_country ) # output: {'address': 'Obere Str.', 'city': 'Berlin', 'id': 3, 'name': 'John Doe'} print ( customer . asdict ()) # output: {'id_customer': 3, 'name': 'John Doe', 'address': 'Obere Str.', 'city': 'Berlin'} print ( customer . asrecord ()) Available methods The patching process performed by @fieldmapper copies all the available methods in the base Record class to the defined class. As a result, all Record methods can be used on a @fieldmapper patched class.","title":"Object Mapper"},{"location":"object_mapper/#object-mapper","text":"","title":"Object Mapper"},{"location":"object_mapper/#dto-records","text":"The RickDb object mapper allows the declaration of DTO (data transfer objects) classes, generically known as Records. A record contains a set of attributes and their corresponding field names in the database scope, and some optional additional details such as table name, schema and primary key information. The object mapper purpose is to manage the translation of database fields to object attributes, and vice-versa. RickDb Records are pure data objects, as they don't depend on or reference any database-specific resource; they only hold attributes and values representing a result row from a given database operation. Attribute names are also independent of their database representation - the mapping between an attribute and the underlying field name is explicit, and performed in the declaration of the class. It is possible to declare Record objects that map only a subset of fields from a given query result; the additional fields will be ignored. These properties make Records a suitable format to carry data between architectural boundaries, not only due to their decoupling from the underlying table structure, but also because they can be easily serialized and deserialized. To achieve better performance, the internal mapping of attributes to database field names is performed at load time within the class declaration context; a decorator patches the class definition with the required internal structures when the file is loaded, instead of handling it in runtime.","title":"DTO Records"},{"location":"object_mapper/#declaring-records","text":"Record classes are declared using the @fieldmapper decorator: from rick_db import fieldmapper @fieldmapper class Customer : id = 'id_customer' # attribute 'id' maps to field 'id_customer' name = 'name' # attribute 'name' maps to field 'name' address = 'address' # attribute 'address' maps to field 'address' city = 'city' # attribute 'city' maps to field 'city' id_country = 'fk_country' # attribute 'id_country' maps to field 'fk_country' # access class-level attributes print ( Customer . name ) # outputs 'name' # access object-level attributes # customer data is loaded via __init__; The key names must match the defined attributes customer = Customer ( id = 3 , name = \"John Doe\" , address = \"Obere Str.\" , city = \"Berlin\" ) # output: John Doe print ( customer . name ) # output: 'None' print ( customer . id_country ) # output: {'address': 'Obere Str.', 'city': 'Berlin', 'id': 3, 'name': 'John Doe'} print ( customer . asdict ()) # output: {'id_customer': 3, 'name': 'John Doe', 'address': 'Obere Str.', 'city': 'Berlin'} print ( customer . asrecord ()) As mentioned previously, it is possible to also provide optional details, such as table or view name, schema and primary key name; these details are quite useful when using RickDb's Repository or Query Builder to provide context for operations. This is probably the most common usage scenario, when designing a multi-tier application: from rick_db import fieldmapper @fieldmapper ( tablename = 'customers' , pk = 'id_customer' , schema = 'public' ) class Customer : id = 'id_customer' # attribute 'id' maps to field 'id_customer' name = 'name' # attribute 'name' maps to field 'name' address = 'address' # attribute 'address' maps to field 'address' city = 'city' # attribute 'city' maps to field 'city' id_country = 'fk_country' # attribute 'id_country' maps to field 'fk_country' # access class-level attributes print ( Customer . name ) # outputs 'name' # access object-level attributes # customer data is loaded via __init__; The key names must match the defined attributes customer = Customer ( id = 3 , name = \"John Doe\" , address = \"Obere Str.\" , city = \"Berlin\" ) # output: John Doe print ( customer . name ) # output: 'None' print ( customer . id_country ) # output: {'address': 'Obere Str.', 'city': 'Berlin', 'id': 3, 'name': 'John Doe'} print ( customer . asdict ()) # output: {'id_customer': 3, 'name': 'John Doe', 'address': 'Obere Str.', 'city': 'Berlin'} print ( customer . asrecord ())","title":"Declaring Records"},{"location":"object_mapper/#available-methods","text":"The patching process performed by @fieldmapper copies all the available methods in the base Record class to the defined class. As a result, all Record methods can be used on a @fieldmapper patched class.","title":"Available methods"},{"location":"repository/","text":"Repositories Repositories provide useful functions for Record interact with the database. They are also a Repository pattern implementation, as hinted by the naming. These constructs are quite handy in the segregation of the data access layer and the business logic or service layer in multi-layer applications, but can also be quite useful as a shortcut for common read, write or delete operations. For more details on all the available methods, check the Repository class documentation. Declaring Repositories A Repository class can be instantiated directly, or declared via direct inheritance. Typically, direct inheritance has the advantage of resulting in a properly named class that can be easily extendable by adding methods. Regardless, there are usage scenarios where direct instantiation can be quite convenient: from rick_db import fieldmapper , Repository from rick_db.conn.pg import PgConnection @fieldmapper ( tablename = 'character' , pk = 'id_character' ) class Character : id = 'id_character' name = 'name' # declare a Repository class for Character using inheritance class CharacterRepository ( Repository ): def __init__ ( self , db ): # new constructor super () . __init__ ( db , Character ) db_cfg = { ... } conn = PgConnection ( ** db_cfg ) # instantiate declared repository class repo = CharacterRepository ( conn ) # insert some records repo . insert ( Character ( id = 1 , name = 'Sarah Connor' )) repo . insert ( Character ( id = 2 , name = 'John Connor' )) # read all records using the repo object for record in repo . fetch_all (): print ( record . name ) # alternative method, instantiate a repository directly repo = Repository ( conn , Character ) # use the repo object repo . insert ( Character ( id = 3 , name = 'T-1000' )) Extending Repositories Repository classes can also contain custom methods; This is the preferred approach when implementing additional database functionality. However, the methods should be designed to be stateless - they should not add or modify internal object attributes, nor depend on previous or future executions to carry their functions. By respecting this, Repository objects can be instantiated or reused in different contexts without any extra supervision: from rick_db import fieldmapper , Repository from rick_db.sql import Select , Literal @fieldmapper ( tablename = 'book' , pk = 'id_book' ) class Book : id = 'id_book' title = 'title' total_pages = 'total_pages' rating = 'rating' isbn = 'isbn' published = 'published_date' fk_publisher = 'fk_publisher' @fieldmapper ( tablename = 'author' , pk = 'id_author' ) class Author : id = 'id_author' first_name = 'first_name' middle_name = 'middle_name' last_name = 'last_name' @fieldmapper ( tablename = 'book_author' , pk = 'id_book_author' ) class BookAuthor : id = 'id_book_author' fk_book = 'fk_book' fk_author = 'fk_author' class AuthorRepository ( Repository ): def __init__ ( self , db ): super () . __init__ ( db , Author ) def calc_avg_rating ( self , id_author : int ): \"\"\" Calculate average rating for a given author :param id_author: author id :return: average rating, if any \"\"\" # generated query: # SELECT avg(rating) AS \"rating\" FROM \"book\" INNER JOIN \"book_author\" ON # \"book\".\"id_book\"=\"book_author\".\"fk_book\" WHERE (\"fk_author\" = %s) qry = Select ( self . _dialect ) . \\ from_ ( Book , { Literal ( \"avg( {} )\" . format ( Book . rating )): 'rating' }) . \\ join ( BookAuthor , BookAuthor . fk_book , Book , Book . id ) . \\ where ( BookAuthor . fk_author , '=' , id_author ) # retrieve result as list of type Book (to get the rating field) rset = self . fetch ( qry , cls = Book ) if len ( rset ) > 0 : return rset . pop ( 0 ) . rating return 0 def books ( self , id_author : int ) -> list [ Book ]: \"\"\" Retrieve all books for the given author :return: list[Book] \"\"\" qry = Select ( self . _dialect ) . \\ from_ ( Book ) . \\ join ( BookAuthor , BookAuthor . fk_book , Book , Book . id ) . \\ where ( BookAuthor . fk_author , '=' , id_author ) return self . fetch ( qry , cls = Book ) Advanced usage While Repository objects are stateless from an operational perspective, there is actually an internal, thread-safe, global cache that is used to accelerate query building. Most Repository methods perform actions with SQL generated from the Query Builder , and these generated SQL statements can often be cached, due to the fact that any required values are passed in a separate structure. The cache operations within the Repository internal scope can be performed by using the protected methods _cache_get(key) and _cache_set(key, value) . The key parameter is a unique identifier for the specific query within the Repository, and will be internally concatenated with a database identifier, module and repository identifier. The typical usage scenario for cache interaction is: sql_string = _cache_get ( string_method_name ) if sql_string is None : sql_string , values = some_query . assemble () _cache_set ( string_method_name , sql_string ) else : values = list_of_required_values ( ... ) The implementation of the actual Registry.fetch_pk() provides a good example of the typical pattern usage of the cache manipulation methods: ( ... ) def fetch_pk ( self , pk_value ) -> Optional [ object ]: if self . _pk is None : raise RepositoryError ( \"find_pk(): missing primary key in Record %s \" % str ( type ( self . _record ))) # try to fetch a finished SQL string from the cache, ready to use # the cache key is the method name qry = self . _cache_get ( 'find_pk' ) if qry is None : # if no cache match, we need to build the SQL string using the query builder qry , values = self . select () . where ( self . _pk , '=' , pk_value ) . limit ( 1 ) . assemble () # ...and store the generated SQL string in the cache, for future usage self . _cache_set ( 'find_pk' , qry ) else : # SQL string was successfully found in the cache, no need to use query builder # just build the required values list values = [ pk_value ] # execute SQL query and return the record with self . _db . cursor () as c : return c . fetchone ( qry , values , self . _record ) ( ... ) Accessing/Purging the Repository Cache If necessary, the cache used for the Repository SQL statements can be inspected or purged. The global variable is a rick_db.cache.StrCache instance, and can be accessed via rick_db.repository.query_cache : from rick_db.repository import query_cache # purge all cached items query_cache . purge ()","title":"Repositories"},{"location":"repository/#repositories","text":"Repositories provide useful functions for Record interact with the database. They are also a Repository pattern implementation, as hinted by the naming. These constructs are quite handy in the segregation of the data access layer and the business logic or service layer in multi-layer applications, but can also be quite useful as a shortcut for common read, write or delete operations. For more details on all the available methods, check the Repository class documentation.","title":"Repositories"},{"location":"repository/#declaring-repositories","text":"A Repository class can be instantiated directly, or declared via direct inheritance. Typically, direct inheritance has the advantage of resulting in a properly named class that can be easily extendable by adding methods. Regardless, there are usage scenarios where direct instantiation can be quite convenient: from rick_db import fieldmapper , Repository from rick_db.conn.pg import PgConnection @fieldmapper ( tablename = 'character' , pk = 'id_character' ) class Character : id = 'id_character' name = 'name' # declare a Repository class for Character using inheritance class CharacterRepository ( Repository ): def __init__ ( self , db ): # new constructor super () . __init__ ( db , Character ) db_cfg = { ... } conn = PgConnection ( ** db_cfg ) # instantiate declared repository class repo = CharacterRepository ( conn ) # insert some records repo . insert ( Character ( id = 1 , name = 'Sarah Connor' )) repo . insert ( Character ( id = 2 , name = 'John Connor' )) # read all records using the repo object for record in repo . fetch_all (): print ( record . name ) # alternative method, instantiate a repository directly repo = Repository ( conn , Character ) # use the repo object repo . insert ( Character ( id = 3 , name = 'T-1000' ))","title":"Declaring Repositories"},{"location":"repository/#extending-repositories","text":"Repository classes can also contain custom methods; This is the preferred approach when implementing additional database functionality. However, the methods should be designed to be stateless - they should not add or modify internal object attributes, nor depend on previous or future executions to carry their functions. By respecting this, Repository objects can be instantiated or reused in different contexts without any extra supervision: from rick_db import fieldmapper , Repository from rick_db.sql import Select , Literal @fieldmapper ( tablename = 'book' , pk = 'id_book' ) class Book : id = 'id_book' title = 'title' total_pages = 'total_pages' rating = 'rating' isbn = 'isbn' published = 'published_date' fk_publisher = 'fk_publisher' @fieldmapper ( tablename = 'author' , pk = 'id_author' ) class Author : id = 'id_author' first_name = 'first_name' middle_name = 'middle_name' last_name = 'last_name' @fieldmapper ( tablename = 'book_author' , pk = 'id_book_author' ) class BookAuthor : id = 'id_book_author' fk_book = 'fk_book' fk_author = 'fk_author' class AuthorRepository ( Repository ): def __init__ ( self , db ): super () . __init__ ( db , Author ) def calc_avg_rating ( self , id_author : int ): \"\"\" Calculate average rating for a given author :param id_author: author id :return: average rating, if any \"\"\" # generated query: # SELECT avg(rating) AS \"rating\" FROM \"book\" INNER JOIN \"book_author\" ON # \"book\".\"id_book\"=\"book_author\".\"fk_book\" WHERE (\"fk_author\" = %s) qry = Select ( self . _dialect ) . \\ from_ ( Book , { Literal ( \"avg( {} )\" . format ( Book . rating )): 'rating' }) . \\ join ( BookAuthor , BookAuthor . fk_book , Book , Book . id ) . \\ where ( BookAuthor . fk_author , '=' , id_author ) # retrieve result as list of type Book (to get the rating field) rset = self . fetch ( qry , cls = Book ) if len ( rset ) > 0 : return rset . pop ( 0 ) . rating return 0 def books ( self , id_author : int ) -> list [ Book ]: \"\"\" Retrieve all books for the given author :return: list[Book] \"\"\" qry = Select ( self . _dialect ) . \\ from_ ( Book ) . \\ join ( BookAuthor , BookAuthor . fk_book , Book , Book . id ) . \\ where ( BookAuthor . fk_author , '=' , id_author ) return self . fetch ( qry , cls = Book )","title":"Extending Repositories"},{"location":"repository/#advanced-usage","text":"While Repository objects are stateless from an operational perspective, there is actually an internal, thread-safe, global cache that is used to accelerate query building. Most Repository methods perform actions with SQL generated from the Query Builder , and these generated SQL statements can often be cached, due to the fact that any required values are passed in a separate structure. The cache operations within the Repository internal scope can be performed by using the protected methods _cache_get(key) and _cache_set(key, value) . The key parameter is a unique identifier for the specific query within the Repository, and will be internally concatenated with a database identifier, module and repository identifier. The typical usage scenario for cache interaction is: sql_string = _cache_get ( string_method_name ) if sql_string is None : sql_string , values = some_query . assemble () _cache_set ( string_method_name , sql_string ) else : values = list_of_required_values ( ... ) The implementation of the actual Registry.fetch_pk() provides a good example of the typical pattern usage of the cache manipulation methods: ( ... ) def fetch_pk ( self , pk_value ) -> Optional [ object ]: if self . _pk is None : raise RepositoryError ( \"find_pk(): missing primary key in Record %s \" % str ( type ( self . _record ))) # try to fetch a finished SQL string from the cache, ready to use # the cache key is the method name qry = self . _cache_get ( 'find_pk' ) if qry is None : # if no cache match, we need to build the SQL string using the query builder qry , values = self . select () . where ( self . _pk , '=' , pk_value ) . limit ( 1 ) . assemble () # ...and store the generated SQL string in the cache, for future usage self . _cache_set ( 'find_pk' , qry ) else : # SQL string was successfully found in the cache, no need to use query builder # just build the required values list values = [ pk_value ] # execute SQL query and return the record with self . _db . cursor () as c : return c . fetchone ( qry , values , self . _record ) ( ... )","title":"Advanced usage"},{"location":"repository/#accessingpurging-the-repository-cache","text":"If necessary, the cache used for the Repository SQL statements can be inspected or purged. The global variable is a rick_db.cache.StrCache instance, and can be accessed via rick_db.repository.query_cache : from rick_db.repository import query_cache # purge all cached items query_cache . purge ()","title":"Accessing/Purging the Repository Cache"},{"location":"classes/connection/","text":"Class rick_db.conn. Connection Base connection class for all database connections. @property Connection. profiler Get or set the current profiler. By default, a connection is initialized with a NullProfiler . Check Profiler for details on the return type. Connection. dialect() Retrieve connection dialect. Check SqlDialect for more details on the return type. Connection. begin() Starts a database transaction. Raises ConnectionError exception if autocommit is enabled or a transaction is already opened. Connection. commit() Finishes (commit) a database transaction. Connection. rollback() Cancels (rollback) a database transaction. Connection. transaction_status() Returns true if there is a started database transaction. Connection. cursor() Initializes and returns a new Cursor object. Connection. backend() Retrieve the underlying database connection object. Connection. migration_manager() Retrieve the appropriate MigrationManager object instance for the current connection. The MigrationManager object can be used to manage database migrations. Connection. metadata() Retrieve the appropriate Metadata object instance for the current connection. The Metadata object can be used to list internal database structures, such as tables, views, schemas and users. Connection. close() Close database connection. If there is a started database transaction, the transaction will be cancelled.","title":"Connection"},{"location":"classes/connection/#class-rick_dbconnconnection","text":"Base connection class for all database connections.","title":"Class rick_db.conn.Connection"},{"location":"classes/connection/#property-connectionprofiler","text":"Get or set the current profiler. By default, a connection is initialized with a NullProfiler . Check Profiler for details on the return type.","title":"@property Connection.profiler"},{"location":"classes/connection/#connectiondialect","text":"Retrieve connection dialect. Check SqlDialect for more details on the return type.","title":"Connection.dialect()"},{"location":"classes/connection/#connectionbegin","text":"Starts a database transaction. Raises ConnectionError exception if autocommit is enabled or a transaction is already opened.","title":"Connection.begin()"},{"location":"classes/connection/#connectioncommit","text":"Finishes (commit) a database transaction.","title":"Connection.commit()"},{"location":"classes/connection/#connectionrollback","text":"Cancels (rollback) a database transaction.","title":"Connection.rollback()"},{"location":"classes/connection/#connectiontransaction_status","text":"Returns true if there is a started database transaction.","title":"Connection.transaction_status()"},{"location":"classes/connection/#connectioncursor","text":"Initializes and returns a new Cursor object.","title":"Connection.cursor()"},{"location":"classes/connection/#connectionbackend","text":"Retrieve the underlying database connection object.","title":"Connection.backend()"},{"location":"classes/connection/#connectionmigration_manager","text":"Retrieve the appropriate MigrationManager object instance for the current connection. The MigrationManager object can be used to manage database migrations.","title":"Connection.migration_manager()"},{"location":"classes/connection/#connectionmetadata","text":"Retrieve the appropriate Metadata object instance for the current connection. The Metadata object can be used to list internal database structures, such as tables, views, schemas and users.","title":"Connection.metadata()"},{"location":"classes/connection/#connectionclose","text":"Close database connection. If there is a started database transaction, the transaction will be cancelled.","title":"Connection.close()"},{"location":"classes/cursor/","text":"Class rick_db.conn. Cursor Provides cursor logic in a database-independent fashion. Cursor. exec(qry: str, params=None, cls=None) Executes a SQL query specified in qry , with optional parameter list params . If cls , the specified class will be used to return objects via Object Mapper. The query may or may not return a result. Cursor. fetchone(qry: str, params=None, cls=None) Executes a SQL query specified in qry , with optional parameter list params and optional Object Mapper class defined via cls . It will return a single result or None Cursor. fetchall(qry: str, params=None, cls=None) Executes a SQL query specified in qry , with optional parameter list params and optional Object Mapper class defined via cls . It will always return a list. If no records are to be returned, the list will be empty. Cursor. close() Closes current cursor. Cursor. get_cursor() Retrieve underlying cursor object.","title":"Cursor"},{"location":"classes/cursor/#class-rick_dbconncursor","text":"Provides cursor logic in a database-independent fashion.","title":"Class rick_db.conn.Cursor"},{"location":"classes/cursor/#cursorexecqry-str-paramsnone-clsnone","text":"Executes a SQL query specified in qry , with optional parameter list params . If cls , the specified class will be used to return objects via Object Mapper. The query may or may not return a result.","title":"Cursor.exec(qry: str, params=None, cls=None)"},{"location":"classes/cursor/#cursorfetchoneqry-str-paramsnone-clsnone","text":"Executes a SQL query specified in qry , with optional parameter list params and optional Object Mapper class defined via cls . It will return a single result or None","title":"Cursor.fetchone(qry: str, params=None, cls=None)"},{"location":"classes/cursor/#cursorfetchallqry-str-paramsnone-clsnone","text":"Executes a SQL query specified in qry , with optional parameter list params and optional Object Mapper class defined via cls . It will always return a list. If no records are to be returned, the list will be empty.","title":"Cursor.fetchall(qry: str, params=None, cls=None)"},{"location":"classes/cursor/#cursorclose","text":"Closes current cursor.","title":"Cursor.close()"},{"location":"classes/cursor/#cursorget_cursor","text":"Retrieve underlying cursor object.","title":"Cursor.get_cursor()"},{"location":"classes/dbgrid/","text":"Class rick_db.sql. DbGrid Const DbGrid. SEARCH_NONE No search to be done. Const DbGrid. SEARCH_ANY Find matches with a different start or ending. Const DbGrid. SEARCH_START Find matches tha start with the expression. Const DbGrid. SEARCH_END Find matches tha end with the expression. DbGrid. __init__(repo: Repository, search_fields: list = None, search_type: int = None, case_sensitive=False) Initialize a DbGrid() object, using the Repository repo , a list of field names to be searched in search_fields , with the search type search_type (see SEARCH_NONE , SEARCH_ANY , SEARCH_START , SEARCH_END ), and if case_sensitive is True, a case-sensitive search is performed. DbGrid. default_query() : Build and returns the Select() object to be used internally for DbGrid. This method can be overridden for specific implementations. DbGrid. default_sort() : Build and returns the default sort dictionary. It can be overridden for specific implementations. DbGrid. run(qry: Select = None, search_text: str = None, match_fields: dict = None, limit: int = None, offset: int = None, sort_fields: dict = None) : Executes a query and returns a tuple with the total row count matching the query, and the records within the specified range defined by offset and limit , sorted by sort_fields . If qry is None, DbGrid.default_query() is used. If search_text is specified, a LIKE/ILIKE search is performed in the searchable fields defined in the constructor. match_fields is an optional {field_name:value} dict to perform exact match (field=value). Example: from rick_db import fieldmapper , Repository , DbGrid from rick_db.conn.pg import PgConnection @fieldmapper ( tablename = 'product' , pk = 'id_product' ) class Product : id = 'id_product' short_description = 'short_description' brand = 'brand_id' db_config = { \"dbname\" : \"products\" , \"user\" : \"someUser\" , \"password\" : \"somePassword\" , \"host\" : \"localhost\" , \"port\" : 5432 } # create connection conn = PgConnection ( ** db_config ) # create a repository repo = Repository ( conn , Product ) # create a grid grid = DbGrid ( repo , # repository to use [ Product . short_description ], # fields to perform text search DbGrid . SEARCH_ANY # type of search ) # retrieve first 10 results # total will have the total row count that matches the filters, without limit total , rows = grid . run ( search_text = 'bag' , match_fields = { Product . brand : 12 }, limit = 10 ) print ( \"total matches:\" , total ) for r in rows : print ( r . id , r . short_description ) # retrieve second page of results total , rows = grid . run ( search_text = 'bag' , match_fields = { Product . brand : 12 }, limit = 10 , offset = 10 ) for r in rows : print ( r . id , r . short_description )","title":"Class rick_db.sql.**DbGrid**"},{"location":"classes/dbgrid/#class-rick_dbsqldbgrid","text":"","title":"Class rick_db.sql.DbGrid"},{"location":"classes/dbgrid/#const-dbgridsearch_none","text":"No search to be done.","title":"Const DbGrid.SEARCH_NONE"},{"location":"classes/dbgrid/#const-dbgridsearch_any","text":"Find matches with a different start or ending.","title":"Const DbGrid.SEARCH_ANY"},{"location":"classes/dbgrid/#const-dbgridsearch_start","text":"Find matches tha start with the expression.","title":"Const DbGrid.SEARCH_START"},{"location":"classes/dbgrid/#const-dbgridsearch_end","text":"Find matches tha end with the expression.","title":"Const DbGrid.SEARCH_END"},{"location":"classes/dbgrid/#dbgrid__init__repo-repository-search_fields-list-none-search_type-int-none-case_sensitivefalse","text":"Initialize a DbGrid() object, using the Repository repo , a list of field names to be searched in search_fields , with the search type search_type (see SEARCH_NONE , SEARCH_ANY , SEARCH_START , SEARCH_END ), and if case_sensitive is True, a case-sensitive search is performed.","title":"DbGrid.__init__(repo: Repository, search_fields: list = None, search_type: int = None, case_sensitive=False)"},{"location":"classes/dbgrid/#dbgriddefault_query","text":"Build and returns the Select() object to be used internally for DbGrid. This method can be overridden for specific implementations.","title":"DbGrid.default_query():"},{"location":"classes/dbgrid/#dbgriddefault_sort","text":"Build and returns the default sort dictionary. It can be overridden for specific implementations.","title":"DbGrid.default_sort():"},{"location":"classes/dbgrid/#dbgridrunqry-select-none-search_text-str-none-match_fields-dict-none-limit-int-none-offset-int-none-sort_fields-dict-none","text":"Executes a query and returns a tuple with the total row count matching the query, and the records within the specified range defined by offset and limit , sorted by sort_fields . If qry is None, DbGrid.default_query() is used. If search_text is specified, a LIKE/ILIKE search is performed in the searchable fields defined in the constructor. match_fields is an optional {field_name:value} dict to perform exact match (field=value). Example: from rick_db import fieldmapper , Repository , DbGrid from rick_db.conn.pg import PgConnection @fieldmapper ( tablename = 'product' , pk = 'id_product' ) class Product : id = 'id_product' short_description = 'short_description' brand = 'brand_id' db_config = { \"dbname\" : \"products\" , \"user\" : \"someUser\" , \"password\" : \"somePassword\" , \"host\" : \"localhost\" , \"port\" : 5432 } # create connection conn = PgConnection ( ** db_config ) # create a repository repo = Repository ( conn , Product ) # create a grid grid = DbGrid ( repo , # repository to use [ Product . short_description ], # fields to perform text search DbGrid . SEARCH_ANY # type of search ) # retrieve first 10 results # total will have the total row count that matches the filters, without limit total , rows = grid . run ( search_text = 'bag' , match_fields = { Product . brand : 12 }, limit = 10 ) print ( \"total matches:\" , total ) for r in rows : print ( r . id , r . short_description ) # retrieve second page of results total , rows = grid . run ( search_text = 'bag' , match_fields = { Product . brand : 12 }, limit = 10 , offset = 10 ) for r in rows : print ( r . id , r . short_description )","title":"DbGrid.run(qry: Select = None, search_text: str = None, match_fields: dict = None, limit: int = None, offset: int = None, sort_fields: dict = None):"},{"location":"classes/delete/","text":"Class rick_db.sql. Delete Delete. __init__(dialect: SqlDialect = None) Initialize a Delete() object, using a database dialect . If no dialect is provided, a default dialect will be used. Check SqlDialect for more details. Delete. from_(table, schema=None): Defines the target table name and schema for deletion. table can be a Record object. Example: # simple DELETE example qry = Delete ( PgSqlDialect ()) . from_ ( 'table' ) # output: ('DELETE FROM \"table\"', []) print ( qry . assemble ()) # DELETE w/ Record object record = Publisher ( name = 'some publisher name' ) qry = Delete ( PgSqlDialect ()) . from_ ( record ) # output: ('DELETE FROM \"publisher\"', []) print ( qry . assemble ()) Delete. where(field, operator=None, value=None) Adds a WHERE clause to the DELETE clause. It requires a mandatory field name and an operator , and allows an optional value . Clauses generated by multiple calls to this method are concatenated with AND . Example: # DELETE WHERE... common usage qry = Delete ( PgSqlDialect ()) . from_ ( 'table' ) . \\ where ( 'id' , '=' , 7 ) # output: ('DELETE FROM \"table\" WHERE \"id\" = %s', [7]) print ( qry . assemble ()) # DELETE WHERE... no value qry = Delete ( PgSqlDialect ()) . from_ ( 'table' ) . \\ where ( 'id' , 'IS NOT NULL' ) # output: ('DELETE FROM \"table\" WHERE \"id\" IS NOT NULL', []) print ( qry . assemble ()) # DELETE WHERE... with multiple clauses qry = Delete ( PgSqlDialect ()) . from_ ( 'table' ) . \\ where ( 'id' , '=' , 7 ) . \\ where ( 'name' , 'ILIKE' , 'john%' ) # output: ('DELETE FROM \"table\" WHERE \"id\" = %s AND \"name\" ILIKE %s', [7, 'john%']) print ( qry . assemble ()) Delete. orwhere(field, operator=None, value=None) Adds a WHERE clause to the DELETE clause. It requires a mandatory field name and an operator , and allows an optional value . Clauses generated by multiple calls to this method are concatenated with OR . Example: qry = Delete ( PgSqlDialect ()) . from_ ( 'table' ) . \\ where ( 'id' , '=' , 7 ) . \\ orwhere ( 'name' , 'ILIKE' , 'john%' ) # output: ('DELETE FROM \"table\" WHERE \"id\" = %s OR \"name\" ILIKE %s', [7, 'john%']) print ( qry . assemble ()) Delete. assemble() Assembles DELETE SQL string and returns a tuple with (sql_string, list_of_values). If an error occurs, SqlError is raised. Example: # simple DELETE example qry = Delete ( PgSqlDialect ()) . from_ ( 'table' ) # output: ('DELETE FROM \"table\"', []) print ( qry . assemble ())","title":"Delete"},{"location":"classes/delete/#class-rick_dbsqldelete","text":"","title":"Class rick_db.sql.Delete"},{"location":"classes/delete/#delete__init__dialect-sqldialect-none","text":"Initialize a Delete() object, using a database dialect . If no dialect is provided, a default dialect will be used. Check SqlDialect for more details.","title":"Delete.__init__(dialect: SqlDialect = None)"},{"location":"classes/delete/#deletefrom_table-schemanone","text":"Defines the target table name and schema for deletion. table can be a Record object. Example: # simple DELETE example qry = Delete ( PgSqlDialect ()) . from_ ( 'table' ) # output: ('DELETE FROM \"table\"', []) print ( qry . assemble ()) # DELETE w/ Record object record = Publisher ( name = 'some publisher name' ) qry = Delete ( PgSqlDialect ()) . from_ ( record ) # output: ('DELETE FROM \"publisher\"', []) print ( qry . assemble ())","title":"Delete.from_(table, schema=None):"},{"location":"classes/delete/#deletewherefield-operatornone-valuenone","text":"Adds a WHERE clause to the DELETE clause. It requires a mandatory field name and an operator , and allows an optional value . Clauses generated by multiple calls to this method are concatenated with AND . Example: # DELETE WHERE... common usage qry = Delete ( PgSqlDialect ()) . from_ ( 'table' ) . \\ where ( 'id' , '=' , 7 ) # output: ('DELETE FROM \"table\" WHERE \"id\" = %s', [7]) print ( qry . assemble ()) # DELETE WHERE... no value qry = Delete ( PgSqlDialect ()) . from_ ( 'table' ) . \\ where ( 'id' , 'IS NOT NULL' ) # output: ('DELETE FROM \"table\" WHERE \"id\" IS NOT NULL', []) print ( qry . assemble ()) # DELETE WHERE... with multiple clauses qry = Delete ( PgSqlDialect ()) . from_ ( 'table' ) . \\ where ( 'id' , '=' , 7 ) . \\ where ( 'name' , 'ILIKE' , 'john%' ) # output: ('DELETE FROM \"table\" WHERE \"id\" = %s AND \"name\" ILIKE %s', [7, 'john%']) print ( qry . assemble ())","title":"Delete.where(field, operator=None, value=None)"},{"location":"classes/delete/#deleteorwherefield-operatornone-valuenone","text":"Adds a WHERE clause to the DELETE clause. It requires a mandatory field name and an operator , and allows an optional value . Clauses generated by multiple calls to this method are concatenated with OR . Example: qry = Delete ( PgSqlDialect ()) . from_ ( 'table' ) . \\ where ( 'id' , '=' , 7 ) . \\ orwhere ( 'name' , 'ILIKE' , 'john%' ) # output: ('DELETE FROM \"table\" WHERE \"id\" = %s OR \"name\" ILIKE %s', [7, 'john%']) print ( qry . assemble ())","title":"Delete.orwhere(field, operator=None, value=None)"},{"location":"classes/delete/#deleteassemble","text":"Assembles DELETE SQL string and returns a tuple with (sql_string, list_of_values). If an error occurs, SqlError is raised. Example: # simple DELETE example qry = Delete ( PgSqlDialect ()) . from_ ( 'table' ) # output: ('DELETE FROM \"table\"', []) print ( qry . assemble ())","title":"Delete.assemble()"},{"location":"classes/insert/","text":"Class rick_db.sql. Insert Insert. __init__(dialect: SqlDialect = None) Initialize a Insert() object, using a database dialect . If no dialect is provided, a default dialect will be used. Check SqlDialect for more details. Insert. into(table, schema=None) Defines the target table name and schema . If table is a Record object, it will also load fields and values from this object. Example: # simple INSERT example qry = Insert ( PgSqlDialect ()) . into ( 'table' ) . fields ([ 'field' ]) . values ([ 'value' ]) # output: ('INSERT INTO \"table\" (\"field\") VALUES (%s)', ['value']) print ( qry . assemble ()) # INSERT w/ Record object record = Publisher ( name = 'some publisher name' ) qry = Insert ( PgSqlDialect ()) . into ( record ) # output: ('INSERT INTO \"publisher\" (\"name\") VALUES (%s)', ['some publisher name']) print ( qry . assemble ()) Insert. fields(fields: list) Defines the field names for insertion. The length of fields list must match the list of provided values. Example: data = [ [ 'john' , 'connor' ], [ 'sarah' , 'connor' ] ] sql = [] qry = Insert ( PgSqlDialect ()) . into ( 'table' ) . fields ([ 'name' , 'surname' ]) for v in data : qry . values ( v ) sql . append ( qry . assemble ()) # output: # [('INSERT INTO \"table\" (\"name\", \"surname\") VALUES (%s, %s)', ['john', 'connor']), # ('INSERT INTO \"table\" (\"name\", \"surname\") VALUES (%s, %s)', ['sarah', 'connor'])] print ( sql ) Insert. values(values: Union[list, dict, object]) Define values to be inserted. This method can be called multiple times (see fields() for an example). If values is a dict, both fields and values are read from the provided dict. If values is a Record object, fields and values are read from the object. Example: # simple INSERT example qry = Insert ( PgSqlDialect ()) . into ( 'table' ) . fields ([ 'field' ]) . values ([ 'value' ]) # output: ('INSERT INTO \"table\" (\"field\") VALUES (%s)', ['value']) print ( qry . assemble ()) # INSERT w/ Record object record = Publisher ( name = 'some publisher name' ) qry = Insert ( PgSqlDialect ()) . into ( 'tablename' ) . values ( record ) # output: ('INSERT INTO \"tablename\" (\"name\") VALUES (%s)', ['some publisher name']) print ( qry . assemble ()) Insert. returning(fields) Adds a RETURNING clause to the INSERT . fields is a string or list of field names to be returned. Example: # simple INSERT example qry = Insert ( PgSqlDialect ()) . into ( 'tablename' ) . fields ([ 'field' ]) . values ([ 'value' ]) . returning ([ 'id' , 'field' ]) # output: ('INSERT INTO \"tablename\" (\"field\") VALUES (%s) RETURNING \"id\", \"field\"', ['value']) print ( qry . assemble ()) # INSERT w/ Record object record = Publisher ( name = 'some publisher name' ) qry = Insert ( PgSqlDialect ()) . into ( 'tablename' ) . values ( record ) . returning ( 'id' ) # output: ('INSERT INTO \"tablename\" (\"name\") VALUES (%s) RETURNING \"id\"', ['some publisher name']) print ( qry . assemble ()) Insert. get_values() Returns list of current values. Example: qry = Insert ( PgSqlDialect ()) . into ( 'tablename' ) . fields ([ 'field' ]) . values ([ 'value' ]) # output: ['value'] print ( qry . get_values ()) Insert. assemble() Assembles INSERT SQL string and returns a tuple with (sql_string, list_of_values). If an error occurs, SqlError is raised. Example: # simple INSERT example qry = Insert ( PgSqlDialect ()) . into ( 'table' ) . fields ([ 'field' ]) . values ([ 'value' ]) # output: ('INSERT INTO \"table\" (\"field\") VALUES (%s)', ['value']) print ( qry . assemble ())","title":"Insert"},{"location":"classes/insert/#class-rick_dbsqlinsert","text":"","title":"Class rick_db.sql.Insert"},{"location":"classes/insert/#insert__init__dialect-sqldialect-none","text":"Initialize a Insert() object, using a database dialect . If no dialect is provided, a default dialect will be used. Check SqlDialect for more details.","title":"Insert.__init__(dialect: SqlDialect = None)"},{"location":"classes/insert/#insertintotable-schemanone","text":"Defines the target table name and schema . If table is a Record object, it will also load fields and values from this object. Example: # simple INSERT example qry = Insert ( PgSqlDialect ()) . into ( 'table' ) . fields ([ 'field' ]) . values ([ 'value' ]) # output: ('INSERT INTO \"table\" (\"field\") VALUES (%s)', ['value']) print ( qry . assemble ()) # INSERT w/ Record object record = Publisher ( name = 'some publisher name' ) qry = Insert ( PgSqlDialect ()) . into ( record ) # output: ('INSERT INTO \"publisher\" (\"name\") VALUES (%s)', ['some publisher name']) print ( qry . assemble ())","title":"Insert.into(table, schema=None)"},{"location":"classes/insert/#insertfieldsfields-list","text":"Defines the field names for insertion. The length of fields list must match the list of provided values. Example: data = [ [ 'john' , 'connor' ], [ 'sarah' , 'connor' ] ] sql = [] qry = Insert ( PgSqlDialect ()) . into ( 'table' ) . fields ([ 'name' , 'surname' ]) for v in data : qry . values ( v ) sql . append ( qry . assemble ()) # output: # [('INSERT INTO \"table\" (\"name\", \"surname\") VALUES (%s, %s)', ['john', 'connor']), # ('INSERT INTO \"table\" (\"name\", \"surname\") VALUES (%s, %s)', ['sarah', 'connor'])] print ( sql )","title":"Insert.fields(fields: list)"},{"location":"classes/insert/#insertvaluesvalues-unionlist-dict-object","text":"Define values to be inserted. This method can be called multiple times (see fields() for an example). If values is a dict, both fields and values are read from the provided dict. If values is a Record object, fields and values are read from the object. Example: # simple INSERT example qry = Insert ( PgSqlDialect ()) . into ( 'table' ) . fields ([ 'field' ]) . values ([ 'value' ]) # output: ('INSERT INTO \"table\" (\"field\") VALUES (%s)', ['value']) print ( qry . assemble ()) # INSERT w/ Record object record = Publisher ( name = 'some publisher name' ) qry = Insert ( PgSqlDialect ()) . into ( 'tablename' ) . values ( record ) # output: ('INSERT INTO \"tablename\" (\"name\") VALUES (%s)', ['some publisher name']) print ( qry . assemble ())","title":"Insert.values(values: Union[list, dict, object])"},{"location":"classes/insert/#insertreturningfields","text":"Adds a RETURNING clause to the INSERT . fields is a string or list of field names to be returned. Example: # simple INSERT example qry = Insert ( PgSqlDialect ()) . into ( 'tablename' ) . fields ([ 'field' ]) . values ([ 'value' ]) . returning ([ 'id' , 'field' ]) # output: ('INSERT INTO \"tablename\" (\"field\") VALUES (%s) RETURNING \"id\", \"field\"', ['value']) print ( qry . assemble ()) # INSERT w/ Record object record = Publisher ( name = 'some publisher name' ) qry = Insert ( PgSqlDialect ()) . into ( 'tablename' ) . values ( record ) . returning ( 'id' ) # output: ('INSERT INTO \"tablename\" (\"name\") VALUES (%s) RETURNING \"id\"', ['some publisher name']) print ( qry . assemble ())","title":"Insert.returning(fields)"},{"location":"classes/insert/#insertget_values","text":"Returns list of current values. Example: qry = Insert ( PgSqlDialect ()) . into ( 'tablename' ) . fields ([ 'field' ]) . values ([ 'value' ]) # output: ['value'] print ( qry . get_values ())","title":"Insert.get_values()"},{"location":"classes/insert/#insertassemble","text":"Assembles INSERT SQL string and returns a tuple with (sql_string, list_of_values). If an error occurs, SqlError is raised. Example: # simple INSERT example qry = Insert ( PgSqlDialect ()) . into ( 'table' ) . fields ([ 'field' ]) . values ([ 'value' ]) # output: ('INSERT INTO \"table\" (\"field\") VALUES (%s)', ['value']) print ( qry . assemble ())","title":"Insert.assemble()"},{"location":"classes/literal/","text":"Class rick_db.sql. Literal Class used to encapsulate literal values Literal. __init__(literal) Create a Literal object with literal as content qry , _ = Select ( PgSqlDialect ()) . from_ ( 'table' , { Literal ( 'COUNT(*)' ): 'total' }) . assemble () # output: SELECT COUNT(*) AS \"total\" FROM \"table\" print ( qry )","title":"Literal"},{"location":"classes/literal/#class-rick_dbsqlliteral","text":"Class used to encapsulate literal values","title":"Class rick_db.sql.Literal"},{"location":"classes/literal/#literal__init__literal","text":"Create a Literal object with literal as content qry , _ = Select ( PgSqlDialect ()) . from_ ( 'table' , { Literal ( 'COUNT(*)' ): 'total' }) . assemble () # output: SELECT COUNT(*) AS \"total\" FROM \"table\" print ( qry )","title":"Literal.__init__(literal)"},{"location":"classes/profiler/","text":"rick_db.profiler Classes related to the SQL Profiler implementation. Class rick_db.profiler. Event Dataclass for a single event entry. Available properties: @dataclass class Event : timestamp : float query : str parameters : dict elapsed : float Class rick_db.profiler. EventCollection A list-based class to hold a collection of Event objects. EventCollection. filter_duration(duration: float) Retrieve a list of Event objects whose duration is bigger than or equal to duration . Class rick_db.profiler. Profiler Base profiler class. Implements an interface for the Profiler classes. Profiler. add_event(query: str, parameters: dict, duration: float) Create a new profiling event based on the passed query , parameters and duration , and add it to the internal event collection. Profiler. clear() Purge (clear) all stored events. Profiler. get_events() Return internal profiling event collection. Class rick_db.profiler. NullProfiler A Profiler -based class with dummy behaviour, to be used when no profiler is desired. Class rick_db.profiler. DefaultProfiler A Profiler -based class. Events are kept in-memory.","title":"Profiler"},{"location":"classes/profiler/#rick_dbprofiler","text":"Classes related to the SQL Profiler implementation.","title":"rick_db.profiler"},{"location":"classes/profiler/#class-rick_dbprofilerevent","text":"Dataclass for a single event entry. Available properties: @dataclass class Event : timestamp : float query : str parameters : dict elapsed : float","title":"Class rick_db.profiler.Event"},{"location":"classes/profiler/#class-rick_dbprofilereventcollection","text":"A list-based class to hold a collection of Event objects.","title":"Class rick_db.profiler.EventCollection"},{"location":"classes/profiler/#eventcollectionfilter_durationduration-float","text":"Retrieve a list of Event objects whose duration is bigger than or equal to duration .","title":"EventCollection.filter_duration(duration: float)"},{"location":"classes/profiler/#class-rick_dbprofilerprofiler","text":"Base profiler class. Implements an interface for the Profiler classes.","title":"Class rick_db.profiler.Profiler"},{"location":"classes/profiler/#profileradd_eventquery-str-parameters-dict-duration-float","text":"Create a new profiling event based on the passed query , parameters and duration , and add it to the internal event collection.","title":"Profiler.add_event(query: str, parameters: dict, duration: float)"},{"location":"classes/profiler/#profilerclear","text":"Purge (clear) all stored events.","title":"Profiler.clear()"},{"location":"classes/profiler/#profilerget_events","text":"Return internal profiling event collection.","title":"Profiler.get_events()"},{"location":"classes/profiler/#class-rick_dbprofilernullprofiler","text":"A Profiler -based class with dummy behaviour, to be used when no profiler is desired.","title":"Class rick_db.profiler.NullProfiler"},{"location":"classes/profiler/#class-rick_dbprofilerdefaultprofiler","text":"A Profiler -based class. Events are kept in-memory.","title":"Class rick_db.profiler.DefaultProfiler"},{"location":"classes/record/","text":"Class rick_db. Record The base Record class definition for all Object Mapper classes. Instead of inheritance, the Record class method attributes are copied to the final class, via attribute patching performed by the @fieldmapper decorator. Classes patched from Record inherit several useful methods, not only in the Object Mapper context, but also for general usage such as serialization/deserialization or type conversion. Record. load(**kwargs) Loads attribute values from the provided named parameters. Note: loading can also be done via constructor Example: from rick_db import fieldmapper @fieldmapper class MyRecord : id = 'id_record' name = 'name' # load values via constructor r1 = MyRecord ( id = 1 , name = 'Sarah Connor' ) # load values via load() r2 = MyRecord () . load ( id = 2 , name = 'John Connor' ) Record. fromrecord(record: dict) Load attribute values from a source dict. This method is used to load database row results into Record objects, and it is performance-sensitive - the attribute names aren't checked, and the values aren't actually copied, but referenced instead. Don't use this with mutable sources, as it will also change the Record object values. Record. has_pk() Returns True if a primary key definition ( pk field in the decorator) exists. Record. pk() Return the primary key value, if primary key is defined and a value is set. If a primary key is defined, but no value is present, raises AttributeError instead. Record. dbfields() Returns a list of the database field names, defined in the class declaration. Example: from rick_db import fieldmapper @fieldmapper class MyRecord : id = 'id_record' name = 'name' r1 = MyRecord ( id = 1 , name = 'Sarah Connor' ) # output: ['id_record', 'name'] print ( r1 . dbfields ()) Record. asdict() Converts the Record object to a dictionary and returns it. Attribute names are used as keys for existing values. Example: from rick_db import fieldmapper @fieldmapper class MyRecord : id = 'id_record' name = 'name' r1 = MyRecord ( id = 1 , name = 'Sarah Connor' ) # output: {'id': 1, 'name': 'Sarah Connor'} print ( r1 . asdict ()) Record. asrecord() Converts the Record object to a database-compatible dictionary and returns it. Field names are used as keys for existing values. Example: from rick_db import fieldmapper @fieldmapper class MyRecord : id = 'id_record' name = 'name' r1 = MyRecord ( id = 1 , name = 'Sarah Connor' ) # output: {'id_record': 1, 'name': 'Sarah Connor'} print ( r1 . asrecord ()) Record. fields() Alias function to Record.asdict().items() Example: from rick_db import fieldmapper @fieldmapper class MyRecord : id = 'id_record' name = 'name' r1 = MyRecord ( id = 1 , name = 'Sarah Connor' ) # output: ['id', 'name'] print ( r1 . fields ()) Record. values() Returns a list with stored values. Example: from rick_db import fieldmapper @fieldmapper class MyRecord : id = 'id_record' name = 'name' r1 = MyRecord ( id = 1 , name = 'Sarah Connor' ) # output: [1, 'Sarah Connor'] print ( r1 . values ())","title":"Record"},{"location":"classes/record/#class-rick_dbrecord","text":"The base Record class definition for all Object Mapper classes. Instead of inheritance, the Record class method attributes are copied to the final class, via attribute patching performed by the @fieldmapper decorator. Classes patched from Record inherit several useful methods, not only in the Object Mapper context, but also for general usage such as serialization/deserialization or type conversion.","title":"Class rick_db.Record"},{"location":"classes/record/#recordloadkwargs","text":"Loads attribute values from the provided named parameters. Note: loading can also be done via constructor Example: from rick_db import fieldmapper @fieldmapper class MyRecord : id = 'id_record' name = 'name' # load values via constructor r1 = MyRecord ( id = 1 , name = 'Sarah Connor' ) # load values via load() r2 = MyRecord () . load ( id = 2 , name = 'John Connor' )","title":"Record.load(**kwargs)"},{"location":"classes/record/#recordfromrecordrecord-dict","text":"Load attribute values from a source dict. This method is used to load database row results into Record objects, and it is performance-sensitive - the attribute names aren't checked, and the values aren't actually copied, but referenced instead. Don't use this with mutable sources, as it will also change the Record object values.","title":"Record.fromrecord(record: dict)"},{"location":"classes/record/#recordhas_pk","text":"Returns True if a primary key definition ( pk field in the decorator) exists.","title":"Record.has_pk()"},{"location":"classes/record/#recordpk","text":"Return the primary key value, if primary key is defined and a value is set. If a primary key is defined, but no value is present, raises AttributeError instead.","title":"Record.pk()"},{"location":"classes/record/#recorddbfields","text":"Returns a list of the database field names, defined in the class declaration. Example: from rick_db import fieldmapper @fieldmapper class MyRecord : id = 'id_record' name = 'name' r1 = MyRecord ( id = 1 , name = 'Sarah Connor' ) # output: ['id_record', 'name'] print ( r1 . dbfields ())","title":"Record.dbfields()"},{"location":"classes/record/#recordasdict","text":"Converts the Record object to a dictionary and returns it. Attribute names are used as keys for existing values. Example: from rick_db import fieldmapper @fieldmapper class MyRecord : id = 'id_record' name = 'name' r1 = MyRecord ( id = 1 , name = 'Sarah Connor' ) # output: {'id': 1, 'name': 'Sarah Connor'} print ( r1 . asdict ())","title":"Record.asdict()"},{"location":"classes/record/#recordasrecord","text":"Converts the Record object to a database-compatible dictionary and returns it. Field names are used as keys for existing values. Example: from rick_db import fieldmapper @fieldmapper class MyRecord : id = 'id_record' name = 'name' r1 = MyRecord ( id = 1 , name = 'Sarah Connor' ) # output: {'id_record': 1, 'name': 'Sarah Connor'} print ( r1 . asrecord ())","title":"Record.asrecord()"},{"location":"classes/record/#recordfields","text":"Alias function to Record.asdict().items() Example: from rick_db import fieldmapper @fieldmapper class MyRecord : id = 'id_record' name = 'name' r1 = MyRecord ( id = 1 , name = 'Sarah Connor' ) # output: ['id', 'name'] print ( r1 . fields ())","title":"Record.fields()"},{"location":"classes/record/#recordvalues","text":"Returns a list with stored values. Example: from rick_db import fieldmapper @fieldmapper class MyRecord : id = 'id_record' name = 'name' r1 = MyRecord ( id = 1 , name = 'Sarah Connor' ) # output: [1, 'Sarah Connor'] print ( r1 . values ())","title":"Record.values()"},{"location":"classes/repository/","text":"rick_db.Repository Class BaseRepository Internal top-level repository type. BaseRepository. backend() Return the internal Connection object. BaseRepository. dialect() Return the internal SqlDialect object used by the current connection. Class Repository(BaseRepository) The parent Repository class implementation, to be extended to implement specific Record repositories. Repository(db, record_type) Repository constructor. Receives a Connection object, db , and a Record class, record_type . The record_type class will provide the schema, table name and primary key information, and be used as a data type for methods that return records or collections. Repository. select(cols=None) Return a Select query builder instance for the current table, with an optional column list, cols . Repository. fetch_pk(pk_value) Attempt to read a record from the database by primary key value. It will return a record of the defined record_type on success, None if no record exists. Will raise RepositoryError if the record_type doesn't have a primary key definition. Example: ( ... ) # try to fetch record with pk=32 record = repo . fetch_pk ( 32 ) if record is not None : print ( \"record 32 exists\" ) Repository. fetch_one(qry: Select) Execute the qry Select statement and return a single record. If there is no record to return, will return None. Example: ( ... ) # fetch record if exists, else returns None user = repo . fetch_one ( repo . select () . where ( 'login' , '=' , 'gandalf@lotr' )) Repository. fetch(qry: Select, cls=None) Execute the qry Select statement and return a list of records. If there is nothing to return, will return and empty list. If a record class is specified in cls , this class will be used as record_type instead of the repository definition. This is useful to e.g. return join results that may return a different record type. Example: ( ... ) # fetch a list of records from a query for r in repo . fetch ( repo . select () . where ( 'name' , 'like' , 'gandalf%' )): print ( r . name ) Repository. fetch_raw(qry: Select) Execute the qry Select statement, but no record conversion is performed on the result - it will return the raw result dataset, a collection of dict-like structures, from the database connection. If there is nothing to return, will return and empty list. Example: ( ... ) # fetch a list of records from a query for r in repo . fetch_raw ( repo . select () . where ( 'name' , 'like' , 'gandalf%' )): print ( r [ 'name' ]) Repository. fetch_by_field(field, value, cols=None) Fetch a list of rows where field matches a value. An optional list of fields to be returned can be defined with cols . It returns a record list, or an empty list if no match is found. Example: ( ... ) # fetch records where login='gandalf@lotr' user = repo . fetch_by_field ( 'login' , 'gandalf@lotr' ) Repository. fetch_where(where_clauses: list, cols=None) Fetch a list of rows that match a list of WHERE clauses. If more than one clause is present, they are concatenated with AND . An optional list of fields to be returned can be defined with cols . It returns a record list, or an empty list if no match is found. A where clause is a list of tuples in the form of (field, operator, value) . See the example below for more details. Example: ( ... ) # fetch 'name' field from records matching a where clause for r in repo . fetch_where ([( 'name' , 'like' , 'gandalf%' ), ], cols = [ 'name' ]): print ( r . name ) Repository. fetch_all() Fetch all rows; equivalent to a SELECT * FROM . It returns a record list, or an empty list if the table is empty. Example: ( ... ) # fetch all records for r in repo . fetch_all (): print ( r . name ) Repository. fetch_all_ordered(col_name:str, order=Sql.SQL_ASC) Fetch all rows ordered by col_name and order direction; equivalent to a SELECT * FROM ORDER BY col_name order . It returns a record list, or an empty list if the table is empty. Example: ( ... ) # fetch all records for r in repo . fetch_all_ordered ( Character . name , Sql . SQL_DESC ): print ( r . name ) Repository. insert(record, cols=None) Insert a new record, optionally returning values. If the database does not support INSERT...RETURNING, cols can only have one entry, and the primary key will be returned regardless of the actual field name. Example: # insert a new record, returns None repo . insert ( Character ( name = \"John Connor\" )) # insert a new record, returns a record with id filled record = repo . insert ( Character ( name = \"Sarah Connor\" ), cols = [ 'id' ]) if record is not None : print ( record . id ) Repository. insert_pk(record) Insert a new record and return the primary key value, or None if database doesn't return any value. If no primary key is defined, will raise RepositoryError . Example: # insert a new record, returns a record with id filled id = repo . insert_pk ( Character ( name = \"John Connor\" )) if id is not None : print ( id ) Repository. delete_pk(pk_value) Remove a record identified by primary key value. If no primary key is defined, will raise RepositoryError . Example: # remove record #32 repo . delete_pk ( 32 ) Repository. delete_where(where_clauses: list) Remove records matching a list of WHERE clauses. If more than one clause is present, they are concatenated with AND . A where clause is a list of tuples in the form of (field, operator, value) . See the example below for more details. Example: # remove records WHERE name='gandalf' AND name='frodo' repo . delete_where ([( 'name' , '=' , 'gandalf' ), ( 'name' , '=' , 'frodo' )]) Repository. map_result_id(result: list) Transform a list of records into a dict indexed by primary key. If no primary key is defined, raises RepositoryError . Example: records = [ Character ( id = 1 , name = \"John Connor\" ), Character ( id = 2 , name = \"Sarah Connor\" ), ] # idx_records = { 1: Character(id=1, name=\"John Connor\"), 2: Character(id=2, name=\"Sarah Connor\") } idx_records = repo . map_result_id ( records ) Repository. valid_pk(pk_value) Returns True if a row exists with a primary key value matching pk_value , or False otherwise. If no primary key is defined, raises RepositoryError . Example: if repo . valid_pk ( 32 ): # record with pk=32 exists ( ... ) Repository. exec(sql, values=None, cls=None, useCls=True) Execute a raw SQL query. Query values must be passed via values . If useCls is True (default), returned database rows are converted to a list of records. If a Record class is specified via cls , it will be used instead of the internal record_type for record serialization. Example: for r in repo . exec ( 'SELECT * FROM characters WHERE id= %s ' , [ 32 ,]): print ( r . name ) Repository. exists(field, value, pk_to_skip) Returns True if a record exists WHERE field=value AND primary_key <> pk_to_skip . If no primary key is defined, raises RepositoryError . This is useful to check for uniqueness. Example: can_update = repo . exists ( 'login' , 'gandalf@lotr' , 32 ) if not can_update : print ( \"A record already exists with the same login value\" ) Repository. update(record, pk_value=None) Updates a record on the database by primary key. If record contains a primary key value, it will be used instead of pk_value . If record doesn't contain a primary key value, pk_value is required. Example: record = Character ( name = 'T-1000' ) repo . update ( record , 2 ) Repository. update_where(record, where_list: list) Updates a record matching a list of WHERE clauses defined by where_list . If more than one clause is present, they are concatenated with AND . A where clause is a list of tuples in the form of (field, value) or (field, operator, value) . See the example below for more details. Example: record = Character ( name = 'T-1000' ) repo . update ( record , [( 'name' , 'John Connor' )]) Repository. count() Returns the number of records in the table. Equivalent of SELECT COUNT(1) FROM . Example: record = Character ( name = 'T-1000' ) total = repo . count () Repository. count_where(where_list: list) Returns the number of records matching a list of WHERE clauses. If more than one clause is present, they are concatenated with AND . A where clause is a list of tuples in the form of (field, value) or (field, operator, value) . See the example below for more details. Example: total_johns = repo . count_where ([( 'name' , 'like' , 'John %' ), ]) Repository. list(qry: Select, limit=None, offset=None, cls=None) Performs a query qry , with an optional offset and limit , and returns a tuple with the total row count for the query (without offset and limit applied), and a list of rows returned from the execution of the query with offset and limit. If a Record class cls is specified, it will be used instead of the predefined record_type . Note: The original qry object is left intact. Example: total_records , recordset = repo . list ( repo . Select (), 10 )","title":"Repository"},{"location":"classes/repository/#rick_dbrepository","text":"","title":"rick_db.Repository"},{"location":"classes/repository/#class-baserepository","text":"Internal top-level repository type.","title":"Class BaseRepository"},{"location":"classes/repository/#baserepositorybackend","text":"Return the internal Connection object.","title":"BaseRepository.backend()"},{"location":"classes/repository/#baserepositorydialect","text":"Return the internal SqlDialect object used by the current connection.","title":"BaseRepository.dialect()"},{"location":"classes/repository/#class-repositorybaserepository","text":"The parent Repository class implementation, to be extended to implement specific Record repositories.","title":"Class Repository(BaseRepository)"},{"location":"classes/repository/#repositorydb-record_type","text":"Repository constructor. Receives a Connection object, db , and a Record class, record_type . The record_type class will provide the schema, table name and primary key information, and be used as a data type for methods that return records or collections.","title":"Repository(db, record_type)"},{"location":"classes/repository/#repositoryselectcolsnone","text":"Return a Select query builder instance for the current table, with an optional column list, cols .","title":"Repository.select(cols=None)"},{"location":"classes/repository/#repositoryfetch_pkpk_value","text":"Attempt to read a record from the database by primary key value. It will return a record of the defined record_type on success, None if no record exists. Will raise RepositoryError if the record_type doesn't have a primary key definition. Example: ( ... ) # try to fetch record with pk=32 record = repo . fetch_pk ( 32 ) if record is not None : print ( \"record 32 exists\" )","title":"Repository.fetch_pk(pk_value)"},{"location":"classes/repository/#repositoryfetch_oneqry-select","text":"Execute the qry Select statement and return a single record. If there is no record to return, will return None. Example: ( ... ) # fetch record if exists, else returns None user = repo . fetch_one ( repo . select () . where ( 'login' , '=' , 'gandalf@lotr' ))","title":"Repository.fetch_one(qry: Select)"},{"location":"classes/repository/#repositoryfetchqry-select-clsnone","text":"Execute the qry Select statement and return a list of records. If there is nothing to return, will return and empty list. If a record class is specified in cls , this class will be used as record_type instead of the repository definition. This is useful to e.g. return join results that may return a different record type. Example: ( ... ) # fetch a list of records from a query for r in repo . fetch ( repo . select () . where ( 'name' , 'like' , 'gandalf%' )): print ( r . name )","title":"Repository.fetch(qry: Select, cls=None)"},{"location":"classes/repository/#repositoryfetch_rawqry-select","text":"Execute the qry Select statement, but no record conversion is performed on the result - it will return the raw result dataset, a collection of dict-like structures, from the database connection. If there is nothing to return, will return and empty list. Example: ( ... ) # fetch a list of records from a query for r in repo . fetch_raw ( repo . select () . where ( 'name' , 'like' , 'gandalf%' )): print ( r [ 'name' ])","title":"Repository.fetch_raw(qry: Select)"},{"location":"classes/repository/#repositoryfetch_by_fieldfield-value-colsnone","text":"Fetch a list of rows where field matches a value. An optional list of fields to be returned can be defined with cols . It returns a record list, or an empty list if no match is found. Example: ( ... ) # fetch records where login='gandalf@lotr' user = repo . fetch_by_field ( 'login' , 'gandalf@lotr' )","title":"Repository.fetch_by_field(field, value, cols=None)"},{"location":"classes/repository/#repositoryfetch_wherewhere_clauses-list-colsnone","text":"Fetch a list of rows that match a list of WHERE clauses. If more than one clause is present, they are concatenated with AND . An optional list of fields to be returned can be defined with cols . It returns a record list, or an empty list if no match is found. A where clause is a list of tuples in the form of (field, operator, value) . See the example below for more details. Example: ( ... ) # fetch 'name' field from records matching a where clause for r in repo . fetch_where ([( 'name' , 'like' , 'gandalf%' ), ], cols = [ 'name' ]): print ( r . name )","title":"Repository.fetch_where(where_clauses: list, cols=None)"},{"location":"classes/repository/#repositoryfetch_all","text":"Fetch all rows; equivalent to a SELECT * FROM . It returns a record list, or an empty list if the table is empty. Example: ( ... ) # fetch all records for r in repo . fetch_all (): print ( r . name )","title":"Repository.fetch_all()"},{"location":"classes/repository/#repositoryfetch_all_orderedcol_namestr-ordersqlsql_asc","text":"Fetch all rows ordered by col_name and order direction; equivalent to a SELECT * FROM ORDER BY col_name order . It returns a record list, or an empty list if the table is empty. Example: ( ... ) # fetch all records for r in repo . fetch_all_ordered ( Character . name , Sql . SQL_DESC ): print ( r . name )","title":"Repository.fetch_all_ordered(col_name:str, order=Sql.SQL_ASC)"},{"location":"classes/repository/#repositoryinsertrecord-colsnone","text":"Insert a new record, optionally returning values. If the database does not support INSERT...RETURNING, cols can only have one entry, and the primary key will be returned regardless of the actual field name. Example: # insert a new record, returns None repo . insert ( Character ( name = \"John Connor\" )) # insert a new record, returns a record with id filled record = repo . insert ( Character ( name = \"Sarah Connor\" ), cols = [ 'id' ]) if record is not None : print ( record . id )","title":"Repository.insert(record, cols=None)"},{"location":"classes/repository/#repositoryinsert_pkrecord","text":"Insert a new record and return the primary key value, or None if database doesn't return any value. If no primary key is defined, will raise RepositoryError . Example: # insert a new record, returns a record with id filled id = repo . insert_pk ( Character ( name = \"John Connor\" )) if id is not None : print ( id )","title":"Repository.insert_pk(record)"},{"location":"classes/repository/#repositorydelete_pkpk_value","text":"Remove a record identified by primary key value. If no primary key is defined, will raise RepositoryError . Example: # remove record #32 repo . delete_pk ( 32 )","title":"Repository.delete_pk(pk_value)"},{"location":"classes/repository/#repositorydelete_wherewhere_clauses-list","text":"Remove records matching a list of WHERE clauses. If more than one clause is present, they are concatenated with AND . A where clause is a list of tuples in the form of (field, operator, value) . See the example below for more details. Example: # remove records WHERE name='gandalf' AND name='frodo' repo . delete_where ([( 'name' , '=' , 'gandalf' ), ( 'name' , '=' , 'frodo' )])","title":"Repository.delete_where(where_clauses: list)"},{"location":"classes/repository/#repositorymap_result_idresult-list","text":"Transform a list of records into a dict indexed by primary key. If no primary key is defined, raises RepositoryError . Example: records = [ Character ( id = 1 , name = \"John Connor\" ), Character ( id = 2 , name = \"Sarah Connor\" ), ] # idx_records = { 1: Character(id=1, name=\"John Connor\"), 2: Character(id=2, name=\"Sarah Connor\") } idx_records = repo . map_result_id ( records )","title":"Repository.map_result_id(result: list)"},{"location":"classes/repository/#repositoryvalid_pkpk_value","text":"Returns True if a row exists with a primary key value matching pk_value , or False otherwise. If no primary key is defined, raises RepositoryError . Example: if repo . valid_pk ( 32 ): # record with pk=32 exists ( ... )","title":"Repository.valid_pk(pk_value)"},{"location":"classes/repository/#repositoryexecsql-valuesnone-clsnone-useclstrue","text":"Execute a raw SQL query. Query values must be passed via values . If useCls is True (default), returned database rows are converted to a list of records. If a Record class is specified via cls , it will be used instead of the internal record_type for record serialization. Example: for r in repo . exec ( 'SELECT * FROM characters WHERE id= %s ' , [ 32 ,]): print ( r . name )","title":"Repository.exec(sql, values=None, cls=None, useCls=True)"},{"location":"classes/repository/#repositoryexistsfield-value-pk_to_skip","text":"Returns True if a record exists WHERE field=value AND primary_key <> pk_to_skip . If no primary key is defined, raises RepositoryError . This is useful to check for uniqueness. Example: can_update = repo . exists ( 'login' , 'gandalf@lotr' , 32 ) if not can_update : print ( \"A record already exists with the same login value\" )","title":"Repository.exists(field, value, pk_to_skip)"},{"location":"classes/repository/#repositoryupdaterecord-pk_valuenone","text":"Updates a record on the database by primary key. If record contains a primary key value, it will be used instead of pk_value . If record doesn't contain a primary key value, pk_value is required. Example: record = Character ( name = 'T-1000' ) repo . update ( record , 2 )","title":"Repository.update(record, pk_value=None)"},{"location":"classes/repository/#repositoryupdate_whererecord-where_list-list","text":"Updates a record matching a list of WHERE clauses defined by where_list . If more than one clause is present, they are concatenated with AND . A where clause is a list of tuples in the form of (field, value) or (field, operator, value) . See the example below for more details. Example: record = Character ( name = 'T-1000' ) repo . update ( record , [( 'name' , 'John Connor' )])","title":"Repository.update_where(record, where_list: list)"},{"location":"classes/repository/#repositorycount","text":"Returns the number of records in the table. Equivalent of SELECT COUNT(1) FROM . Example: record = Character ( name = 'T-1000' ) total = repo . count ()","title":"Repository.count()"},{"location":"classes/repository/#repositorycount_wherewhere_list-list","text":"Returns the number of records matching a list of WHERE clauses. If more than one clause is present, they are concatenated with AND . A where clause is a list of tuples in the form of (field, value) or (field, operator, value) . See the example below for more details. Example: total_johns = repo . count_where ([( 'name' , 'like' , 'John %' ), ])","title":"Repository.count_where(where_list: list)"},{"location":"classes/repository/#repositorylistqry-select-limitnone-offsetnone-clsnone","text":"Performs a query qry , with an optional offset and limit , and returns a tuple with the total row count for the query (without offset and limit applied), and a list of rows returned from the execution of the query with offset and limit. If a Record class cls is specified, it will be used instead of the predefined record_type . Note: The original qry object is left intact. Example: total_records , recordset = repo . list ( repo . Select (), 10 )","title":"Repository.list(qry: Select, limit=None, offset=None, cls=None)"},{"location":"classes/select/","text":"Class rick_db.sql. Select Select. __init__(dialect: SqlDialect = None) Initialize a Select() object, using a database dialect . If no dialect is provided, a default dialect will be used. Check SqlDialect for more details. Select. distinct(flag=True) Enables or disables the usage of DISTINCT clause, based on the state of flag . The provided DISTINCT functionality is limited - it doesn't support wildcard or specific columns. Example: sql , _ = Select ( PgSqlDialect ()) . from_ ( 'test_table' , 'field' ) . distinct () . assemble () # output: SELECT DISTINCT \"field\" FROM \"test_table\" print ( sql ) Select. expr(cols=None) Adds an anonymous expression to the SELECT statement. It can only be used once in a query. Possible cols values can be: - string with contents - a list of strings with contents - a Literal object - a list of Literal objects Example: qry , _ = Select ( PgSqlDialect ()) . expr ( '1' ) . assemble () # output: SELECT 1 print ( qry ) qry , _ = Select ( PgSqlDialect ()) . expr ([ '1' , '2' , '3' ]) . assemble () # output: SELECT 1,2,3 print ( qry ) qry , _ = Select ( PgSqlDialect ()) . expr ({ Literal ( \"NEXTVAL('some_sequence_name')\" ): \"seq_next\" }) . assemble () # output: SELECT NEXTVAL('some_sequence_name') AS \"seq_next\" print ( qry ) Select. from_(table, cols=None, schema=None) Adds a FROM clause to the query. The table is a table identifier expression, cols is a column identifier and schema specifies an optional schema for table . Example: qry , _ = Select ( PgSqlDialect ()) . from_ ( \"foo\" ) . assemble () # output: SELECT \"foo\".* FROM \"foo\" print ( qry ) qry , _ = Select ( PgSqlDialect ()) . from_ ( \"foo\" , None , \"public\" ) . assemble () # output: SELECT \"foo\".* FROM \"public\".\"foo\" print ( qry ) qry , _ = Select ( PgSqlDialect ()) . from_ ({ \"foo\" : \"bar\" }) . assemble () # output: SELECT \"bar\".* FROM \"foo\" AS \"bar\" print ( qry ) qry , _ = Select ( PgSqlDialect ()) . from_ ( \"foo\" , { \"field1\" : None , \"field2\" : \"alias\" }) . assemble () # output: SELECT \"field1\",\"field2\" AS \"alias\" FROM \"foo\" print ( qry ) qry , _ = Select ( PgSqlDialect ()) . from_ ( \"foo\" , \"field\" ) . assemble () # output: SELECT \"field\" FROM \"foo\" print ( qry ) qry , _ = Select ( PgSqlDialect ()) . from_ ( \"foo\" , [ \"field1\" , \"field2\" ]) . assemble () # output: SELECT \"field1\", \"field2\" FROM \"foo\" print ( qry ) qry , _ = Select ( PgSqlDialect ()) . from_ ({ \"foo\" : \"bar\" }, [ \"field1\" ]) . assemble () # output: SELECT \"bar.field1\" FROM \"foo\" AS \"bar\" print ( qry ) qry , _ = Select ( PgSqlDialect ()) . from_ ( record_class_or_object , [ \"field1\" ]) . assemble () # output: SELECT \"field1\" FROM \"<object_table_name>\" print ( qry ) qry , _ = Select ( PgSqlDialect ()) . from_ ({ record_class_or_object : \"bar\" }, [ \"field1\" ]) . assemble () # output: SELECT \"bar\".\"field1\" FROM \"<object_table_name>\" AS \"bar\" print ( qry ) Table identifier A table identifier can be a string, Record class or object, a {'table':'alias'} dict, or a { Record class or object:'alias'} dict. Column identifier A column identifier can be None ('*' will be used), a string with a field name, a list of field names, a {'field': 'alias'} dict, a {'field': None, 'other_field':'alias} dict, or a [{'field': 'alias'}, 'field', ] list of mixed string and dict values. Select. limit(limit: int, offset: int = None) Adds an LIMIT / OFFSET clause. Example: qry , _ = Select ( PgSqlDialect ()) . from_ ( \"foo\" ) . limit ( 10 ) . assemble () # output: SELECT \"foo\".* FROM \"foo\" LIMIT 10 print ( qry ) qry , _ = Select ( PgSqlDialect ()) . from_ ( \"foo\" ) . limit ( 10 , 5 ) . assemble () # output: SELECT \"foo\".* FROM \"foo\" LIMIT 10 OFFSET 5 print ( qry ) Select. page(page: int, page_rows: int) Helper to add LIMIT / OFFSET clause for pagination purposes. page specifies which page to fetch, starting from 1, and page rows specifies the number of rows per page Example: qry , _ = Select ( PgSqlDialect ()) . from_ ( \"foo\" ) . page ( 1 , 10 ) . assemble () # output: SELECT \"foo\".* FROM \"foo\" LIMIT 10 OFFSET 0 print ( qry ) qry , _ = Select ( PgSqlDialect ()) . from_ ( \"foo\" ) . page ( 10 , 10 ) . assemble () # output: SELECT \"foo\".* FROM \"foo\" LIMIT 10 OFFSET 10 print ( qry ) Select. for_update(flag: bool = True) Adds a FOR UPDATE clause if flag is True. Select. order(fields, order=Sql.SQL_ASC) Adds an ORDER BY clause with the specified fields . order is ASC by default. Example: qry , _ = Select ( PgSqlDialect ()) . from_ ( \"foo\" ) . order ( 'id' ) . assemble () # output: SELECT \"foo\".* FROM \"foo\" ORDER BY id ASC print ( qry ) qry , _ = Select ( PgSqlDialect ()) . from_ ( \"foo\" ) . order ([ 'id' , 'name' ], Select . ORDER_DESC ) . assemble () # output: SELECT \"foo\".* FROM \"foo\" ORDER BY id DESC, a DESC print ( qry ) Select. where(field, operator=None, value=None) Adds a WHERE clause. Multiple calls to this method are concatenated with AND . field must contain a valid Field identifier , operator can contain either a string with an operator or a Literal object, and finally value , if specified, is the operand. Example: # showcase multiple WHERE... AND clauses qry = Select ( PgSqlDialect ()) . from_ ( \"foo\" ) . \\ where ( 'id' , '>' , 5 ) . \\ where ( 'name' , 'IS NOT NULL' ) . \\ where ( 'cp' , 'IN' , [ 100 , 200 , 300 , 400 ]) # output: ('SELECT \"foo\".* FROM \"foo\" WHERE (\"id\" > %s) AND (\"name\" IS NOT NULL) AND (\"cp\" IN %s)', [5, [100, 200, 300, 400]]) print ( qry . assemble ()) Field identifier A field identifier can be a string with a field name, a Literal object, a {'table':'field'} dict or { :'field'} dict. Select. where_and() Starts a parenthesis AND block within the WHERE clause, allowing the build of complex WHERE clauses. This method is nestable, allowing the composition of multi-level parenthesis blocks. All declared blocks need to be explicitly closed with where_end() . Example: # showcase WHERE clause AND ( clause OR clause) qry = Select ( PgSqlDialect ()) . from_ ( \"foo\" ) . \\ where ( 'id' , '>' , 5 ) . \\ where_and () . \\ where ( 'name' , 'IS NOT NULL' ) . \\ orwhere ( 'cp' , 'IN' , [ 100 , 200 , 300 , 400 ]) . \\ where_end () # output: ('SELECT \"foo\".* FROM \"foo\" WHERE (\"id\" > %s) AND ( (\"name\" IS NOT NULL) OR (\"cp\" IN %s) )', [5, [100, 200, 300, 400]]) print ( qry . assemble ()) Select. where_or() Starts a parenthesis OR block within the WHERE clause, allowing the build of complex WHERE clauses. This method is nestable, allowing the composition of multi-level parenthesis blocks. All declared blocks need to be explicitly closed with where_end() . Example: # showcase WHERE clause OR ( clause AND clause) qry = Select ( PgSqlDialect ()) . from_ ( \"foo\" ) . \\ where ( 'id' , '>' , 5 ) . \\ where_or () . \\ where ( 'name' , 'IS NOT NULL' ) . \\ where ( 'cp' , 'IN' , [ 100 , 200 , 300 , 400 ]) . \\ where_end () # output: ('SELECT \"foo\".* FROM \"foo\" WHERE (\"id\" > %s) OR ( (\"name\" IS NOT NULL) AND (\"cp\" IN %s) )', [5, [100, 200, 300, 400]]) print ( qry . assemble ()) Select. where_end() Closes a parenthesis AND or OR block. Please note, to allow the most freedom when building queries, Validation of open/closed blocks is only performed on assemble() . If the internal open block counter is not 0 on assemble() , a RuntimeError is raised. See where_and() and where_or() for usage examples. Select. orwhere(field, operator=None, value=None) Adds a WHERE clause to be concatenated with OR . field must contain a valid Field identifier , operator can contain either a string with an operator or a Literal object, and finally value , if specified, is the operand. Example: # showcase multiple WHERE... AND clauses qry = Select ( PgSqlDialect ()) . from_ ( \"foo\" ) . \\ where ( 'id' , '>' , 5 ) . \\ orwhere ( 'name' , 'IS NOT NULL' ) . \\ where ( 'cp' , 'IN' , [ 100 , 200 , 300 , 400 ]) # output: ('SELECT \"foo\".* FROM \"foo\" WHERE (\"id\" > %s) OR (\"name\" IS NOT NULL) AND (\"cp\" IN %s)', [5, [100, 200, 300, 400]]) print ( qry . assemble ()) Select. group(fields) Adds a GROUP BY clause. fields can be either a field name, a list of field names, a Literal or a list of Literal objects. Example: qry , _ = Select ( PgSqlDialect ()) . from_ ( \"foo\" ) . group ([ 'age' , 'name' ]) . assemble () # output: SELECT \"foo\".* FROM \"foo\" GROUP BY \"age\", \"name\" print ( qry ) Select. having(field, operator=None, value=None, schema=None) Adds a HAVING clause. field can be a field name, a Literal , a {'table':'field'} dict or a { Record class or object:'field'} dict. Example: # HAVING Literal condition qry , _ = Select ( PgSqlDialect ()) . from_ ( \"foo\" ) . having ( Literal ( 'COUNT(field) > 5' )) . assemble () # output: SELECT \"foo\".* FROM \"foo\" HAVING (COUNT(field) > 5) print ( qry ) # HAVING condition qry , _ = Select ( PgSqlDialect ()) . from_ ( \"foo\" ) . having ( 'field' , '>' , 5 , 'public' ) . assemble () # output: SELECT \"foo\".* FROM \"foo\" HAVING (\"field\" > %s) print ( qry ) # HAVING with schema qry , _ = Select ( PgSqlDialect ()) . from_ ( \"foo\" ) . having ({ 'some_table' : 'field' }, '>' , 5 , 'public' ) . assemble () # output: SELECT \"foo\".* FROM \"foo\" HAVING (\"public\".\"some_table\".\"field\" > %s) print ( qry ) Select. union(queries: list, union_type: str = Sql.SQL_UNION) Performs an UNION of two or more Select() or string queries. union_type can be either Sql.SQL_UNION or Sql.SQL_UNION_ALL . Example: qry , _ = Select ( PgSqlDialect ()) . union ([ Select () . from_ ( 'table' ), Select () . from_ ( 'other_table' )]) . \\ assemble () # output: SELECT \"table\".* FROM \"table\" UNION SELECT \"other_table\".* FROM \"other_table\" print ( qry ) Select. join(table, field, expr_table=None, expr_field=None, operator=None, cols=None, schema=None, expr_schema=None) Adds a INNER JOIN clause. The parameters must conform with join() parameters . Example: # simple example qry , _ = Select ( PgSqlDialect ()) . from_ ( 'some_table' ) . \\ join ( 'other_table' , 'fk_some_table' , 'some_table' , 'id' ) . \\ assemble () # output: SELECT \"some_table\".* FROM \"some_table\" INNER JOIN \"other_table\" ON \"some_table\".\"id\"=\"other_table\".\"fk_some_table\" print ( qry ) # example w/ destination table aliasing qry , _ = Select ( PgSqlDialect ()) . from_ ( 'some_table' ) . \\ join ({ 'other_table' : 't2' }, 'fk_some_table' , 'some_table' , 'id' ) . \\ assemble () # output: SELECT \"some_table\".* FROM \"some_table\" INNER JOIN \"other_table\" AS \"t2\" ON \"some_table\".\"id\"=\"t2\".\"fk_some_table\" print ( qry ) # example w/ source table aliasing qry , _ = Select ( PgSqlDialect ()) . from_ ({ 'some_table' : 't1' }) . \\ join ({ 'other_table' : 't2' }, 'fk_some_table' , { 'some_table' : 't1' }, 'id' ) . \\ assemble () # output: SELECT \"t1\".* FROM \"some_table\" AS \"t1\" INNER JOIN \"other_table\" AS \"t2\" ON \"t1\".\"id\"=\"t2\".\"fk_some_table\" print ( qry ) # example w/ Record objects and extra SELECT column w/alias qry , _ = Select ( PgSqlDialect ()) . from_ ( Book ) . \\ join ( Publisher , Publisher . id , Book , Book . fk_publisher , '=' , [{ Publisher . name : 'publisher_name' }]) . assemble () # output: SELECT \"book\".*,\"publisher\".\"name\" AS \"publisher_name\" FROM \"book\" INNER JOIN \"publisher\" ON \"book\".\"fk_publisher\"=\"publisher\".\"id_publisher\" print ( qry ) join() parameters table identifies the table to JOIN to, and must be a valid Table identifier expression. field is the field name or expression to join on table . expr_table identifies the existing table to JOIN from, and must be a valid Table identifier . expr_field is the field name or expression to JOIN on the existing table. operator is an optional join operator - if omitted, '=' is used. cols is an optional list of column names to add to the SELECT statement. schema and expr_schema can provide optional schema naming for both table to JOIN to and table to JOIN from. Select. join_inner(table, field, expr_table=None, expr_field=None, operator=None, cols=None, schema=None, expr_schema=None) Alias to join() . Select. join_left(table, field, expr_table=None, expr_field=None, operator=None, cols=None, schema=None, expr_schema=None) Adds a LEFT JOIN clause. The parameters must conform with join() parameters . Example: # simple example qry , _ = Select ( PgSqlDialect ()) . from_ ( 'some_table' ) . \\ join_left ( 'other_table' , 'fk_some_table' , 'some_table' , 'id' ) . \\ assemble () # output: SELECT \"some_table\".* FROM \"some_table\" LEFT JOIN \"other_table\" ON \"some_table\".\"id\"=\"other_table\".\"fk_some_table\" print ( qry ) # example w/ destination table aliasing qry , _ = Select ( PgSqlDialect ()) . from_ ( 'some_table' ) . \\ join_left ({ 'other_table' : 't2' }, 'fk_some_table' , 'some_table' , 'id' ) . \\ assemble () # output: SELECT \"some_table\".* FROM \"some_table\" LEFT JOIN \"other_table\" AS \"t2\" ON \"some_table\".\"id\"=\"t2\".\"fk_some_table\" print ( qry ) # example w/ source table aliasing qry , _ = Select ( PgSqlDialect ()) . from_ ({ 'some_table' : 't1' }) . \\ join_left ({ 'other_table' : 't2' }, 'fk_some_table' , { 'some_table' : 't1' }, 'id' ) . \\ assemble () # output: SELECT \"t1\".* FROM \"some_table\" AS \"t1\" LEFT JOIN \"other_table\" AS \"t2\" ON \"t1\".\"id\"=\"t2\".\"fk_some_table\" print ( qry ) # example w/ Record objects and extra SELECT column w/alias qry , _ = Select ( PgSqlDialect ()) . from_ ( Book ) . \\ join_left ( Publisher , Publisher . id , Book , Book . fk_publisher , '=' , [{ Publisher . name : 'publisher_name' }]) . assemble () # output: SELECT \"book\".*,\"publisher\".\"name\" AS \"publisher_name\" FROM \"book\" LEFT JOIN \"publisher\" ON \"book\".\"fk_publisher\"=\"publisher\".\"id_publisher\" print ( qry ) Select. join_right(table, field, expr_table=None, expr_field=None, operator=None, cols=None, schema=None, expr_schema=None) Adds a RIGHT JOIN clause. The parameters must conform with join() parameters . Example: # simple example qry , _ = Select ( PgSqlDialect ()) . from_ ( 'some_table' ) . \\ join_right ( 'other_table' , 'fk_some_table' , 'some_table' , 'id' ) . \\ assemble () # output: SELECT \"some_table\".* FROM \"some_table\" RIGHT JOIN \"other_table\" ON \"some_table\".\"id\"=\"other_table\".\"fk_some_table\" print ( qry ) # example w/ destination table aliasing qry , _ = Select ( PgSqlDialect ()) . from_ ( 'some_table' ) . \\ join_right ({ 'other_table' : 't2' }, 'fk_some_table' , 'some_table' , 'id' ) . \\ assemble () # output: SELECT \"some_table\".* FROM \"some_table\" RIGHT JOIN \"other_table\" AS \"t2\" ON \"some_table\".\"id\"=\"t2\".\"fk_some_table\" print ( qry ) # example w/ source table aliasing qry , _ = Select ( PgSqlDialect ()) . from_ ({ 'some_table' : 't1' }) . \\ join_right ({ 'other_table' : 't2' }, 'fk_some_table' , { 'some_table' : 't1' }, 'id' ) . \\ assemble () # output: SELECT \"t1\".* FROM \"some_table\" AS \"t1\" RIGHT JOIN \"other_table\" AS \"t2\" ON \"t1\".\"id\"=\"t2\".\"fk_some_table\" print ( qry ) # example w/ Record objects and extra SELECT column w/alias qry , _ = Select ( PgSqlDialect ()) . from_ ( Book ) . \\ join_right ( Publisher , Publisher . id , Book , Book . fk_publisher , '=' , [{ Publisher . name : 'publisher_name' }]) . assemble () # output: SELECT \"book\".*,\"publisher\".\"name\" AS \"publisher_name\" FROM \"book\" RIGHT JOIN \"publisher\" ON \"book\".\"fk_publisher\"=\"publisher\".\"id_publisher\" print ( qry ) Select. join_full(table, field, expr_table=None, expr_field=None, operator=None, cols=None, schema=None, expr_schema=None) Adds a FULL OUTER JOIN clause. The parameters must conform with join() parameters . Example: # simple example qry , _ = Select ( PgSqlDialect ()) . from_ ( 'some_table' ) . \\ join_full ( 'other_table' , 'fk_some_table' , 'some_table' , 'id' ) . \\ assemble () # output: SELECT \"some_table\".* FROM \"some_table\" FULL JOIN \"other_table\" ON \"some_table\".\"id\"=\"other_table\".\"fk_some_table\" print ( qry ) # example w/ destination table aliasing qry , _ = Select ( PgSqlDialect ()) . from_ ( 'some_table' ) . \\ join_full ({ 'other_table' : 't2' }, 'fk_some_table' , 'some_table' , 'id' ) . \\ assemble () # output: SELECT \"some_table\".* FROM \"some_table\" FULL JOIN \"other_table\" AS \"t2\" ON \"some_table\".\"id\"=\"t2\".\"fk_some_table\" print ( qry ) # example w/ source table aliasing qry , _ = Select ( PgSqlDialect ()) . from_ ({ 'some_table' : 't1' }) . \\ join_full ({ 'other_table' : 't2' }, 'fk_some_table' , { 'some_table' : 't1' }, 'id' ) . \\ assemble () # output: SELECT \"t1\".* FROM \"some_table\" AS \"t1\" FULL JOIN \"other_table\" AS \"t2\" ON \"t1\".\"id\"=\"t2\".\"fk_some_table\" print ( qry ) # example w/ Record objects and extra SELECT column w/alias qry , _ = Select ( PgSqlDialect ()) . from_ ( Book ) . \\ join_full ( Publisher , Publisher . id , Book , Book . fk_publisher , '=' , [{ Publisher . name : 'publisher_name' }]) . assemble () # output: SELECT \"book\".*,\"publisher\".\"name\" AS \"publisher_name\" FROM \"book\" FULL JOIN \"publisher\" ON \"book\".\"fk_publisher\"=\"publisher\".\"id_publisher\" print ( qry ) Select. join_cross(table, cols=None, schema=None) Adds a CROSS JOIN clause. table identifies the table to CROSS JOIN with, and must be a valid Table identifier expression. cols a list of field names to be SELECT ed from the joined table. schema is the optional schema name for the joined table. Example: # simple example qry , _ = Select ( PgSqlDialect ()) . from_ ( 'table1' ) . \\ join_cross ( 'table2' ) . \\ assemble () # output: SELECT \"table1\".* FROM \"table1\" CROSS JOIN \"table2\" print ( qry ) # example w/ destination table aliasing qry , _ = Select ( PgSqlDialect ()) . from_ ( 'table1' ) . \\ join_cross ({ 'table2' : 't2' }) . \\ assemble () # output: SELECT \"table1\".* FROM \"table1\" CROSS JOIN \"table2\" AS \"t2\" print ( qry ) # example w/ destination table aliasing and extra SELECT columns qry , _ = Select ( PgSqlDialect ()) . from_ ( 'table1' ) . \\ join_cross ({ 'table2' : 't2' }, [{ 'id' : 't2_id' }, 'name' ]) . \\ assemble () # output: SELECT \"table1\".*,\"t2\".\"id\" AS \"t2_id\",\"t2\".\"name\" FROM \"table1\" CROSS JOIN \"table2\" AS \"t2\" print ( qry ) # example w/ Record objects and extra SELECT columns qry , _ = Select ( PgSqlDialect ()) . from_ ( Book ) . \\ join_cross ( Publisher , [ Publisher . id , Publisher . name ]) . \\ assemble () # output: SELECT \"book\".*,\"publisher\".\"id_publisher\",\"publisher\".\"name\" FROM \"book\" CROSS JOIN \"publisher\" print ( qry ) Select. join_natural(table, cols=None, schema=None) Adds a CROSS JOIN clause. table identifies the table to CROSS JOIN with, and must be a valid Table identifier expression. cols a list of field names to be SELECT ed from the joined table. schema is the optional schema name for the joined table. Example: # simple example qry , _ = Select ( PgSqlDialect ()) . from_ ( 'table1' ) . \\ join_natural ( 'table2' ) . \\ assemble () # output: SELECT \"table1\".* FROM \"table1\" NATURAL JOIN \"table2\" print ( qry ) # example w/ destination table aliasing qry , _ = Select ( PgSqlDialect ()) . from_ ( 'table1' ) . \\ join_natural ({ 'table2' : 't2' }) . \\ assemble () # output: SELECT \"table1\".* FROM \"table1\" NATURAL JOIN \"table2\" AS \"t2\" print ( qry ) # example w/ destination table aliasing and extra SELECT columns qry , _ = Select ( PgSqlDialect ()) . from_ ( 'table1' ) . \\ join_natural ({ 'table2' : 't2' }, [{ 'id' : 't2_id' }, 'name' ]) . \\ assemble () # output: SELECT \"table1\".*,\"t2\".\"id\" AS \"t2_id\",\"t2\".\"name\" FROM \"table1\" NATURAL JOIN \"table2\" AS \"t2\" print ( qry ) # example w/ Record objects and extra SELECT columns qry , _ = Select ( PgSqlDialect ()) . from_ ( Book ) . \\ join_natural ( Publisher , [ Publisher . id , Publisher . name ]) . \\ assemble () # output: SELECT \"book\".*,\"publisher\".\"id_publisher\",\"publisher\".\"name\" FROM \"book\" NATURAL JOIN \"publisher\" print ( qry ) Select. assemble() Assembles and returns the SQL query string and list of values. Returns a tuple with (sql_query, list_of_values) . If no values are present, an empty list is returned instead. It will raise RuntimeError on existing errors. Example: qry , _ = Select ( PgSqlDialect ()) . expr ([ 1 ]) . assemble () # output: SELECT 1 print ( qry ) Select. dialect() Return the current SqlDialect object in use.","title":"Select"},{"location":"classes/select/#class-rick_dbsqlselect","text":"","title":"Class rick_db.sql.Select"},{"location":"classes/select/#select__init__dialect-sqldialect-none","text":"Initialize a Select() object, using a database dialect . If no dialect is provided, a default dialect will be used. Check SqlDialect for more details.","title":"Select.__init__(dialect: SqlDialect = None)"},{"location":"classes/select/#selectdistinctflagtrue","text":"Enables or disables the usage of DISTINCT clause, based on the state of flag . The provided DISTINCT functionality is limited - it doesn't support wildcard or specific columns. Example: sql , _ = Select ( PgSqlDialect ()) . from_ ( 'test_table' , 'field' ) . distinct () . assemble () # output: SELECT DISTINCT \"field\" FROM \"test_table\" print ( sql )","title":"Select.distinct(flag=True)"},{"location":"classes/select/#selectexprcolsnone","text":"Adds an anonymous expression to the SELECT statement. It can only be used once in a query. Possible cols values can be: - string with contents - a list of strings with contents - a Literal object - a list of Literal objects Example: qry , _ = Select ( PgSqlDialect ()) . expr ( '1' ) . assemble () # output: SELECT 1 print ( qry ) qry , _ = Select ( PgSqlDialect ()) . expr ([ '1' , '2' , '3' ]) . assemble () # output: SELECT 1,2,3 print ( qry ) qry , _ = Select ( PgSqlDialect ()) . expr ({ Literal ( \"NEXTVAL('some_sequence_name')\" ): \"seq_next\" }) . assemble () # output: SELECT NEXTVAL('some_sequence_name') AS \"seq_next\" print ( qry )","title":"Select.expr(cols=None)"},{"location":"classes/select/#selectfrom_table-colsnone-schemanone","text":"Adds a FROM clause to the query. The table is a table identifier expression, cols is a column identifier and schema specifies an optional schema for table . Example: qry , _ = Select ( PgSqlDialect ()) . from_ ( \"foo\" ) . assemble () # output: SELECT \"foo\".* FROM \"foo\" print ( qry ) qry , _ = Select ( PgSqlDialect ()) . from_ ( \"foo\" , None , \"public\" ) . assemble () # output: SELECT \"foo\".* FROM \"public\".\"foo\" print ( qry ) qry , _ = Select ( PgSqlDialect ()) . from_ ({ \"foo\" : \"bar\" }) . assemble () # output: SELECT \"bar\".* FROM \"foo\" AS \"bar\" print ( qry ) qry , _ = Select ( PgSqlDialect ()) . from_ ( \"foo\" , { \"field1\" : None , \"field2\" : \"alias\" }) . assemble () # output: SELECT \"field1\",\"field2\" AS \"alias\" FROM \"foo\" print ( qry ) qry , _ = Select ( PgSqlDialect ()) . from_ ( \"foo\" , \"field\" ) . assemble () # output: SELECT \"field\" FROM \"foo\" print ( qry ) qry , _ = Select ( PgSqlDialect ()) . from_ ( \"foo\" , [ \"field1\" , \"field2\" ]) . assemble () # output: SELECT \"field1\", \"field2\" FROM \"foo\" print ( qry ) qry , _ = Select ( PgSqlDialect ()) . from_ ({ \"foo\" : \"bar\" }, [ \"field1\" ]) . assemble () # output: SELECT \"bar.field1\" FROM \"foo\" AS \"bar\" print ( qry ) qry , _ = Select ( PgSqlDialect ()) . from_ ( record_class_or_object , [ \"field1\" ]) . assemble () # output: SELECT \"field1\" FROM \"<object_table_name>\" print ( qry ) qry , _ = Select ( PgSqlDialect ()) . from_ ({ record_class_or_object : \"bar\" }, [ \"field1\" ]) . assemble () # output: SELECT \"bar\".\"field1\" FROM \"<object_table_name>\" AS \"bar\" print ( qry )","title":"Select.from_(table, cols=None, schema=None)"},{"location":"classes/select/#table-identifier","text":"A table identifier can be a string, Record class or object, a {'table':'alias'} dict, or a { Record class or object:'alias'} dict.","title":"Table identifier"},{"location":"classes/select/#column-identifier","text":"A column identifier can be None ('*' will be used), a string with a field name, a list of field names, a {'field': 'alias'} dict, a {'field': None, 'other_field':'alias} dict, or a [{'field': 'alias'}, 'field', ] list of mixed string and dict values.","title":"Column identifier"},{"location":"classes/select/#selectlimitlimit-int-offset-int-none","text":"Adds an LIMIT / OFFSET clause. Example: qry , _ = Select ( PgSqlDialect ()) . from_ ( \"foo\" ) . limit ( 10 ) . assemble () # output: SELECT \"foo\".* FROM \"foo\" LIMIT 10 print ( qry ) qry , _ = Select ( PgSqlDialect ()) . from_ ( \"foo\" ) . limit ( 10 , 5 ) . assemble () # output: SELECT \"foo\".* FROM \"foo\" LIMIT 10 OFFSET 5 print ( qry )","title":"Select.limit(limit: int, offset: int = None)"},{"location":"classes/select/#selectpagepage-int-page_rows-int","text":"Helper to add LIMIT / OFFSET clause for pagination purposes. page specifies which page to fetch, starting from 1, and page rows specifies the number of rows per page Example: qry , _ = Select ( PgSqlDialect ()) . from_ ( \"foo\" ) . page ( 1 , 10 ) . assemble () # output: SELECT \"foo\".* FROM \"foo\" LIMIT 10 OFFSET 0 print ( qry ) qry , _ = Select ( PgSqlDialect ()) . from_ ( \"foo\" ) . page ( 10 , 10 ) . assemble () # output: SELECT \"foo\".* FROM \"foo\" LIMIT 10 OFFSET 10 print ( qry )","title":"Select.page(page: int, page_rows: int)"},{"location":"classes/select/#selectfor_updateflag-bool-true","text":"Adds a FOR UPDATE clause if flag is True.","title":"Select.for_update(flag: bool = True)"},{"location":"classes/select/#selectorderfields-ordersqlsql_asc","text":"Adds an ORDER BY clause with the specified fields . order is ASC by default. Example: qry , _ = Select ( PgSqlDialect ()) . from_ ( \"foo\" ) . order ( 'id' ) . assemble () # output: SELECT \"foo\".* FROM \"foo\" ORDER BY id ASC print ( qry ) qry , _ = Select ( PgSqlDialect ()) . from_ ( \"foo\" ) . order ([ 'id' , 'name' ], Select . ORDER_DESC ) . assemble () # output: SELECT \"foo\".* FROM \"foo\" ORDER BY id DESC, a DESC print ( qry )","title":"Select.order(fields, order=Sql.SQL_ASC)"},{"location":"classes/select/#selectwherefield-operatornone-valuenone","text":"Adds a WHERE clause. Multiple calls to this method are concatenated with AND . field must contain a valid Field identifier , operator can contain either a string with an operator or a Literal object, and finally value , if specified, is the operand. Example: # showcase multiple WHERE... AND clauses qry = Select ( PgSqlDialect ()) . from_ ( \"foo\" ) . \\ where ( 'id' , '>' , 5 ) . \\ where ( 'name' , 'IS NOT NULL' ) . \\ where ( 'cp' , 'IN' , [ 100 , 200 , 300 , 400 ]) # output: ('SELECT \"foo\".* FROM \"foo\" WHERE (\"id\" > %s) AND (\"name\" IS NOT NULL) AND (\"cp\" IN %s)', [5, [100, 200, 300, 400]]) print ( qry . assemble ())","title":"Select.where(field, operator=None, value=None)"},{"location":"classes/select/#field-identifier","text":"A field identifier can be a string with a field name, a Literal object, a {'table':'field'} dict or { :'field'} dict.","title":"Field identifier"},{"location":"classes/select/#selectwhere_and","text":"Starts a parenthesis AND block within the WHERE clause, allowing the build of complex WHERE clauses. This method is nestable, allowing the composition of multi-level parenthesis blocks. All declared blocks need to be explicitly closed with where_end() . Example: # showcase WHERE clause AND ( clause OR clause) qry = Select ( PgSqlDialect ()) . from_ ( \"foo\" ) . \\ where ( 'id' , '>' , 5 ) . \\ where_and () . \\ where ( 'name' , 'IS NOT NULL' ) . \\ orwhere ( 'cp' , 'IN' , [ 100 , 200 , 300 , 400 ]) . \\ where_end () # output: ('SELECT \"foo\".* FROM \"foo\" WHERE (\"id\" > %s) AND ( (\"name\" IS NOT NULL) OR (\"cp\" IN %s) )', [5, [100, 200, 300, 400]]) print ( qry . assemble ())","title":"Select.where_and()"},{"location":"classes/select/#selectwhere_or","text":"Starts a parenthesis OR block within the WHERE clause, allowing the build of complex WHERE clauses. This method is nestable, allowing the composition of multi-level parenthesis blocks. All declared blocks need to be explicitly closed with where_end() . Example: # showcase WHERE clause OR ( clause AND clause) qry = Select ( PgSqlDialect ()) . from_ ( \"foo\" ) . \\ where ( 'id' , '>' , 5 ) . \\ where_or () . \\ where ( 'name' , 'IS NOT NULL' ) . \\ where ( 'cp' , 'IN' , [ 100 , 200 , 300 , 400 ]) . \\ where_end () # output: ('SELECT \"foo\".* FROM \"foo\" WHERE (\"id\" > %s) OR ( (\"name\" IS NOT NULL) AND (\"cp\" IN %s) )', [5, [100, 200, 300, 400]]) print ( qry . assemble ())","title":"Select.where_or()"},{"location":"classes/select/#selectwhere_end","text":"Closes a parenthesis AND or OR block. Please note, to allow the most freedom when building queries, Validation of open/closed blocks is only performed on assemble() . If the internal open block counter is not 0 on assemble() , a RuntimeError is raised. See where_and() and where_or() for usage examples.","title":"Select.where_end()"},{"location":"classes/select/#selectorwherefield-operatornone-valuenone","text":"Adds a WHERE clause to be concatenated with OR . field must contain a valid Field identifier , operator can contain either a string with an operator or a Literal object, and finally value , if specified, is the operand. Example: # showcase multiple WHERE... AND clauses qry = Select ( PgSqlDialect ()) . from_ ( \"foo\" ) . \\ where ( 'id' , '>' , 5 ) . \\ orwhere ( 'name' , 'IS NOT NULL' ) . \\ where ( 'cp' , 'IN' , [ 100 , 200 , 300 , 400 ]) # output: ('SELECT \"foo\".* FROM \"foo\" WHERE (\"id\" > %s) OR (\"name\" IS NOT NULL) AND (\"cp\" IN %s)', [5, [100, 200, 300, 400]]) print ( qry . assemble ())","title":"Select.orwhere(field, operator=None, value=None)"},{"location":"classes/select/#selectgroupfields","text":"Adds a GROUP BY clause. fields can be either a field name, a list of field names, a Literal or a list of Literal objects. Example: qry , _ = Select ( PgSqlDialect ()) . from_ ( \"foo\" ) . group ([ 'age' , 'name' ]) . assemble () # output: SELECT \"foo\".* FROM \"foo\" GROUP BY \"age\", \"name\" print ( qry )","title":"Select.group(fields)"},{"location":"classes/select/#selecthavingfield-operatornone-valuenone-schemanone","text":"Adds a HAVING clause. field can be a field name, a Literal , a {'table':'field'} dict or a { Record class or object:'field'} dict. Example: # HAVING Literal condition qry , _ = Select ( PgSqlDialect ()) . from_ ( \"foo\" ) . having ( Literal ( 'COUNT(field) > 5' )) . assemble () # output: SELECT \"foo\".* FROM \"foo\" HAVING (COUNT(field) > 5) print ( qry ) # HAVING condition qry , _ = Select ( PgSqlDialect ()) . from_ ( \"foo\" ) . having ( 'field' , '>' , 5 , 'public' ) . assemble () # output: SELECT \"foo\".* FROM \"foo\" HAVING (\"field\" > %s) print ( qry ) # HAVING with schema qry , _ = Select ( PgSqlDialect ()) . from_ ( \"foo\" ) . having ({ 'some_table' : 'field' }, '>' , 5 , 'public' ) . assemble () # output: SELECT \"foo\".* FROM \"foo\" HAVING (\"public\".\"some_table\".\"field\" > %s) print ( qry )","title":"Select.having(field, operator=None, value=None, schema=None)"},{"location":"classes/select/#selectunionqueries-list-union_type-str-sqlsql_union","text":"Performs an UNION of two or more Select() or string queries. union_type can be either Sql.SQL_UNION or Sql.SQL_UNION_ALL . Example: qry , _ = Select ( PgSqlDialect ()) . union ([ Select () . from_ ( 'table' ), Select () . from_ ( 'other_table' )]) . \\ assemble () # output: SELECT \"table\".* FROM \"table\" UNION SELECT \"other_table\".* FROM \"other_table\" print ( qry )","title":"Select.union(queries: list, union_type: str = Sql.SQL_UNION)"},{"location":"classes/select/#selectjointable-field-expr_tablenone-expr_fieldnone-operatornone-colsnone-schemanone-expr_schemanone","text":"Adds a INNER JOIN clause. The parameters must conform with join() parameters . Example: # simple example qry , _ = Select ( PgSqlDialect ()) . from_ ( 'some_table' ) . \\ join ( 'other_table' , 'fk_some_table' , 'some_table' , 'id' ) . \\ assemble () # output: SELECT \"some_table\".* FROM \"some_table\" INNER JOIN \"other_table\" ON \"some_table\".\"id\"=\"other_table\".\"fk_some_table\" print ( qry ) # example w/ destination table aliasing qry , _ = Select ( PgSqlDialect ()) . from_ ( 'some_table' ) . \\ join ({ 'other_table' : 't2' }, 'fk_some_table' , 'some_table' , 'id' ) . \\ assemble () # output: SELECT \"some_table\".* FROM \"some_table\" INNER JOIN \"other_table\" AS \"t2\" ON \"some_table\".\"id\"=\"t2\".\"fk_some_table\" print ( qry ) # example w/ source table aliasing qry , _ = Select ( PgSqlDialect ()) . from_ ({ 'some_table' : 't1' }) . \\ join ({ 'other_table' : 't2' }, 'fk_some_table' , { 'some_table' : 't1' }, 'id' ) . \\ assemble () # output: SELECT \"t1\".* FROM \"some_table\" AS \"t1\" INNER JOIN \"other_table\" AS \"t2\" ON \"t1\".\"id\"=\"t2\".\"fk_some_table\" print ( qry ) # example w/ Record objects and extra SELECT column w/alias qry , _ = Select ( PgSqlDialect ()) . from_ ( Book ) . \\ join ( Publisher , Publisher . id , Book , Book . fk_publisher , '=' , [{ Publisher . name : 'publisher_name' }]) . assemble () # output: SELECT \"book\".*,\"publisher\".\"name\" AS \"publisher_name\" FROM \"book\" INNER JOIN \"publisher\" ON \"book\".\"fk_publisher\"=\"publisher\".\"id_publisher\" print ( qry )","title":"Select.join(table, field, expr_table=None, expr_field=None, operator=None, cols=None, schema=None, expr_schema=None)"},{"location":"classes/select/#join-parameters","text":"table identifies the table to JOIN to, and must be a valid Table identifier expression. field is the field name or expression to join on table . expr_table identifies the existing table to JOIN from, and must be a valid Table identifier . expr_field is the field name or expression to JOIN on the existing table. operator is an optional join operator - if omitted, '=' is used. cols is an optional list of column names to add to the SELECT statement. schema and expr_schema can provide optional schema naming for both table to JOIN to and table to JOIN from.","title":"join() parameters"},{"location":"classes/select/#selectjoin_innertable-field-expr_tablenone-expr_fieldnone-operatornone-colsnone-schemanone-expr_schemanone","text":"Alias to join() .","title":"Select.join_inner(table, field, expr_table=None, expr_field=None, operator=None, cols=None, schema=None, expr_schema=None)"},{"location":"classes/select/#selectjoin_lefttable-field-expr_tablenone-expr_fieldnone-operatornone-colsnone-schemanone-expr_schemanone","text":"Adds a LEFT JOIN clause. The parameters must conform with join() parameters . Example: # simple example qry , _ = Select ( PgSqlDialect ()) . from_ ( 'some_table' ) . \\ join_left ( 'other_table' , 'fk_some_table' , 'some_table' , 'id' ) . \\ assemble () # output: SELECT \"some_table\".* FROM \"some_table\" LEFT JOIN \"other_table\" ON \"some_table\".\"id\"=\"other_table\".\"fk_some_table\" print ( qry ) # example w/ destination table aliasing qry , _ = Select ( PgSqlDialect ()) . from_ ( 'some_table' ) . \\ join_left ({ 'other_table' : 't2' }, 'fk_some_table' , 'some_table' , 'id' ) . \\ assemble () # output: SELECT \"some_table\".* FROM \"some_table\" LEFT JOIN \"other_table\" AS \"t2\" ON \"some_table\".\"id\"=\"t2\".\"fk_some_table\" print ( qry ) # example w/ source table aliasing qry , _ = Select ( PgSqlDialect ()) . from_ ({ 'some_table' : 't1' }) . \\ join_left ({ 'other_table' : 't2' }, 'fk_some_table' , { 'some_table' : 't1' }, 'id' ) . \\ assemble () # output: SELECT \"t1\".* FROM \"some_table\" AS \"t1\" LEFT JOIN \"other_table\" AS \"t2\" ON \"t1\".\"id\"=\"t2\".\"fk_some_table\" print ( qry ) # example w/ Record objects and extra SELECT column w/alias qry , _ = Select ( PgSqlDialect ()) . from_ ( Book ) . \\ join_left ( Publisher , Publisher . id , Book , Book . fk_publisher , '=' , [{ Publisher . name : 'publisher_name' }]) . assemble () # output: SELECT \"book\".*,\"publisher\".\"name\" AS \"publisher_name\" FROM \"book\" LEFT JOIN \"publisher\" ON \"book\".\"fk_publisher\"=\"publisher\".\"id_publisher\" print ( qry )","title":"Select.join_left(table, field, expr_table=None, expr_field=None, operator=None, cols=None, schema=None, expr_schema=None)"},{"location":"classes/select/#selectjoin_righttable-field-expr_tablenone-expr_fieldnone-operatornone-colsnone-schemanone-expr_schemanone","text":"Adds a RIGHT JOIN clause. The parameters must conform with join() parameters . Example: # simple example qry , _ = Select ( PgSqlDialect ()) . from_ ( 'some_table' ) . \\ join_right ( 'other_table' , 'fk_some_table' , 'some_table' , 'id' ) . \\ assemble () # output: SELECT \"some_table\".* FROM \"some_table\" RIGHT JOIN \"other_table\" ON \"some_table\".\"id\"=\"other_table\".\"fk_some_table\" print ( qry ) # example w/ destination table aliasing qry , _ = Select ( PgSqlDialect ()) . from_ ( 'some_table' ) . \\ join_right ({ 'other_table' : 't2' }, 'fk_some_table' , 'some_table' , 'id' ) . \\ assemble () # output: SELECT \"some_table\".* FROM \"some_table\" RIGHT JOIN \"other_table\" AS \"t2\" ON \"some_table\".\"id\"=\"t2\".\"fk_some_table\" print ( qry ) # example w/ source table aliasing qry , _ = Select ( PgSqlDialect ()) . from_ ({ 'some_table' : 't1' }) . \\ join_right ({ 'other_table' : 't2' }, 'fk_some_table' , { 'some_table' : 't1' }, 'id' ) . \\ assemble () # output: SELECT \"t1\".* FROM \"some_table\" AS \"t1\" RIGHT JOIN \"other_table\" AS \"t2\" ON \"t1\".\"id\"=\"t2\".\"fk_some_table\" print ( qry ) # example w/ Record objects and extra SELECT column w/alias qry , _ = Select ( PgSqlDialect ()) . from_ ( Book ) . \\ join_right ( Publisher , Publisher . id , Book , Book . fk_publisher , '=' , [{ Publisher . name : 'publisher_name' }]) . assemble () # output: SELECT \"book\".*,\"publisher\".\"name\" AS \"publisher_name\" FROM \"book\" RIGHT JOIN \"publisher\" ON \"book\".\"fk_publisher\"=\"publisher\".\"id_publisher\" print ( qry )","title":"Select.join_right(table, field, expr_table=None, expr_field=None, operator=None, cols=None, schema=None, expr_schema=None)"},{"location":"classes/select/#selectjoin_fulltable-field-expr_tablenone-expr_fieldnone-operatornone-colsnone-schemanone-expr_schemanone","text":"Adds a FULL OUTER JOIN clause. The parameters must conform with join() parameters . Example: # simple example qry , _ = Select ( PgSqlDialect ()) . from_ ( 'some_table' ) . \\ join_full ( 'other_table' , 'fk_some_table' , 'some_table' , 'id' ) . \\ assemble () # output: SELECT \"some_table\".* FROM \"some_table\" FULL JOIN \"other_table\" ON \"some_table\".\"id\"=\"other_table\".\"fk_some_table\" print ( qry ) # example w/ destination table aliasing qry , _ = Select ( PgSqlDialect ()) . from_ ( 'some_table' ) . \\ join_full ({ 'other_table' : 't2' }, 'fk_some_table' , 'some_table' , 'id' ) . \\ assemble () # output: SELECT \"some_table\".* FROM \"some_table\" FULL JOIN \"other_table\" AS \"t2\" ON \"some_table\".\"id\"=\"t2\".\"fk_some_table\" print ( qry ) # example w/ source table aliasing qry , _ = Select ( PgSqlDialect ()) . from_ ({ 'some_table' : 't1' }) . \\ join_full ({ 'other_table' : 't2' }, 'fk_some_table' , { 'some_table' : 't1' }, 'id' ) . \\ assemble () # output: SELECT \"t1\".* FROM \"some_table\" AS \"t1\" FULL JOIN \"other_table\" AS \"t2\" ON \"t1\".\"id\"=\"t2\".\"fk_some_table\" print ( qry ) # example w/ Record objects and extra SELECT column w/alias qry , _ = Select ( PgSqlDialect ()) . from_ ( Book ) . \\ join_full ( Publisher , Publisher . id , Book , Book . fk_publisher , '=' , [{ Publisher . name : 'publisher_name' }]) . assemble () # output: SELECT \"book\".*,\"publisher\".\"name\" AS \"publisher_name\" FROM \"book\" FULL JOIN \"publisher\" ON \"book\".\"fk_publisher\"=\"publisher\".\"id_publisher\" print ( qry )","title":"Select.join_full(table, field, expr_table=None, expr_field=None, operator=None, cols=None, schema=None, expr_schema=None)"},{"location":"classes/select/#selectjoin_crosstable-colsnone-schemanone","text":"Adds a CROSS JOIN clause. table identifies the table to CROSS JOIN with, and must be a valid Table identifier expression. cols a list of field names to be SELECT ed from the joined table. schema is the optional schema name for the joined table. Example: # simple example qry , _ = Select ( PgSqlDialect ()) . from_ ( 'table1' ) . \\ join_cross ( 'table2' ) . \\ assemble () # output: SELECT \"table1\".* FROM \"table1\" CROSS JOIN \"table2\" print ( qry ) # example w/ destination table aliasing qry , _ = Select ( PgSqlDialect ()) . from_ ( 'table1' ) . \\ join_cross ({ 'table2' : 't2' }) . \\ assemble () # output: SELECT \"table1\".* FROM \"table1\" CROSS JOIN \"table2\" AS \"t2\" print ( qry ) # example w/ destination table aliasing and extra SELECT columns qry , _ = Select ( PgSqlDialect ()) . from_ ( 'table1' ) . \\ join_cross ({ 'table2' : 't2' }, [{ 'id' : 't2_id' }, 'name' ]) . \\ assemble () # output: SELECT \"table1\".*,\"t2\".\"id\" AS \"t2_id\",\"t2\".\"name\" FROM \"table1\" CROSS JOIN \"table2\" AS \"t2\" print ( qry ) # example w/ Record objects and extra SELECT columns qry , _ = Select ( PgSqlDialect ()) . from_ ( Book ) . \\ join_cross ( Publisher , [ Publisher . id , Publisher . name ]) . \\ assemble () # output: SELECT \"book\".*,\"publisher\".\"id_publisher\",\"publisher\".\"name\" FROM \"book\" CROSS JOIN \"publisher\" print ( qry )","title":"Select.join_cross(table, cols=None, schema=None)"},{"location":"classes/select/#selectjoin_naturaltable-colsnone-schemanone","text":"Adds a CROSS JOIN clause. table identifies the table to CROSS JOIN with, and must be a valid Table identifier expression. cols a list of field names to be SELECT ed from the joined table. schema is the optional schema name for the joined table. Example: # simple example qry , _ = Select ( PgSqlDialect ()) . from_ ( 'table1' ) . \\ join_natural ( 'table2' ) . \\ assemble () # output: SELECT \"table1\".* FROM \"table1\" NATURAL JOIN \"table2\" print ( qry ) # example w/ destination table aliasing qry , _ = Select ( PgSqlDialect ()) . from_ ( 'table1' ) . \\ join_natural ({ 'table2' : 't2' }) . \\ assemble () # output: SELECT \"table1\".* FROM \"table1\" NATURAL JOIN \"table2\" AS \"t2\" print ( qry ) # example w/ destination table aliasing and extra SELECT columns qry , _ = Select ( PgSqlDialect ()) . from_ ( 'table1' ) . \\ join_natural ({ 'table2' : 't2' }, [{ 'id' : 't2_id' }, 'name' ]) . \\ assemble () # output: SELECT \"table1\".*,\"t2\".\"id\" AS \"t2_id\",\"t2\".\"name\" FROM \"table1\" NATURAL JOIN \"table2\" AS \"t2\" print ( qry ) # example w/ Record objects and extra SELECT columns qry , _ = Select ( PgSqlDialect ()) . from_ ( Book ) . \\ join_natural ( Publisher , [ Publisher . id , Publisher . name ]) . \\ assemble () # output: SELECT \"book\".*,\"publisher\".\"id_publisher\",\"publisher\".\"name\" FROM \"book\" NATURAL JOIN \"publisher\" print ( qry )","title":"Select.join_natural(table, cols=None, schema=None)"},{"location":"classes/select/#selectassemble","text":"Assembles and returns the SQL query string and list of values. Returns a tuple with (sql_query, list_of_values) . If no values are present, an empty list is returned instead. It will raise RuntimeError on existing errors. Example: qry , _ = Select ( PgSqlDialect ()) . expr ([ 1 ]) . assemble () # output: SELECT 1 print ( qry )","title":"Select.assemble()"},{"location":"classes/select/#selectdialect","text":"Return the current SqlDialect object in use.","title":"Select.dialect()"},{"location":"classes/sqldialect/","text":"Class rick_db.sql. SqlDialect Base Dialect Class. Implements schema, table and field quoting specifics to be used primarily within the query builder. SqlDialect. table(table_name, alias=None, schema=None) Quotes a table name, with an optional alias and schema . Example: # get dialect from a PgConnection() object dialect = conn . dialect () # output: \"tbl\" print ( dialect . table ( 'tbl' , None , None )) # output: \"schema\".\"tbl\" AS \"alias\" print ( dialect . table ( 'tbl' , 'alias' , 'schema' )) SqlDialect. field(field, field_alias=None, table=None, schema=None) Quotes a field name, with an optional field_alias , table and schema . If field_alias is a list or tuple, a CAST() is performed instead, using the first item as type. If the list or tuple contains 2 items, the first one is used as type, and the second one as alias. Example: # get dialect from a PgConnection() object dialect = conn . dialect () # output: \"field\" print ( dialect . field ( 'field' , None )) # output: \"field\" AS \"alias\" print ( dialect . field ( 'field' , 'alias' )) # output: CAST(\"field\" AS text) print ( dialect . field ( 'field' , [ 'text' ])) # output: CAST(\"field\" AS text) AS \"alias\" print ( dialect . field ( 'field' , [ 'text' , 'alias' ])) # output: CAST(COUNT(*) AS int) AS \"total\" print ( dialect . field ( Literal ( 'COUNT(*)' ), [ 'int' , 'total' ])) # output: \"table\".\"field\" AS \"alias\" print ( dialect . field ( 'field' , 'alias' , 'table' )) # output: \"public\".\"table\".\"field\" AS \"alias\" print ( dialect . field ( 'field' , 'alias' , 'table' , 'public' ))","title":"SqlDialect"},{"location":"classes/sqldialect/#class-rick_dbsqlsqldialect","text":"Base Dialect Class. Implements schema, table and field quoting specifics to be used primarily within the query builder.","title":"Class rick_db.sql.SqlDialect"},{"location":"classes/sqldialect/#sqldialecttabletable_name-aliasnone-schemanone","text":"Quotes a table name, with an optional alias and schema . Example: # get dialect from a PgConnection() object dialect = conn . dialect () # output: \"tbl\" print ( dialect . table ( 'tbl' , None , None )) # output: \"schema\".\"tbl\" AS \"alias\" print ( dialect . table ( 'tbl' , 'alias' , 'schema' ))","title":"SqlDialect.table(table_name, alias=None, schema=None)"},{"location":"classes/sqldialect/#sqldialectfieldfield-field_aliasnone-tablenone-schemanone","text":"Quotes a field name, with an optional field_alias , table and schema . If field_alias is a list or tuple, a CAST() is performed instead, using the first item as type. If the list or tuple contains 2 items, the first one is used as type, and the second one as alias. Example: # get dialect from a PgConnection() object dialect = conn . dialect () # output: \"field\" print ( dialect . field ( 'field' , None )) # output: \"field\" AS \"alias\" print ( dialect . field ( 'field' , 'alias' )) # output: CAST(\"field\" AS text) print ( dialect . field ( 'field' , [ 'text' ])) # output: CAST(\"field\" AS text) AS \"alias\" print ( dialect . field ( 'field' , [ 'text' , 'alias' ])) # output: CAST(COUNT(*) AS int) AS \"total\" print ( dialect . field ( Literal ( 'COUNT(*)' ), [ 'int' , 'total' ])) # output: \"table\".\"field\" AS \"alias\" print ( dialect . field ( 'field' , 'alias' , 'table' )) # output: \"public\".\"table\".\"field\" AS \"alias\" print ( dialect . field ( 'field' , 'alias' , 'table' , 'public' ))","title":"SqlDialect.field(field, field_alias=None, table=None, schema=None)"},{"location":"classes/update/","text":"Class rick_db.sql. Update Update. __init__(dialect: SqlDialect = None) Initialize a Update() object, using a database dialect . If no dialect is provided, a default dialect will be used. Check SqlDialect for more details. Update. table(table, schema=None) Defines the target table name and schema for update. If table is a Record object, it will also load fields and values from this object. Example: # simple UPDATE example qry = Update ( PgSqlDialect ()) . table ( 'table' ) . fields ([ 'field' ]) . values ([ 'value' ]) # output: ('UPDATE \"table\" SET \"field\"=%s', ['value']) print ( qry . assemble ()) # UPDATE w/ Record object record = Publisher ( name = 'some publisher name' ) qry = Update ( PgSqlDialect ()) . table ( record ) # output: ('UPDATE \"publisher\" SET \"name\"=%s', ['some publisher name']) print ( qry . assemble ()) Update. fields(fields: list) Defines the field names to be updated. The length of fields list must match the list of provided values. Example: data = [ [ 'john' , 'connor' ], [ 'sarah' , 'connor' ] ] sql = [] qry = Update ( PgSqlDialect ()) . table ( 'table' ) . fields ([ 'name' , 'surname' ]) for v in data : qry . values ( v ) sql . append ( qry . assemble ()) # output: # [('UPDATE \"table\" SET \"name\"=%s, \"surname\"=%s', ['john', 'connor']), # ('UPDATE \"table\" SET \"name\"=%s, \"surname\"=%s', ['sarah', 'connor'])] print ( sql ) Update. values(values: Union[list, dict, object]) Define values of fields to be updated. This method can be called multiple times (see fields() for an example). If values is a dict, both fields and values are read from the provided dict. If values is a Record object, fields and values are read from the object. Example: # simple UPDATE example qry = Update ( PgSqlDialect ()) . table ( 'table' ) . fields ([ 'field' ]) . values ([ 'value' ]) # output: ('UPDATE \"table\" SET \"field\"=%s', ['value']) print ( qry . assemble ()) # INSERT w/ Record object record = Publisher ( name = 'some publisher name' ) qry = Update ( PgSqlDialect ()) . table ( 'tablename' ) . values ( record ) # output: ('UPDATE \"tablename\" SET \"name\"=%s', ['some publisher name']) print ( qry . assemble ()) Update. where(field, operator=None, value=None) Adds a WHERE clause to the UPDATE clause. It requires a mandatory field name and an operator , and allows an optional value . Clauses generated by multiple calls to this method are concatenated with AND . Example: # UPDATE WHERE... common usage qry = Update ( PgSqlDialect ()) . table ( 'table' ) . \\ values ({ 'field' : 'value' }) . \\ where ( 'id' , '=' , 7 ) # output: ('UPDATE \"table\" SET \"field\"=%s WHERE \"id\" = %s', ['value', 7]) print ( qry . assemble ()) # UPDATE WHERE... no value qry = Update ( PgSqlDialect ()) . table ( 'table' ) . \\ values ({ 'field' : 'value' }) . \\ where ( 'id' , 'IS NOT NULL' ) # output: ('UPDATE \"table\" SET \"field\"=%s WHERE \"id\" IS NOT NULL', ['value']) print ( qry . assemble ()) # UPDATE WHERE... with multiple clauses qry = Update ( PgSqlDialect ()) . table ( 'table' ) . \\ values ({ 'field' : 'value' }) . \\ where ( 'id' , '=' , 7 ) . \\ where ( 'name' , 'ILIKE' , 'john%' ) # output: ('UPDATE \"table\" SET \"field\"=%s WHERE \"id\" = %s AND \"name\" ILIKE %s', ['value', 7, 'john%']) print ( qry . assemble ()) Update. orwhere(field, operator=None, value=None) Adds a WHERE clause to the UPDATE clause. It requires a mandatory field name and an operator , and allows an optional value . Clauses generated by multiple calls to this method are concatenated with OR . Example: qry = Update ( PgSqlDialect ()) . table ( 'table' ) . \\ values ({ 'field' : 'value' }) . \\ where ( 'id' , '=' , 7 ) . \\ orwhere ( 'name' , 'ILIKE' , 'john%' ) # output: ('UPDATE \"table\" SET \"field\"=%s WHERE \"id\" = %s OR \"name\" ILIKE %s', ['value', 7, 'john%']) print ( qry . assemble ()) Update. returning(fields: Union[list, str] = Sql.SQL_ALL) Adds a RETURNING clause to the UPDATE clause with a list of field names. If fields is empty, '*' is used. Example: qry = Update ( PgSqlDialect ()) \\ . table ( 'table' ) \\ . values ({ 'field' : 'value' }) \\ . where ( 'id' , '=' , 7 ) \\ . orwhere ( 'name' , 'ILIKE' , 'john%' ) \\ . returning () # output: ('UPDATE \"table\" SET \"field\"=%s WHERE \"id\" = %s OR \"name\" ILIKE %s RETURNING *', ['value', 7, 'john%']) print ( qry . assemble ()) Update. assemble() Assembles UPDATE SQL string and returns a tuple with (sql_string, list_of_values). If an error occurs, SqlError is raised. Example: # simple UPDATE example qry = Update ( PgSqlDialect ()) . table ( 'table' ) . fields ([ 'field' ]) . values ([ 'value' ]) # output: ('UPDATE \"table\" SET \"field\"=%s', ['value']) print ( qry . assemble ())","title":"Update"},{"location":"classes/update/#class-rick_dbsqlupdate","text":"","title":"Class rick_db.sql.Update"},{"location":"classes/update/#update__init__dialect-sqldialect-none","text":"Initialize a Update() object, using a database dialect . If no dialect is provided, a default dialect will be used. Check SqlDialect for more details.","title":"Update.__init__(dialect: SqlDialect = None)"},{"location":"classes/update/#updatetabletable-schemanone","text":"Defines the target table name and schema for update. If table is a Record object, it will also load fields and values from this object. Example: # simple UPDATE example qry = Update ( PgSqlDialect ()) . table ( 'table' ) . fields ([ 'field' ]) . values ([ 'value' ]) # output: ('UPDATE \"table\" SET \"field\"=%s', ['value']) print ( qry . assemble ()) # UPDATE w/ Record object record = Publisher ( name = 'some publisher name' ) qry = Update ( PgSqlDialect ()) . table ( record ) # output: ('UPDATE \"publisher\" SET \"name\"=%s', ['some publisher name']) print ( qry . assemble ())","title":"Update.table(table, schema=None)"},{"location":"classes/update/#updatefieldsfields-list","text":"Defines the field names to be updated. The length of fields list must match the list of provided values. Example: data = [ [ 'john' , 'connor' ], [ 'sarah' , 'connor' ] ] sql = [] qry = Update ( PgSqlDialect ()) . table ( 'table' ) . fields ([ 'name' , 'surname' ]) for v in data : qry . values ( v ) sql . append ( qry . assemble ()) # output: # [('UPDATE \"table\" SET \"name\"=%s, \"surname\"=%s', ['john', 'connor']), # ('UPDATE \"table\" SET \"name\"=%s, \"surname\"=%s', ['sarah', 'connor'])] print ( sql )","title":"Update.fields(fields: list)"},{"location":"classes/update/#updatevaluesvalues-unionlist-dict-object","text":"Define values of fields to be updated. This method can be called multiple times (see fields() for an example). If values is a dict, both fields and values are read from the provided dict. If values is a Record object, fields and values are read from the object. Example: # simple UPDATE example qry = Update ( PgSqlDialect ()) . table ( 'table' ) . fields ([ 'field' ]) . values ([ 'value' ]) # output: ('UPDATE \"table\" SET \"field\"=%s', ['value']) print ( qry . assemble ()) # INSERT w/ Record object record = Publisher ( name = 'some publisher name' ) qry = Update ( PgSqlDialect ()) . table ( 'tablename' ) . values ( record ) # output: ('UPDATE \"tablename\" SET \"name\"=%s', ['some publisher name']) print ( qry . assemble ())","title":"Update.values(values: Union[list, dict, object])"},{"location":"classes/update/#updatewherefield-operatornone-valuenone","text":"Adds a WHERE clause to the UPDATE clause. It requires a mandatory field name and an operator , and allows an optional value . Clauses generated by multiple calls to this method are concatenated with AND . Example: # UPDATE WHERE... common usage qry = Update ( PgSqlDialect ()) . table ( 'table' ) . \\ values ({ 'field' : 'value' }) . \\ where ( 'id' , '=' , 7 ) # output: ('UPDATE \"table\" SET \"field\"=%s WHERE \"id\" = %s', ['value', 7]) print ( qry . assemble ()) # UPDATE WHERE... no value qry = Update ( PgSqlDialect ()) . table ( 'table' ) . \\ values ({ 'field' : 'value' }) . \\ where ( 'id' , 'IS NOT NULL' ) # output: ('UPDATE \"table\" SET \"field\"=%s WHERE \"id\" IS NOT NULL', ['value']) print ( qry . assemble ()) # UPDATE WHERE... with multiple clauses qry = Update ( PgSqlDialect ()) . table ( 'table' ) . \\ values ({ 'field' : 'value' }) . \\ where ( 'id' , '=' , 7 ) . \\ where ( 'name' , 'ILIKE' , 'john%' ) # output: ('UPDATE \"table\" SET \"field\"=%s WHERE \"id\" = %s AND \"name\" ILIKE %s', ['value', 7, 'john%']) print ( qry . assemble ())","title":"Update.where(field, operator=None, value=None)"},{"location":"classes/update/#updateorwherefield-operatornone-valuenone","text":"Adds a WHERE clause to the UPDATE clause. It requires a mandatory field name and an operator , and allows an optional value . Clauses generated by multiple calls to this method are concatenated with OR . Example: qry = Update ( PgSqlDialect ()) . table ( 'table' ) . \\ values ({ 'field' : 'value' }) . \\ where ( 'id' , '=' , 7 ) . \\ orwhere ( 'name' , 'ILIKE' , 'john%' ) # output: ('UPDATE \"table\" SET \"field\"=%s WHERE \"id\" = %s OR \"name\" ILIKE %s', ['value', 7, 'john%']) print ( qry . assemble ())","title":"Update.orwhere(field, operator=None, value=None)"},{"location":"classes/update/#updatereturningfields-unionlist-str-sqlsql_all","text":"Adds a RETURNING clause to the UPDATE clause with a list of field names. If fields is empty, '*' is used. Example: qry = Update ( PgSqlDialect ()) \\ . table ( 'table' ) \\ . values ({ 'field' : 'value' }) \\ . where ( 'id' , '=' , 7 ) \\ . orwhere ( 'name' , 'ILIKE' , 'john%' ) \\ . returning () # output: ('UPDATE \"table\" SET \"field\"=%s WHERE \"id\" = %s OR \"name\" ILIKE %s RETURNING *', ['value', 7, 'john%']) print ( qry . assemble ())","title":"Update.returning(fields: Union[list, str] = Sql.SQL_ALL)"},{"location":"classes/update/#updateassemble","text":"Assembles UPDATE SQL string and returns a tuple with (sql_string, list_of_values). If an error occurs, SqlError is raised. Example: # simple UPDATE example qry = Update ( PgSqlDialect ()) . table ( 'table' ) . fields ([ 'field' ]) . values ([ 'value' ]) # output: ('UPDATE \"table\" SET \"field\"=%s', ['value']) print ( qry . assemble ())","title":"Update.assemble()"}]}