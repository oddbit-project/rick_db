{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Welcome to RickDb","text":"<p>RickDb is a SQL database layer for Python3. It includes connection management, Object Mapper, Query Builder, and a Repository pattern implementation.  </p>"},{"location":"#features","title":"Features","text":"<ul> <li>Object Mapper</li> <li>Fluent SQL Query builder with schema support</li> <li>High level connectors for PostgreSQL, SQLite</li> <li>Pluggable SQL query profiler</li> <li>Grid helper</li> <li>Migration Manager</li> </ul>"},{"location":"#purpose","title":"Purpose","text":"<p>RickDb was designed to be used in schema-first scenarios: Database schema is built and managed directly with SQL DDL commands, and there is a clear segregation of concerns - the application layer has no responsibility on the structure of the database.</p> <p>This approach is the direct opposite of most available ORMS, but allows complete control over how the database is queried and how results are processed within the application, favoring cache-friendly multi-tier/service-oriented implementations.</p> <p>However, it can also be used to consume information from existing databases, implement lightweight middleware services, or to perform some quick application prototyping. </p> <p>Please note, RickDb does not implement any async functionality, and there are no plans to support it in the near future.</p>"},{"location":"#tldr-example","title":"TL;DR; example","text":"<p>A simple bookstore DTO and Repository example, with a custom query via QueryBuilder: <pre><code>from rick_db import fieldmapper, Repository\nfrom rick_db.conn.pg import PgConnection\nfrom rick_db.sql import Select, Literal\n@fieldmapper(tablename='publisher', pk='id_publisher')\nclass Publisher:\nid = 'id_publisher'\nname = 'name'\n@fieldmapper(tablename='book', pk='id_book')\nclass Book:\nid = 'id_book'\ntitle = 'title'\ntotal_pages = 'total_pages'\nrating = 'rating'\nisbn = 'isbn'\npublished = 'published_date'\nfk_publisher = 'fk_publisher'\n@fieldmapper(tablename='author', pk='id_author')\nclass Author:\nid = 'id_author'\nfirst_name = 'first_name'\nmiddle_name = 'middle_name'\nlast_name = 'last_name'\n@fieldmapper(tablename='book_author', pk='id_book_author')\nclass BookAuthor:\nid = 'id_book_author'\nfk_book = 'fk_book'\nfk_author = 'fk_author'\nclass AuthorRepository(Repository):\ndef __init__(self, db):\nsuper().__init__(db, Author)\ndef calc_avg_rating(self, id_author: int):\n\"\"\"\n        Calculate average rating for a given author\n        :param id_author: author id\n        :return: average rating, if any\n        \"\"\"\n# generated query:\n# SELECT avg(rating) AS \"rating\" FROM \"book\" INNER JOIN \"book_author\" ON \n# \"book\".\"id_book\"=\"book_author\".\"fk_book\" WHERE (\"fk_author\" = %s)\nqry = Select(self._dialect). \\\n            from_(Book, {Literal(\"avg({})\".format(Book.rating)): 'rating'}). \\\n            join(BookAuthor, BookAuthor.fk_book, Book, Book.id). \\\n            where(BookAuthor.fk_author, '=', id_author)\n# retrieve result as list of type Book (to get the rating field)\nrset = self.fetch(qry, cls=Book)\nif len(rset) &gt; 0:\nreturn rset.pop(0).rating\nreturn 0\ndef books(self, id_author: int) -&gt; list[Book]:\n\"\"\"\n        Retrieve all books for the given author\n        :return: list[Book]\n        \"\"\"\nqry = Select(self._dialect). \\\n            from_(Book). \\\n            join(BookAuthor, BookAuthor.fk_book, Book, Book.id). \\\n            where(BookAuthor.fk_author, '=', id_author)\nreturn self.fetch(qry, cls=Book)\ndef dump_author_rating(repo: AuthorRepository):\nfor author in repo.fetch_all():\n# calculate average\nrating = repo.calc_avg_rating(author.id)\n# print book list\nprint(\"Books by {firstname} {lastname}:\".format(firstname=author.first_name, lastname=author.last_name))\nfor book in repo.books(author.id):\nprint(book.title)\n# print average rating           \nprint(\"Average rating for {firstname} {lastname} is {rating}\".\nformat(firstname=author.first_name, lastname=author.last_name, rating=rating))\nif __name__ == '__main__':\ndb_cfg = {\n'dbname': \"rickdb-bookstore\",\n'user': \"rickdb_user\",\n'password': \"rickdb_pass\",\n'host': \"localhost\",\n'port': 5432,\n'sslmode': 'require'        \n}\nconn = PgConnection(**db_cfg)\nrepo = AuthorRepository(conn)\ndump_author_rating(repo)\n</code></pre></p>"},{"location":"building_queries/","title":"Building Queries","text":"<p>RickDb's Query Builder can generate SELECT, INSERT, DELETE and UPDATE queries. It also provides schema support (including cross-schema operations), JOIN support and recognizes Record objects for table and schema  identification.</p> <p>The query builder provides SQL generation using a fluent interface, suitable for most cases. Different database support is handled via dialect objects (extending from SqlDialect). The query builder itself will only generate a SQL string and a parameter value list; it is up to the developer to use the generated SQL in the appropriate database context.</p>"},{"location":"building_queries/#select","title":"Select","text":"<p>Selects are by far the most common statements, and can be easily built using a Select query builder object. Check the class documentation for more details on all available methods.</p> <p>Simple Select() examples:</p> <pre><code>from rick_db.sql import Select, PgSqlDialect\n# SELECT ALL\nqry, _ = Select(PgSqlDialect()).from_(\"table\").assemble()\n# output: SELECT \"table\".* FROM \"table\"\nprint(qry)\n# SELECT from 2 tables, with specific columns\nqry, _ = (\nSelect(PgSqlDialect())\n.from_(\"table1\", [\"table1_field\"])\n.from_(\"table2\", [\"table2_field\"])\n.assemble()\n)\n# output: SELECT \"table1_field\",\"table2_field\" FROM \"table1\", \"table2\"\nprint(qry)\n# SELECT WHERE\nqry, values = Select(PgSqlDialect()).from_(\"table\").where(\"id\", \"=\", 7).assemble()\n# output: SELECT \"table\".* FROM \"table\" WHERE (\"id\" = %s)\nprint(qry)\n</code></pre> <p>Table aliasing is also supported, as well as schema names: <pre><code>from rick_db.sql import Select, PgSqlDialect\n# SELECT w/ table alias and schema\nqry, _ = Select(PgSqlDialect()).from_({'table': 't1'}, schema='data').assemble()\n# output: SELECT \"t1\".* FROM \"data\".\"table\" AS \"t1\"\nprint(qry)\n</code></pre></p> <p>And, of course, columns can be aliased too: <pre><code>from rick_db.sql import Select, PgSqlDialect\n# SELECT w/ column alias\nqry, _ = Select(PgSqlDialect()).from_('table', {'id': 'id_table'}).assemble()\n# output: SELECT \"id\" AS \"id_table\" FROM \"table\"\nprint(qry)\n# SELECT w/ column alias, and non aliased field\nqry, _ = Select(PgSqlDialect()).from_('table', {'id': 'id_table', 'name':None}).assemble()\n# output: SELECT \"id\" AS \"id_table\",\"name\" FROM \"table\"\nprint(qry)\n</code></pre></p> <p>The query builder also fully supports Record classes or objects as table and schema identifiers:</p> <pre><code>from rick_db import fieldmapper\nfrom rick_db.sql import Select, PgSqlDialect\n@fieldmapper(tablename=\"publisher\", pk=\"id_publisher\")\nclass Publisher:\nid = \"id_publisher\"\nname = \"name\"\n@fieldmapper(tablename=\"book\", pk=\"id_book\")\nclass Book:\nid = \"id_book\"\ntitle = \"title\"\ntotal_pages = \"total_pages\"\nrating = \"rating\"\nisbn = \"isbn\"\npublished = \"published_date\"\nfk_publisher = \"fk_publisher\"\n# simple SELECT\nqry, values = Select(PgSqlDialect()).from_(Publisher).assemble()\n# output: SELECT \"publisher\".* FROM \"publisher\"\nprint(qry)\n# SELECT... WHERE\nqry, values = (\nSelect(PgSqlDialect())\n.from_(Book, [Book.title, Book.rating])\n.where(Book.id, \"=\", 5)\n.assemble()\n)\n# output: SELECT \"title\",\"rating\" FROM \"book\" WHERE (\"id_book\" = %s)\nprint(qry)\n# SELECT... JOIN\nqry, values = (\nSelect(PgSqlDialect())\n.from_(Book)\n.join(\nPublisher,\nPublisher.id,\nBook,\nBook.fk_publisher,\ncols={Publisher.name: \"publisher_name\"},\n)\n.assemble()\n)\n# output: SELECT \"book\".*,\"publisher\".\"name\" AS \"publisher_name\" FROM \"book\" INNER JOIN \"publisher\" ON \"book\".\"fk_publisher\"=\"publisher\".\"id_publisher\"\nprint(qry)\n</code></pre> <p>The Select Object also supports both AND and OR WHERE clauses, as well as nested parenthesis:</p> <pre><code>from rick_db.sql import Select, PgSqlDialect\n# SELECT... WHERE &lt;cond&gt; OR &lt;cond&gt;\nqry, values = (\nSelect(PgSqlDialect())\n.from_(Book)\n.where(Book.title, \"ILIKE\", \"%SQL%\")\n.orwhere(Book.rating, \"&gt;\", 4)\n.assemble()\n)\n# output: SELECT \"book\".* FROM \"book\" WHERE (\"title\" ILIKE %s) OR (\"rating\" &gt; %s)\nprint(qry)\n# SELECT... WHERE &lt;cond&gt; OR (&lt;cond&gt; AND &lt;cond&gt;)\nqry, values = (\nSelect(PgSqlDialect())\n.from_(Book)\n.where(Book.title, \"ILIKE\", \"%SQL%\")\n.where_or()\n.where(Book.rating, \"&gt;\", 4)\n.where(Book.total_pages, \"&gt;\", 150)\n.where_end()\n.assemble()\n)\n# output: SELECT \"book\".* FROM \"book\" WHERE (\"title\" ILIKE %s) OR ( (\"rating\" &gt; %s) AND (\"total_pages\" &gt; %s) )\nprint(qry)\n</code></pre> <p>Select Object supports LEFT JOIN, RIGHT JOIN, FULL JOIN, CROSS JOIN and NATURAL JOIN:</p> <pre><code>from rick_db.sql import Select, PgSqlDialect\n# LEFT JOIN\nqry, values = (\nSelect(PgSqlDialect())\n.from_(\"table1\")\n.join(\"table2\", \"id\", \"table1\", \"fk_table2\")\n.assemble()\n)\n# output: SELECT \"table1\".* FROM \"table1\" INNER JOIN \"table2\" ON \"table1\".\"fk_table2\"=\"table2\".\"id\"\nprint(qry)\n# RIGHT JOIN\nqry, values = (\nSelect(PgSqlDialect())\n.from_(\"table1\")\n.join_right(\"table2\", \"id\", \"table1\", \"fk_table2\")\n.assemble()\n)\n# output: SELECT \"table1\".* FROM \"table1\" RIGHT JOIN \"table2\" ON \"table1\".\"fk_table2\"=\"table2\".\"id\"\nprint(qry)\n# FULL JOIN\nqry, values = (\nSelect(PgSqlDialect())\n.from_(\"table1\")\n.join_full(\"table2\", \"id\", \"table1\", \"fk_table2\")\n.assemble()\n)\n# output: SELECT \"table1\".* FROM \"table1\" FULL JOIN \"table2\" ON \"table1\".\"fk_table2\"=\"table2\".\"id\"\nprint(qry)\n# CROSS JOIN\nqry, values = Select(PgSqlDialect()).from_(\"table1\").join_cross(\"table2\").assemble()\n# output: SELECT \"table1\".* FROM \"table1\" CROSS JOIN \"table2\"\nprint(qry)\n# NATURAL JOIN\nqry, values = Select(PgSqlDialect()).from_(\"table1\").join_natural(\"table2\").assemble()\n# output: SELECT \"table1\".* FROM \"table1\" NATURAL JOIN \"table2\"\nprint(qry)\n# mixed example\nqry, values = (\nSelect(PgSqlDialect())\n.from_(\"table1\")\n.join_right(\"table2\", \"id\", \"table1\", \"fk_table2\")\n.join(\"table3\", \"id\", \"table2\", \"fk_table3\")\n.join(\"table4\", \"id\", \"table3\", \"fk_table4\")\n.assemble()\n)\n# output: SELECT \"table1\".* FROM \"table1\" RIGHT JOIN \"table2\" ON \"table1\".\"fk_table2\"=\"table2\".\"id\" INNER JOIN \"table3\" ON \"table2\".\"fk_table3\"=\"table3\".\"id\" INNER JOIN \"table4\" ON \"table3\".\"fk_table4\"=\"table4\".\"id\"\nprint(qry)\n</code></pre> <p>It is also possible to use subselects:</p> <pre><code>from rick_db.sql import Select, PgSqlDialect\nsubselect = Select(PgSqlDialect()).from_(\"some_table\", [\"id\"]).where(\"field\", \"&gt;\", 32)\nqry, _ = (\nSelect(PgSqlDialect()).from_(\"table\").where(\"field\", \"IN\", subselect).assemble()\n)\n# output: SELECT \"table\".* FROM \"table\" WHERE (\"field\" IN (SELECT \"id\" FROM \"some_table\" WHERE (\"field\" &gt; %s)))\nprint(qry)\n</code></pre> <p>Also, custom SQL expressions are supported: <pre><code>from rick_db.sql import Select, PgSqlDialect, Literal\n# using a simple expression\nqry, _ = Select(PgSqlDialect()).expr([1]).assemble()\n# output: SELECT 1\nprint(qry)\n# using a simple expression\nqry, _ = Select(PgSqlDialect()).expr([1, 2, 3]).assemble()\n# output: SELECT 1,2,3\nprint(qry)\n# using LITERAL\nqry, _ = Select(PgSqlDialect()).from_('table', {Literal('COUNT(*)'):'total'}).assemble()\n# output: SELECT COUNT(*) AS \"total\" FROM \"table\"\nprint(qry)\n</code></pre></p>"},{"location":"building_queries/#insert","title":"Insert","text":"<p>Insert objects can be used to generate SQL INSERT statements, with optional RETURNING clause, and with full support for Record objects:</p> <pre><code>from rick_db.sql import Insert, PgSqlDialect\nfrom rick_db import fieldmapper\n@fieldmapper(tablename='publisher', pk='id_publisher')\nclass Publisher:\nid = 'id_publisher'\nname = 'name'\n# simple INSERT example\nqry = Insert(PgSqlDialect()).into('table').fields(['field']).values(['value'])\n# output: ('INSERT INTO \"table\" (\"field\") VALUES (%s)', ['value'])\nprint(qry.assemble())\n# INSERT w/ Record object\nrecord = Publisher(name='some publisher name')\nqry = Insert(PgSqlDialect()).into(record)\n# output: ('INSERT INTO \"publisher\" (\"name\") VALUES (%s)', ['some publisher name'])\nprint(qry.assemble())\n</code></pre> <p>It is possible to build an INSERT query to perform multiple inserts:</p> <pre><code>from rick_db.sql import Insert, PgSqlDialect\ndata = [\n['john', 'connor'],\n['sarah', 'connor']\n]\nsql = []\nqry = Insert(PgSqlDialect()).into('table').fields(['name', 'surname'])\nfor v in data:\nqry.values(v)\nsql.append(qry.assemble())\n# output: \n# [('INSERT INTO \"table\" (\"name\", \"surname\") VALUES (%s, %s)', ['john', 'connor']), \n# ('INSERT INTO \"table\" (\"name\", \"surname\") VALUES (%s, %s)', ['sarah', 'connor'])]\nprint(sql)\n</code></pre>"},{"location":"building_queries/#update","title":"Update","text":"<p>Update objects can be used to generate SQL UPDATE WHERE statements, with Record object support:</p> <pre><code>from rick_db.sql import Update, PgSqlDialect\n@fieldmapper(tablename='publisher', pk='id_publisher')\nclass Publisher:\nid = 'id_publisher'\nname = 'name'\n# simple UPDATE example\nqry = Update(PgSqlDialect()).table('table').fields(['field']).values(['value'])\n# output: ('UPDATE \"table\" SET \"field\"=%s', ['value'])\nprint(qry.assemble())\n# INSERT w/ Record object\nrecord = Publisher(name='some publisher name')\nqry = Update(PgSqlDialect()).table('tablename').values(record)\n# output: ('UPDATE \"tablename\" SET \"name\"=%s', ['some publisher name'])\nprint(qry.assemble())\n</code></pre> <p>WHERE clause support: <pre><code>from rick_db.sql import Update, PgSqlDialect\n# UPDATE WHERE... common usage\nqry = (\nUpdate(PgSqlDialect()).table(\"table\").values({\"field\": \"value\"}).where(\"id\", \"=\", 7)\n)\n# output: ('UPDATE \"table\" SET \"field\"=%s WHERE \"id\" = %s', ['value', 7])\nprint(qry.assemble())\n# UPDATE WHERE... no value\nqry = (\nUpdate(PgSqlDialect())\n.table(\"table\")\n.values({\"field\": \"value\"})\n.where(\"id\", \"IS NOT NULL\")\n)\n# output: ('UPDATE \"table\" SET \"field\"=%s WHERE \"id\" IS NOT NULL', ['value'])\nprint(qry.assemble())\n# UPDATE WHERE... with multiple clauses\nqry = (\nUpdate(PgSqlDialect())\n.table(\"table\")\n.values({\"field\": \"value\"})\n.where(\"id\", \"=\", 7)\n.where(\"name\", \"ILIKE\", \"john%\")\n)\n# output: ('UPDATE \"table\" SET \"field\"=%s WHERE \"id\" = %s AND \"name\" ILIKE %s', ['value', 7, 'john%'])\nprint(qry.assemble())\n</code></pre></p>"},{"location":"building_queries/#delete","title":"Delete","text":"<p>Delete objects can be used to generate SQL DELETE statements:</p> <pre><code>from rick_db.sql import Delete, PgSqlDialect\n# DELETE WHERE... common usage\nqry = Delete(PgSqlDialect()).from_(\"table\").where(\"id\", \"=\", 7)\n# output: ('DELETE FROM \"table\" WHERE \"id\" = %s', [7])\nprint(qry.assemble())\n# DELETE WHERE... no value\nqry = Delete(PgSqlDialect()).from_(\"table\").where(\"id\", \"IS NOT NULL\")\n# output: ('DELETE FROM \"table\" WHERE \"id\" IS NOT NULL', [])\nprint(qry.assemble())\n# DELETE WHERE... with multiple clauses\nqry = (\nDelete(PgSqlDialect())\n.from_(\"table\")\n.where(\"id\", \"=\", 7)\n.where(\"name\", \"ILIKE\", \"john%\")\n)\n# output: ('DELETE FROM \"table\" WHERE \"id\" = %s AND \"name\" ILIKE %s', [7, 'john%'])\nprint(qry.assemble())\n</code></pre>"},{"location":"building_queries/#with","title":"With","text":"<p>With objects can be used to generate CTE statements:</p> <pre><code>from rick_db import fieldmapper\nfrom rick_db.sql import Select, PgSqlDialect, With, Sql\n@fieldmapper(tablename=\"folder\", pk=\"id_folder\")\nclass FolderRecord:\nid = \"id_folder\"\nparent = \"fk_parent\"\ndialect = PgSqlDialect()\nunion = Select(dialect).union(\n[\nSelect(dialect).from_({FolderRecord: \"f1\"}).where(FolderRecord.id, \"=\", 19),\nSelect(dialect)\n.from_({FolderRecord: \"f2\"})\n.join(\"folder_tree\", FolderRecord.parent, \"f2\", FolderRecord.id),\n],\nSql.SQL_UNION_ALL,\n)\nqry = (\nWith()\n.clause(\"folder_tree\", union)\n.query(Select(dialect).from_(\"folder_tree\"))\n.recursive()\n)\n# output:\n# ('WITH RECURSIVE \"folder_tree\" AS (\n#   SELECT \"f1\".* FROM \"folder\" AS \"f1\" WHERE (\"id_folder\" = %s)\n#   UNION ALL\n#   SELECT \"f2\".* FROM \"folder\" AS \"f2\" INNER JOIN \"folder_tree\" ON \"f2\".\"id_folder\"=\"folder_tree\".\"fk_parent\"\n#   ) SELECT \"folder_tree\".* FROM \"folder_tree\"', [19])\nprint(qry.assemble())\n</code></pre>"},{"location":"connection/","title":"Connection","text":"<p>The connection object provides high-level methods to interact with the database, including cursor and transaction support, as well as a profiler. For more information on available methods, see Connection.</p>"},{"location":"connection/#connecting-to-postgresql","title":"Connecting to PostgreSQL","text":"<p>There are three PostgreSQL connectors available; however, it is advisable to use the regular PgConnection with an external connection pool, such as pgpool or equivalent.</p> <p>Available connection parameters:</p> Field Connector Description dbname All Database Name user All User name used to authenticate password All Password used to authenticate host All Database host (defaults to UNIX socket if not provided port All Connection port (defaults to 5432 if not provided sslmode All *SSL negotiation type: disable, allow, prefer, require minconn PgConnectionPool, PgThreadedConnectionPool Minimum number of connections to keep, defaults to 5 if not provided maxconn PgConnectionPool, PgThreadedConnectionPool Maximum number of connections to keep, defaults to 5 if not provided <p>*More details on sslmode operation are available in the libpq documentation. </p> <p>Using PgConnection:</p> <pre><code>from rick_db.conn.pg import PgConnection\nconfig = {\n'dbname': 'my_database',\n'user': '&lt;some_user&gt;',\n'password': '&lt;some_password&gt;',\n'host': 'localhost',\n'port': 5432,\n'sslmode': 'require'    \n}\n# create connection\nconn = PgConnection(**config)\n</code></pre> <p>Using PgConnectionPool:</p> <pre><code>from rick_db.conn.pg import PgConnectionPool\nconfig = {\n'dbname': 'my_database',\n'user': '&lt;some_user&gt;',\n'password': '&lt;some_password&gt;',\n'host': 'localhost',\n'port': 5432,\n'minconn': 4,\n}\n# create connection\nconn = PgConnectionPool(**config)\n</code></pre> <p>Using PgThreadedConnectionPool:</p> <pre><code>from rick_db.conn.pg import PgThreadedConnectionPool\nconfig = {\n'dbname': 'my_database',\n'user': '&lt;some_user&gt;',\n'password': '&lt;some_password&gt;',\n'host': 'localhost',\n'port': 5432,\n'minconn': 4,\n}\n# create connection\nconn = PgThreadedConnectionPool(**config)\n</code></pre>"},{"location":"connection/#connecting-to-sqlite","title":"Connecting to SQLite","text":"<p>Available connection parameters:</p> Field Description db_file Database file isolation_level Optional isolation level; defaults to empty if not provided timeout Timeout in seconds; defaults to 5.0 if not provided <p>Example: <pre><code>from rick_db.conn.sqlite import Sqlite3Connection\n# create or open a sqlite database\nconn = Sqlite3Connection('my_database.db')\n</code></pre></p>"},{"location":"connection/#using-a-profiler","title":"Using a profiler","text":"<p>RickDb provides a simple profiler interface that allows logging of queries, parameters and execution times, as well as a simple in-memory profiler implementation, DefaultProfiler.</p> <p>To use a DefaultProfiler instance on a connection, just assign the desired instance to the profiler property:</p> <pre><code>from rick_db.conn.pg import PgConnection\nfrom rick_db.profiler import DefaultProfiler\ndb_cfg = {\n'dbname': \"rick_test\",\n'user': \"rickdb_user\",\n'password': \"rickdb_password\",\n'sslmode': 'require'\n}\nconn = PgConnection(**db_cfg)\n# instantiate profiler, and use it on conn object\nconn.profiler = DefaultProfiler()\n# perform some queries we can profile\nwith conn.cursor() as c:\nc.exec(\"SELECT 1\")\n# output: SELECT 1 0.00012579001486301422\nfor evt in conn.profiler.get_events():\nprint(evt.query, evt.elapsed)\n</code></pre>"},{"location":"grid/","title":"DbGrid","text":"<p>DbGrid is a helper class to aid the creation of table-like listings(grids). It provides a clean, programmatic way of searching a given database object (or use a custom query) with string search, exact matching and pagination. </p> <p>It returns the total row count (without applying pagination), and the filtered row subset matching the pagination results.</p> <p>Example:</p> <pre><code>from rick_db import fieldmapper, Repository, DbGrid\nfrom rick_db.conn.pg import PgConnection\n@fieldmapper(tablename='product', pk='id_product')\nclass Product:\nid = 'id_product'\nshort_description = 'short_description'\nbrand = 'brand_id'\ndb_config = {\n\"dbname\": \"products\",\n\"user\": \"someUser\",\n\"password\": \"somePassword\",\n\"host\": \"localhost\",\n\"port\": 5432\n}\n# create connection\nconn = PgConnection(**db_config)\n# create a repository\nrepo = Repository(conn, Product)\n# create a grid\ngrid = DbGrid(\nrepo,                           # repository to use\n[Product.short_description],    # fields to perform text search\nDbGrid.SEARCH_ANY               # type of search\n)\n# retrieve first 10 results\n# total will have the total row count that matches the filters, without limit\ntotal, rows = grid.run(search_text='bag', match_fields={Product.brand: 12}, limit=10)\nprint(\"total matches:\", total)\nfor r in rows:\nprint(r.id, r.short_description)\n# retrieve second page of results\ntotal, rows = grid.run(search_text='bag', match_fields={Product.brand: 12}, limit=10, offset=10)\nfor r in rows:\nprint(r.id, r.short_description)\n</code></pre>"},{"location":"grid/#limitations","title":"Limitations:","text":"<p>Sqlite3</p> <p>On Sqlite3, case-insensitive search is done via UPPER(), since no ILIKE equivalent is available.  This is may trigger a full table scan and will not use indexes if they are available for the specific field. Additionally, this method only works with ASCII chars. </p> <p>It its therefore recommended to avoid the usage of case-sensitive search with this driver.</p> <p>As an option, one can instead use COLLATE NOCASE on the creation of the required fields, and use DbGrid with case_sensitive=True. This way, search will be case insensitive on the fields created with the COLLATE NOCASE option.  </p>"},{"location":"install/","title":"Installation","text":"<p>The recommended instalation procedure is to use the available pip package. Make sure you have psycopg2 and setuptools installed before proceeding.</p>"},{"location":"install/#required-dependencies","title":"Required dependencies","text":"<p>RickDb requires the following dependencies:</p> <ul> <li>pytest</li> <li>psycopg2</li> <li>toml</li> <li>setuptools</li> </ul> <p>Please note, most platforms have both psycopg2 and setuptools available as a separate, binary installed package.</p> <p>Installing psycopg2 and setuptools in Ubuntu (&gt;=18): <pre><code>$ sudo apt install  python3-setuptools python3-psycopg2\n</code></pre></p>"},{"location":"install/#installing-from-package","title":"Installing from package","text":"<p>RickDb is available in PyPi as a package, an can easily be installed using pip: <pre><code>$ pip install rick-db\n</code></pre></p>"},{"location":"install/#installing-from-source","title":"Installing from source","text":"<ol> <li> <p>clone the repository to a folder: <pre><code>$ git clone https://github.com/oddbit-project/rick_db.git\n$ cd rick_db\nrick_db$\n</code></pre></p> </li> <li> <p>install missing dependencies <pre><code>rick_db$ pip install -r requirements.txt\n</code></pre></p> </li> <li> <p>run setuptools from the repository folder: <pre><code>rick_db$ python3 setup.py install\n</code></pre></p> </li> </ol>"},{"location":"migrations/","title":"Migrations","text":"<p>RickDb is a schema-first library - there is no automatic generation of database objects; instead they are usually modeled using raw SQL, and kept in files separated from application code.</p> <p>While there are plenty of tools to manage migration, RickDb provides a simple, forward-only migration manager cli utility that can be used to manage these SQL files, rickdb.</p>"},{"location":"migrations/#why-forward-only","title":"Why forward-only?","text":"<p>Many database migration tools provide mechanisms to create and remove database objects, with the purpose of  rolling back schema changes. However, rolling back schema changes can lead to the truncation of relevant data; adding a field, then removing it will effectively truncate the stored information; however, adding a row with an  automatic identity field, then removing it will not rollback the underlying identity sequence value. While this kind of rollback capability is quite popular, it is obvious most SGBDs can't actually perform rollbacks the way they were conceptualized.</p> <p>Instead of this approach, RickDb's Migration Manager only supports \"forward-only\" migrations - a sequence of SQL files with the desired changes for a given database. These changes can be additive (e.g. creating tables and  views), transformational (e.g. adding fields or indexes) or destructive (e.g. removing tables, views, fields, etc).</p>"},{"location":"migrations/#configuration","title":"Configuration","text":"<p>The bundled Migration Manager requires a TOML configuration file, called by default rickdb.toml, containing  the database connection details. The file usually resides in the project root directory, but can also have a custom location, specified by the environment variable RICKDB_CONFIG.</p> <p>The TOML config file can have one or more database configuration keys. These keys may be a single default key db (for single database applications), or multiple, name-based keys prefixed with db_:</p> <p>Simple single-database configuration example:</p> <p><pre><code># single database, no name\n[db]\nengine = \"pgsql\"\nhost = \"localhost\"\nport = 5432\nuser = \"myuser\"\npassword = \"mypassword\"\ndbname = \"myschema\"\n</code></pre> Multiple database configuration example:</p> <pre><code># administration database\n[db_admin]\nengine = \"pgsql\"\nhost = \"localhost\"\nport = 5432\nuser = \"myuser\"\npassword = \"mypassword\"\ndbname = \"admin_schema\"\n# application database\n[db_app]\nengine = \"pgsql\"\nhost = \"localhost\"\nport = 5432\nuser = \"myuser\"\ndbname = \"app_schema\"\npassfile = \"/var/run/super_secret_pwd\"\n# test database\n[db_test]\nengine = \"sqlite\"\ndb_file = \"/tmp/test.db\"    </code></pre> <p>If a [db] section exists, it will be used when no database is specified in the cli arguments; db_&lt;name&gt; configurations can be invoked by providing &lt;name&gt; as the first argument:</p> <pre><code># use [db] database\n$ rickdb list 14/12/2021 18:28:56     001.sql\n15/12/2021 19:32:58     002.sql\n15/12/2021 19:33:42     003.sql\n\n# use [db_app] database\n$ rickdb app list\n15/12/2021 19:15:00     001_schema.sql\n</code></pre> <p>In addition to the parameters required by the connection object, there are two additional parameters:</p> Parameter Mandatory Description engine yes Database engine to use (currently \"pgsql\" or \"sqlite\") passfile no Optional password file containing the database password <p>Engine is a mandatory field that specifies which database Connection object will be used. Currently, its value can be either 'pgsql' or 'sqlite'.</p> <p>Passfile is an optional parameter indicating that the password should be read from an existing file instead. When passfile is used, the file is read into a password parameter automatically. Keep in mind, if both password and passfile are used, passfile overrides the password contents.</p>"},{"location":"migrations/#installation","title":"Installation","text":"<p>The Migration Manager requires a database table to record executed migration information. This database table can be easily created via command-line:</p> <p>Single database configuration: <pre><code>$ rickdb init\nMigration Manager installed sucessfully!\n$\n</code></pre></p> <p>Multiple database configuration, in this case for db_app: <pre><code>$ rickdb app init\nMigration Manager installed sucessfully!\n$\n</code></pre></p>"},{"location":"migrations/#creating-migrations","title":"Creating migrations","text":"<p>To create a migration, just create a directory with a set of SQL files. It is good practice to name the files sequentially, as migrations are executed ordered by name. The naming format is free-form, as long as the file has an .sql extension in lowercase.</p> <p>Common migration naming examples: <pre><code># sequence number\n0001.sql\n0002.sql\n\n# sequence number &amp; description\n0001-base_schema.sql\n0002-index_change_users.sql\n\n# ticket name &amp; description\nTICKET001-some_stuff.sql\nTICKET002-other_stuff.sql\n\n# date\n20210101-something.sql\n20210102-something_else.sql\n</code></pre> Keep in mind, each migration file should be treated as immutable - each file is only applied/executed once. Subsequent changes to the file will be ignored; any desired changes to the file after it has been run should be made on a separate  migration. </p>"},{"location":"migrations/#applying-migrations","title":"Applying migrations","text":"<p>The migration manager provides two useful commands to manage pending migrations - check and migrate.</p>"},{"location":"migrations/#rickdb-check-path","title":"rickdb check &lt;path&gt;","text":"<p>This command compares all migration names in the specified path with the already applied ones, indicating which ones were already applied:</p> <pre><code>$ rickdb check migrations/\nChecking 001.sql... already applied\nChecking 002.sql... already applied\nChecking 003.sql... new migration\n$\n</code></pre>"},{"location":"migrations/#rickdb-migrate-path","title":"rickdb migrate &lt;path&gt;","text":"<p>This command executes the new migrations, one by one, from the specified directory, ordered by file name. If any error occurs, execution is aborted. The migrations are not executed within a transaction, due to varying transaction support in  database engines; any required transaction blocks must be explicit, or there is always the possibility of failure in the middle of a multi-statement migration. Partially failed migrations are not registered (because execution is aborted), and should be handled manually.</p> <pre><code>$ rickdb migrate migrations/\nExecuting 001.sql... skipping, already applied\nExecuting 002.sql... skipping, already applied\nExecuting 003.sql... success\n$\n</code></pre>"},{"location":"migrations/#flattening-migrations","title":"Flattening migrations","text":"<p>During a schema-first application lifecycle, it is common to periodically combine all the migrations in a single sql file, or to replace them with a clean schema dump instead. This way, the number of migration files is kept to a sane level while assuming a certain schema state (either from a backup or from a plain file).</p> <p>When this is done, it is necessary to \"notify\" the migration manager that all the applied migrations ceased to exist, and now reside on a specific file to be ignored (except on clean deploys), as migrations have already been applied.</p> <p>To remove all those applied migration names and replace them with a single entry with a custom name, we use the  flatten command: <pre><code>$ rickdb flatten schema.sql\nFlattening all migrations to schema.sql... success\n</code></pre> In the above example, the migration manager will remove all information of applied migrations, and create a single entry with schema.sql as migration name.</p>"},{"location":"migrations/#generating-dtos","title":"Generating DTOs","text":"<p>In addition to the Migration Manager functionalities, rickdb cli also provides basic code-generation capabilities based on the object mapper - specifically, the capability of generating field mapper class definitions from database objects -  tables and views:</p> <pre><code>$ rickdb dto page page.py\nDAO written to file page.py\n$ cat page.py \nfrom rick_db import fieldmapper\n@fieldmapper(tablename='page', pk='id_page')\nclass Page:\nid = 'id_page'\ncrawled = 'crawled'\nurl = 'url'\ntype = 'type'\ntitle = 'title'\ndescription = 'description'\nbreadcrumbs = 'breadcrumbs'\n</code></pre> <p>And, of course, PostgreSQL schemas are supported out-of-the-box, too: <pre><code>$ rickdb dto test.some_page page.py\nDAO written to file page.py\n$ cat page.py \nfrom rick_db import fieldmapper\n@fieldmapper(tablename='some_page', schema='test', pk='id_page')\nclass SomePage:\nid = 'id_page'\ncrawled = 'crawled'\nurl = 'url'\ntype = 'type'\ntitle = 'title'\ndescription = 'description'\nbreadcrumbs = 'breadcrumbs'\n</code></pre></p>"},{"location":"object_mapper/","title":"Object Mapper","text":""},{"location":"object_mapper/#dto-records","title":"DTO Records","text":"<p>The RickDb object mapper allows the declaration of DTO (data transfer objects) classes, generically known as Records. A record contains a set of attributes and their corresponding field names in the database scope, and some optional additional details such as table name, schema and primary key information. The object mapper purpose is to manage the translation  of database fields to object attributes, and vice-versa.</p> <p>RickDb Records are pure data objects, as they don't depend on or reference any database-specific resource; they only hold attributes and values representing a result row from a given database operation. Attribute names are also independent of their database representation - the mapping between an attribute and the underlying field name is explicit, and performed in the declaration of the class.</p> <p>It is possible to declare Record objects that map only a subset of fields from a given query result; the additional fields will be ignored.</p> <p>These properties make Records a suitable format to carry data between architectural boundaries, not only due to their  decoupling from the underlying table structure, but also because they can be easily serialized and deserialized.</p> <p>To achieve better performance, the internal mapping of attributes to database field names is performed at load time within the class declaration context; a decorator patches the class definition with the required internal structures when the file is loaded, instead of handling it in runtime. </p>"},{"location":"object_mapper/#declaring-records","title":"Declaring Records","text":"<p>Record classes are declared using the @fieldmapper decorator:</p> <pre><code>from rick_db import fieldmapper\n@fieldmapper\nclass Customer:\nid = 'id_customer'  # attribute 'id' maps to field 'id_customer'\nname = 'name'       # attribute 'name' maps to field 'name'\naddress = 'address' # attribute 'address' maps to field 'address'\ncity = 'city'       # attribute 'city' maps to field 'city'\nid_country = 'fk_country' # attribute 'id_country' maps to field 'fk_country'\n# access class-level attributes\nprint(Customer.name) # outputs  'name'\n# access object-level attributes\n# customer data is loaded via __init__; The key names must match the defined attributes\ncustomer = Customer(id=3, name=\"John Doe\", address=\"Obere Str.\", city=\"Berlin\")\n# output: John Doe\nprint(customer.name)  \n# output: 'None'\nprint(customer.id_country)  \n# output: {'address': 'Obere Str.', 'city': 'Berlin', 'id': 3, 'name': 'John Doe'}\nprint(customer.asdict())\n# output: {'id_customer': 3, 'name': 'John Doe', 'address': 'Obere Str.', 'city': 'Berlin'}\nprint(customer.asrecord())\n</code></pre> <p>As mentioned previously, it is possible to also provide optional details, such as table or view name, schema and primary key name; these details are quite useful when using RickDb's Repository or Query Builder to provide context for operations. This is probably the most common usage scenario, when designing a multi-tier application:</p> <pre><code>from rick_db import fieldmapper\n@fieldmapper(tablename='customers', pk='id_customer', schema='public')\nclass Customer:\nid = 'id_customer'  # attribute 'id' maps to field 'id_customer'\nname = 'name'       # attribute 'name' maps to field 'name'\naddress = 'address' # attribute 'address' maps to field 'address'\ncity = 'city'       # attribute 'city' maps to field 'city'\nid_country = 'fk_country' # attribute 'id_country' maps to field 'fk_country'\n# access class-level attributes\nprint(Customer.name) # outputs  'name'\n# access object-level attributes\n# customer data is loaded via __init__; The key names must match the defined attributes\ncustomer = Customer(id=3, name=\"John Doe\", address=\"Obere Str.\", city=\"Berlin\")\n# output: John Doe\nprint(customer.name)  \n# output: 'None'\nprint(customer.id_country)  \n# output: {'address': 'Obere Str.', 'city': 'Berlin', 'id': 3, 'name': 'John Doe'}\nprint(customer.asdict())\n# output: {'id_customer': 3, 'name': 'John Doe', 'address': 'Obere Str.', 'city': 'Berlin'}\nprint(customer.asrecord())\n</code></pre>"},{"location":"object_mapper/#available-methods","title":"Available methods","text":"<p>The patching process performed by @fieldmapper copies all the available methods in the base Record class to the defined class. As a result, all Record methods can be used on a @fieldmapper patched  class.</p>"},{"location":"repository/","title":"Repositories","text":"<p>Repositories provide useful functions for Record interact with the database. They are also a Repository pattern implementation, as hinted by the naming. These constructs are quite handy in the segregation of the data access layer and the business logic or service layer in multi-layer applications, but can also be quite useful as a shortcut for common read, write or delete operations.</p> <p>For more details on all the available methods, check the Repository class documentation.</p>"},{"location":"repository/#declaring-repositories","title":"Declaring Repositories","text":"<p>A Repository class can be instantiated directly, or declared via direct inheritance. Typically, direct inheritance has the advantage of resulting in a properly named class that can be easily extendable by adding methods. Regardless, there are usage scenarios where direct instantiation can be quite convenient:</p> <pre><code>from rick_db import fieldmapper, Repository\nfrom rick_db.conn.pg import PgConnection\n@fieldmapper(tablename='character', pk='id_character')\nclass Character:\nid = 'id_character'\nname = 'name'\n# declare a Repository class for Character using inheritance\nclass CharacterRepository(Repository):\ndef __init__(self, db):\n# new constructor\nsuper().__init__(db, Character)\ndb_cfg = {...}\nconn = PgConnection(**db_cfg)\n# instantiate declared repository class\nrepo = CharacterRepository(conn)\n# insert some records\nrepo.insert(Character(id=1, name='Sarah Connor'))\nrepo.insert(Character(id=2, name='John Connor'))\n# read all records using the repo object\nfor record in repo.fetch_all():\nprint(record.name)\n# alternative method, instantiate a repository directly\nrepo = Repository(conn, Character)\n# use the repo object\nrepo.insert(Character(id=3, name='T-1000'))\n</code></pre>"},{"location":"repository/#extending-repositories","title":"Extending Repositories","text":"<p>Repository classes can also contain custom methods; This is the preferred approach when implementing additional database functionality. However, the methods should be designed to be stateless - they should not add or modify internal object attributes, nor depend on previous or future executions to carry their functions. By respecting this, Repository objects can be instantiated or reused in different contexts without any extra supervision:</p> <pre><code>from rick_db import fieldmapper, Repository\nfrom rick_db.sql import Select, Literal\n@fieldmapper(tablename='book', pk='id_book')\nclass Book:\nid = 'id_book'\ntitle = 'title'\ntotal_pages = 'total_pages'\nrating = 'rating'\nisbn = 'isbn'\npublished = 'published_date'\nfk_publisher = 'fk_publisher'\n@fieldmapper(tablename='author', pk='id_author')\nclass Author:\nid = 'id_author'\nfirst_name = 'first_name'\nmiddle_name = 'middle_name'\nlast_name = 'last_name'\n@fieldmapper(tablename='book_author', pk='id_book_author')\nclass BookAuthor:\nid = 'id_book_author'\nfk_book = 'fk_book'\nfk_author = 'fk_author'\nclass AuthorRepository(Repository):\ndef __init__(self, db):\nsuper().__init__(db, Author)\ndef calc_avg_rating(self, id_author: int):\n\"\"\"\n        Calculate average rating for a given author\n        :param id_author: author id\n        :return: average rating, if any\n        \"\"\"\n# generated query:\n# SELECT avg(rating) AS \"rating\" FROM \"book\" INNER JOIN \"book_author\" ON \n# \"book\".\"id_book\"=\"book_author\".\"fk_book\" WHERE (\"fk_author\" = %s)\nqry = Select(self._dialect). \\\n            from_(Book, {Literal(\"avg({})\".format(Book.rating)): 'rating'}). \\\n            join(BookAuthor, BookAuthor.fk_book, Book, Book.id). \\\n            where(BookAuthor.fk_author, '=', id_author)\n# retrieve result as list of type Book (to get the rating field)\nrset = self.fetch(qry, cls=Book)\nif len(rset) &gt; 0:\nreturn rset.pop(0).rating\nreturn 0\ndef books(self, id_author: int) -&gt; list[Book]:\n\"\"\"\n        Retrieve all books for the given author\n        :return: list[Book]\n        \"\"\"\nqry = Select(self._dialect). \\\n            from_(Book). \\\n            join(BookAuthor, BookAuthor.fk_book, Book, Book.id). \\\n            where(BookAuthor.fk_author, '=', id_author)\nreturn self.fetch(qry, cls=Book)\n</code></pre>"},{"location":"repository/#advanced-usage","title":"Advanced usage","text":"<p>While Repository objects are stateless from an operational perspective, there is actually an internal, thread-safe, global cache that is used to accelerate query building. Most Repository methods perform actions with SQL generated from the Query Builder, and these generated SQL statements can often be cached, due to the fact that any required values are passed in a separate structure.</p> <p>The cache operations within the Repository internal scope can be performed by using the protected methods _cache_get(key) and _cache_set(key, value). The key parameter is a unique identifier for the specific query within the Repository, and  will be internally concatenated with a database identifier, module and repository identifier. </p> <p>The typical usage scenario for cache interaction is: <pre><code>sql_string = _cache_get(string_method_name)\nif sql_string is None:\nsql_string, values = some_query.assemble()\n_cache_set(string_method_name, sql_string)\nelse:\nvalues = list_of_required_values\n(...)\n</code></pre></p> <p>The implementation of the actual Registry.fetch_pk() provides a good example of the typical pattern usage of the cache manipulation methods:</p> <pre><code>    (...)   \ndef fetch_pk(self, pk_value) -&gt; Optional[object]:\nif self._pk is None:\nraise RepositoryError(\"find_pk(): missing primary key in Record %s\" % str(type(self._record)))\n# try to fetch a finished SQL string from the cache, ready to use\n# the cache key is the method name\nqry = self._cache_get('find_pk')\nif qry is None:\n# if no cache match, we need to build the SQL string using the query builder\nqry, values = self.select().where(self._pk, '=', pk_value).limit(1).assemble()\n# ...and store the generated SQL string in the cache, for future usage\nself._cache_set('find_pk', qry)\nelse:\n# SQL string was successfully found in the cache, no need to use query builder\n# just build the required values list\nvalues = [pk_value]\n# execute SQL query and return the record           \nwith self._db.cursor() as c:\nreturn c.fetchone(qry, values, self._record)\n(...)\n</code></pre>"},{"location":"repository/#accessingpurging-the-repository-cache","title":"Accessing/Purging the Repository Cache","text":"<p>If necessary, the cache used for the Repository SQL statements can be inspected or purged. The global variable is  a rick_db.cache.StrCache instance, and can be accessed via rick_db.repository.query_cache:</p> <pre><code>from rick_db.repository import  query_cache\n# purge all cached items\nquery_cache.purge()\n</code></pre>"},{"location":"classes/connection/","title":"Class rick_db.conn.Connection","text":"<p>Base connection class for all database connections.</p>"},{"location":"classes/connection/#property-connectionprofiler","title":"@property Connection.profiler","text":"<p>Get or set the current profiler. By default, a connection is initialized with a NullProfiler. Check Profiler for details on the return type.</p>"},{"location":"classes/connection/#connectiondialect","title":"Connection.dialect()","text":"<p>Retrieve connection dialect. Check SqlDialect for more details on the return type.</p>"},{"location":"classes/connection/#connectionbegin","title":"Connection.begin()","text":"<p>Starts a database transaction. Raises ConnectionError exception if autocommit is enabled or a transaction is already opened.</p>"},{"location":"classes/connection/#connectioncommit","title":"Connection.commit()","text":"<p>Finishes (commit) a database transaction.</p>"},{"location":"classes/connection/#connectionrollback","title":"Connection.rollback()","text":"<p>Cancels (rollback) a database transaction.</p>"},{"location":"classes/connection/#connectiontransaction_status","title":"Connection.transaction_status()","text":"<p>Returns true if there is a started database transaction.</p>"},{"location":"classes/connection/#connectioncursor","title":"Connection.cursor()","text":"<p>Initializes and returns a new Cursor object.</p>"},{"location":"classes/connection/#connectionbackend","title":"Connection.backend()","text":"<p>Retrieve the underlying database connection object.</p>"},{"location":"classes/connection/#connectionmigration_manager","title":"Connection.migration_manager()","text":"<p>Retrieve the appropriate MigrationManager object instance for the current connection. The MigrationManager object can be used to manage database migrations.</p>"},{"location":"classes/connection/#connectionmetadata","title":"Connection.metadata()","text":"<p>Retrieve the appropriate Metadata object instance for the current connection. The Metadata object can be used to list internal database structures, such as tables, views, schemas and users.</p>"},{"location":"classes/connection/#connectionclose","title":"Connection.close()","text":"<p>Close database connection. If there is a started database transaction, the transaction will be cancelled.</p>"},{"location":"classes/cursor/","title":"Class rick_db.conn.Cursor","text":"<p>Provides cursor logic in a database-independent fashion.</p>"},{"location":"classes/cursor/#cursorexecqry-str-paramsnone-clsnone","title":"Cursor.exec(qry: str, params=None, cls=None)","text":"<p>Executes a SQL query specified in qry, with optional parameter list params. If cls, the specified class will be used to return objects via Object Mapper. The query may or may not return a result.</p>"},{"location":"classes/cursor/#cursorfetchoneqry-str-paramsnone-clsnone","title":"Cursor.fetchone(qry: str, params=None, cls=None)","text":"<p>Executes a SQL query specified in qry, with optional parameter list params and optional Object Mapper class defined via  cls. It will return a single result or None</p>"},{"location":"classes/cursor/#cursorfetchallqry-str-paramsnone-clsnone","title":"Cursor.fetchall(qry: str, params=None, cls=None)","text":"<p>Executes a SQL query specified in qry, with optional parameter list params and optional Object Mapper class defined via  cls. It will always return a list. If no records are to be returned, the list will be empty.</p>"},{"location":"classes/cursor/#cursorclose","title":"Cursor.close()","text":"<p>Closes current cursor.</p>"},{"location":"classes/cursor/#cursorget_cursor","title":"Cursor.get_cursor()","text":"<p>Retrieve underlying cursor object.</p>"},{"location":"classes/dbgrid/","title":"Class rick_db.sql.DbGrid","text":""},{"location":"classes/dbgrid/#const-dbgridsearch_none","title":"Const DbGrid.SEARCH_NONE","text":"<p>No search to be done.</p>"},{"location":"classes/dbgrid/#const-dbgridsearch_any","title":"Const DbGrid.SEARCH_ANY","text":"<p>Find matches with a different start or ending.</p>"},{"location":"classes/dbgrid/#const-dbgridsearch_start","title":"Const DbGrid.SEARCH_START","text":"<p>Find matches tha start with the expression.</p>"},{"location":"classes/dbgrid/#const-dbgridsearch_end","title":"Const DbGrid.SEARCH_END","text":"<p>Find matches tha end with the expression.</p>"},{"location":"classes/dbgrid/#dbgrid__init__repo-repository-search_fields-list-none-search_type-int-none-case_sensitivefalse","title":"DbGrid.__init__(repo: Repository, search_fields: list = None, search_type: int = None, case_sensitive=False)","text":"<p>Initialize a DbGrid() object, using the Repository repo, a list of field names to be searched in search_fields, with the search type search_type (see SEARCH_NONE, SEARCH_ANY,  SEARCH_START, SEARCH_END), and if case_sensitive is True, a case-sensitive search is performed.</p>"},{"location":"classes/dbgrid/#dbgriddefault_query","title":"DbGrid.default_query():","text":"<p>Build and returns the Select() object to be used internally for DbGrid. This method can be overridden for specific implementations.</p>"},{"location":"classes/dbgrid/#dbgriddefault_sort","title":"DbGrid.default_sort():","text":"<p>Build and returns the default sort dictionary. It can be overridden for specific implementations.</p>"},{"location":"classes/dbgrid/#dbgridrunqry-select-none-search_text-str-none-match_fields-dict-none-limit-int-none-offset-int-none-sort_fields-dict-none-search_fields-list-none","title":"DbGrid.run(qry: Select = None, search_text: str = None, match_fields: dict = None, limit: int = None, offset: int = None, sort_fields: dict = None, search_fields: list = None):","text":"<p>Executes a query and returns a tuple with the total row count matching the query, and the records within the specified range  defined by offset and limit, sorted by sort_fields.</p> <p>If qry is None, DbGrid.default_query() is used. If search_text is specified, a LIKE/ILIKE search is performed in the searchable fields defined in the constructor. Specific search fields can be specified, within the set of fields specified in the constructor. match_fields is an optional {field_name:value} dict to perform exact  match (field=value).</p> <p>Example: <pre><code>from rick_db import fieldmapper, Repository, DbGrid\nfrom rick_db.conn.pg import PgConnection\n@fieldmapper(tablename=\"product\", pk=\"id_product\")\nclass Product:\nid = \"id_product\"\nshort_description = \"short_description\"\nbrand = \"brand_id\"\ndb_config = {\n\"dbname\": \"products\",\n\"user\": \"someUser\",\n\"password\": \"somePassword\",\n\"host\": \"localhost\",\n\"port\": 5432,\n}\n# create connection\nconn = PgConnection(**db_config)\n# create a repository\nrepo = Repository(conn, Product)\n# create a grid\ngrid = DbGrid(\nrepo,  # repository to use\n[Product.short_description],  # fields to perform text search\nDbGrid.SEARCH_ANY,  # type of search\n)\n# retrieve first 10 results\n# total will have the total row count that matches the filters, without limit\ntotal, rows = grid.run(search_text=\"bag\", match_fields={Product.brand: 12}, limit=10)\nprint(\"total matches:\", total)\nfor r in rows:\nprint(r.id, r.short_description)\n# retrieve second page of results\ntotal, rows = grid.run(\nsearch_text=\"bag\", match_fields={Product.brand: 12}, limit=10, offset=10\n)\nfor r in rows:\nprint(r.id, r.short_description)\n</code></pre></p>"},{"location":"classes/delete/","title":"Class rick_db.sql.Delete","text":""},{"location":"classes/delete/#delete__init__dialect-sqldialect-none","title":"Delete.__init__(dialect: SqlDialect = None)","text":"<p>Initialize a Delete() object, using a database dialect. If no dialect is provided, a default dialect will be used. Check SqlDialect for more details.</p>"},{"location":"classes/delete/#deletefrom_table-schemanone","title":"Delete.from_(table, schema=None):","text":"<p>Defines the target table name and schema for deletion. table can be a Record object.</p> <p>Example: <pre><code># simple DELETE example\nqry = Delete(PgSqlDialect()).from_('table')\n# output: ('DELETE FROM \"table\"', [])\nprint(qry.assemble())\n# DELETE w/ Record object\nrecord = Publisher(name='some publisher name')\nqry = Delete(PgSqlDialect()).from_(record)\n# output: ('DELETE FROM \"publisher\"', [])\nprint(qry.assemble())\n</code></pre></p>"},{"location":"classes/delete/#deletewherefield-operatornone-valuenone","title":"Delete.where(field, operator=None, value=None)","text":"<p>Adds a WHERE clause to the DELETE clause. It requires a mandatory field name and an operator, and allows an optional value. Clauses generated by multiple calls to this method are concatenated with AND. </p> <p>Example:</p> <pre><code># DELETE WHERE... common usage\nqry = Delete(PgSqlDialect()).from_(\"table\").where(\"id\", \"=\", 7)\n# output: ('DELETE FROM \"table\" WHERE \"id\" = %s', [7])\nprint(qry.assemble())\n# DELETE WHERE... no value\nqry = Delete(PgSqlDialect()).from_(\"table\").where(\"id\", \"IS NOT NULL\")\n# output: ('DELETE FROM \"table\" WHERE \"id\" IS NOT NULL', [])\nprint(qry.assemble())\n# DELETE WHERE... with multiple clauses\nqry = (\nDelete(PgSqlDialect())\n.from_(\"table\")\n.where(\"id\", \"=\", 7)\n.where(\"name\", \"ILIKE\", \"john%\")\n)\n# output: ('DELETE FROM \"table\" WHERE \"id\" = %s AND \"name\" ILIKE %s', [7, 'john%'])\nprint(qry.assemble())\n</code></pre>"},{"location":"classes/delete/#deleteorwherefield-operatornone-valuenone","title":"Delete.orwhere(field, operator=None, value=None)","text":"<p>Adds a WHERE clause to the DELETE clause. It requires a mandatory field name and an operator, and allows an optional value. Clauses generated by multiple calls to this method are concatenated with OR. </p> <p>Example:</p> <pre><code>qry = (\nDelete(PgSqlDialect())\n.from_(\"table\")\n.where(\"id\", \"=\", 7)\n.orwhere(\"name\", \"ILIKE\", \"john%\")\n)\n# output: ('DELETE FROM \"table\" WHERE \"id\" = %s OR \"name\" ILIKE %s', [7, 'john%'])\nprint(qry.assemble())\n</code></pre>"},{"location":"classes/delete/#deleteassemble","title":"Delete.assemble()","text":"<p>Assembles DELETE SQL string and returns a tuple with (sql_string, list_of_values). If an error occurs, SqlError is raised.</p> <p>Example:</p> <pre><code># simple DELETE example\nqry = Delete(PgSqlDialect()).from_('table')\n# output: ('DELETE FROM \"table\"', [])\nprint(qry.assemble())\n</code></pre>"},{"location":"classes/insert/","title":"Class rick_db.sql.Insert","text":""},{"location":"classes/insert/#insert__init__dialect-sqldialect-none","title":"Insert.__init__(dialect: SqlDialect = None)","text":"<p>Initialize a Insert() object, using a database dialect. If no dialect is provided, a default dialect will be used. Check SqlDialect for more details.</p>"},{"location":"classes/insert/#insertintotable-schemanone","title":"Insert.into(table, schema=None)","text":"<p>Defines the target table name and schema. If table is a Record object, it will also load fields and values from this object.</p> <p>Example: <pre><code># simple INSERT example\nqry = Insert(PgSqlDialect()).into('table').fields(['field']).values(['value'])\n# output: ('INSERT INTO \"table\" (\"field\") VALUES (%s)', ['value'])\nprint(qry.assemble())\n# INSERT w/ Record object\nrecord = Publisher(name='some publisher name')\nqry = Insert(PgSqlDialect()).into(record)\n# output: ('INSERT INTO \"publisher\" (\"name\") VALUES (%s)', ['some publisher name'])\nprint(qry.assemble())\n</code></pre></p>"},{"location":"classes/insert/#insertfieldsfields-list","title":"Insert.fields(fields: list)","text":"<p>Defines the field names for insertion. The length of fields list must match the list of provided values.</p> <p>Example: <pre><code>data = [\n['john', 'connor'],\n['sarah', 'connor']\n]\nsql = []\nqry = Insert(PgSqlDialect()).into('table').fields(['name', 'surname'])\nfor v in data:\nqry.values(v)\nsql.append(qry.assemble())\n# output: \n# [('INSERT INTO \"table\" (\"name\", \"surname\") VALUES (%s, %s)', ['john', 'connor']), \n# ('INSERT INTO \"table\" (\"name\", \"surname\") VALUES (%s, %s)', ['sarah', 'connor'])]\nprint(sql)\n</code></pre></p>"},{"location":"classes/insert/#insertvaluesvalues-unionlist-dict-object","title":"Insert.values(values: Union[list, dict, object])","text":"<p>Define values to be inserted. This method can be called multiple times (see fields() for an example). If values is a dict, both fields and values are read from the provided dict. If values is a Record object, fields and values are read from the object.</p> <p>Example: <pre><code># simple INSERT example\nqry = Insert(PgSqlDialect()).into('table').fields(['field']).values(['value'])\n# output: ('INSERT INTO \"table\" (\"field\") VALUES (%s)', ['value'])\nprint(qry.assemble())\n# INSERT w/ Record object\nrecord = Publisher(name='some publisher name')\nqry = Insert(PgSqlDialect()).into('tablename').values(record)\n# output: ('INSERT INTO \"tablename\" (\"name\") VALUES (%s)', ['some publisher name'])\nprint(qry.assemble())\n</code></pre></p>"},{"location":"classes/insert/#insertreturningfields","title":"Insert.returning(fields)","text":"<p>Adds a RETURNING clause to the INSERT. fields is a string or list of field names to be returned.</p> <p>Example:</p> <pre><code># simple INSERT example\nqry = Insert(PgSqlDialect()).into('tablename').fields(['field']).values(['value']).returning(['id', 'field'])\n# output: ('INSERT INTO \"tablename\" (\"field\") VALUES (%s) RETURNING \"id\", \"field\"', ['value'])\nprint(qry.assemble())\n# INSERT w/ Record object\nrecord = Publisher(name='some publisher name')\nqry = Insert(PgSqlDialect()).into('tablename').values(record).returning('id')\n# output: ('INSERT INTO \"tablename\" (\"name\") VALUES (%s) RETURNING \"id\"', ['some publisher name'])\nprint(qry.assemble())\n</code></pre>"},{"location":"classes/insert/#insertget_values","title":"Insert.get_values()","text":"<p>Returns list of current values.</p> <p>Example:</p> <pre><code>qry = Insert(PgSqlDialect()).into('tablename').fields(['field']).values(['value'])\n# output: ['value']\nprint(qry.get_values())\n</code></pre>"},{"location":"classes/insert/#insertassemble","title":"Insert.assemble()","text":"<p>Assembles INSERT SQL string and returns a tuple with (sql_string, list_of_values). If an error occurs, SqlError is raised.</p> <p>Example:</p> <pre><code># simple INSERT example\nqry = Insert(PgSqlDialect()).into('table').fields(['field']).values(['value'])\n# output: ('INSERT INTO \"table\" (\"field\") VALUES (%s)', ['value'])\nprint(qry.assemble())\n</code></pre>"},{"location":"classes/literal/","title":"Class rick_db.sql.Literal","text":"<p>Class used to encapsulate literal values</p>"},{"location":"classes/literal/#literal__init__literal","title":"Literal.__init__(literal)","text":"<p>Create a Literal object with literal as content <pre><code>qry, _ = Select(PgSqlDialect()).from_('table', {Literal('COUNT(*)'): 'total'}).assemble()\n# output: SELECT COUNT(*) AS \"total\" FROM \"table\"\nprint(qry)\n</code></pre></p>"},{"location":"classes/profiler/","title":"rick_db.profiler","text":"<p>Classes related to the SQL Profiler implementation.</p>"},{"location":"classes/profiler/#class-rick_dbprofilerevent","title":"Class rick_db.profiler.Event","text":"<p>Dataclass for a single event entry. Available properties:</p> <pre><code>@dataclass\nclass Event:\ntimestamp: float\nquery: str\nparameters: dict\nelapsed: float\n</code></pre>"},{"location":"classes/profiler/#class-rick_dbprofilereventcollection","title":"Class rick_db.profiler.EventCollection","text":"<p>A list-based class to hold a collection of Event objects.</p>"},{"location":"classes/profiler/#eventcollectionfilter_durationduration-float","title":"EventCollection.filter_duration(duration: float)","text":"<p>Retrieve a list of Event objects whose duration is bigger than or equal to duration.</p>"},{"location":"classes/profiler/#class-rick_dbprofilerprofiler","title":"Class rick_db.profiler.Profiler","text":"<p>Base profiler class. Implements an interface for the Profiler classes.</p>"},{"location":"classes/profiler/#profileradd_eventquery-str-parameters-dict-duration-float","title":"Profiler.add_event(query: str, parameters: dict, duration: float)","text":"<p>Create a new profiling event based on the passed query, parameters and duration, and add it to the internal event collection.</p>"},{"location":"classes/profiler/#profilerclear","title":"Profiler.clear()","text":"<p>Purge (clear) all stored events.</p>"},{"location":"classes/profiler/#profilerget_events","title":"Profiler.get_events()","text":"<p>Return internal profiling event collection.</p>"},{"location":"classes/profiler/#class-rick_dbprofilernullprofiler","title":"Class rick_db.profiler.NullProfiler","text":"<p>A Profiler-based class with dummy behaviour, to be used when no profiler is desired.</p>"},{"location":"classes/profiler/#class-rick_dbprofilerdefaultprofiler","title":"Class rick_db.profiler.DefaultProfiler","text":"<p>A Profiler-based class. Events are kept in-memory.</p>"},{"location":"classes/record/","title":"Class rick_db.Record","text":"<p>The base Record class definition for all Object Mapper classes. Instead of inheritance, the Record class method attributes are copied to the final class, via attribute patching performed by the @fieldmapper decorator.</p> <p>Classes patched from Record inherit several useful methods, not only in the Object Mapper context, but also for general usage such as serialization/deserialization or type conversion.</p>"},{"location":"classes/record/#recordloadkwargs","title":"Record.load(**kwargs)","text":"<p>Loads attribute values from the provided named parameters.  Note: loading can also be done via constructor</p> <p>Example: <pre><code>from rick_db import fieldmapper\n@fieldmapper\nclass MyRecord:\nid = 'id_record'\nname = 'name'\n# load values via constructor\nr1 = MyRecord(id=1, name='Sarah Connor')\n# load values via load()\nr2 = MyRecord().load(id=2, name='John Connor')\n</code></pre></p>"},{"location":"classes/record/#recordfromrecordrecord-dict","title":"Record.fromrecord(record: dict)","text":"<p>Load attribute values from a source dict. This method is used to load database row results into Record objects, and it is performance-sensitive - the attribute names aren't checked, and the values aren't actually copied, but referenced  instead. Don't use this with mutable sources, as it will also change the Record object values.</p>"},{"location":"classes/record/#recordhas_pk","title":"Record.has_pk()","text":"<p>Returns True if a primary key definition (pk field in the decorator) exists. </p>"},{"location":"classes/record/#recordpk","title":"Record.pk()","text":"<p>Return the primary key value, if primary key is defined and a value is set. If a primary key is defined, but no value is present, raises AttributeError instead.</p>"},{"location":"classes/record/#recorddbfields","title":"Record.dbfields()","text":"<p>Returns a list of the database field names, defined in the class declaration.</p> <p>Example: <pre><code>from rick_db import fieldmapper\n@fieldmapper\nclass MyRecord:\nid = 'id_record'\nname = 'name'\nr1 = MyRecord(id=1, name='Sarah Connor')\n# output: ['id_record', 'name']\nprint(r1.dbfields())\n</code></pre></p>"},{"location":"classes/record/#recordasdict","title":"Record.asdict()","text":"<p>Converts the Record object to a dictionary and returns it. Attribute names are used as keys for existing values.</p> <p>Example: <pre><code>from rick_db import fieldmapper\n@fieldmapper\nclass MyRecord:\nid = 'id_record'\nname = 'name'\nr1 = MyRecord(id=1, name='Sarah Connor')\n# output: {'id': 1, 'name': 'Sarah Connor'}\nprint(r1.asdict())\n</code></pre></p>"},{"location":"classes/record/#recordasrecord","title":"Record.asrecord()","text":"<p>Converts the Record object to a database-compatible dictionary and returns it. Field names are used as keys for existing values.</p> <p>Example: <pre><code>from rick_db import fieldmapper\n@fieldmapper\nclass MyRecord:\nid = 'id_record'\nname = 'name'\nr1 = MyRecord(id=1, name='Sarah Connor')\n# output: {'id_record': 1, 'name': 'Sarah Connor'}\nprint(r1.asrecord())\n</code></pre></p>"},{"location":"classes/record/#recordfields","title":"Record.fields()","text":"<p>Alias function to Record.asdict().items()</p> <p>Example: <pre><code>from rick_db import fieldmapper\n@fieldmapper\nclass MyRecord:\nid = 'id_record'\nname = 'name'\nr1 = MyRecord(id=1, name='Sarah Connor')\n# output: ['id', 'name']\nprint(r1.fields())\n</code></pre></p>"},{"location":"classes/record/#recordvalues","title":"Record.values()","text":"<p>Returns a list with stored values.</p> <p>Example: <pre><code>from rick_db import fieldmapper\n@fieldmapper\nclass MyRecord:\nid = 'id_record'\nname = 'name'\nr1 = MyRecord(id=1, name='Sarah Connor')\n# output: [1, 'Sarah Connor']\nprint(r1.values())\n</code></pre></p>"},{"location":"classes/repository/","title":"rick_db.Repository","text":""},{"location":"classes/repository/#class-baserepository","title":"Class BaseRepository","text":"<p>Internal top-level repository type.</p>"},{"location":"classes/repository/#baserepositorybackend","title":"BaseRepository.backend()","text":"<p>Return the internal Connection object.</p>"},{"location":"classes/repository/#baserepositorydialect","title":"BaseRepository.dialect()","text":"<p>Return the internal SqlDialect object used by the current connection.</p>"},{"location":"classes/repository/#class-repositorybaserepository","title":"Class Repository(BaseRepository)","text":"<p>The parent Repository class implementation, to be extended to implement specific Record repositories.</p>"},{"location":"classes/repository/#repositorydb-record_type","title":"Repository(db, record_type)","text":"<p>Repository constructor. Receives a Connection object, db, and a Record class, record_type. The record_type class will provide the schema, table name and primary key information, and be used as a data type for methods that return records or collections.</p>"},{"location":"classes/repository/#repositoryselectcolsnone","title":"Repository.select(cols=None)","text":"<p>Return a Select query builder instance for the current table, with an optional column list, cols.</p>"},{"location":"classes/repository/#repositoryfetch_pkpk_value","title":"Repository.fetch_pk(pk_value)","text":"<p>Attempt to read a record  from the database by primary key value. It will return a record of the defined record_type on  success, None if no record exists. Will raise RepositoryError if the record_type doesn't have a primary key definition.</p> <p>Example: <pre><code>(...)\n# try to fetch record with pk=32\nrecord = repo.fetch_pk(32)\nif record is not None:\nprint(\"record 32 exists\")\n</code></pre></p>"},{"location":"classes/repository/#repositoryfetch_oneqry-select","title":"Repository.fetch_one(qry: Select)","text":"<p>Execute the qry Select statement and return a single record. If there is no record to return, will return None.</p> <p>Example: <pre><code>(...)\n# fetch record if exists, else returns None\nuser = repo.fetch_one(repo.select().where('login', '=', 'gandalf@lotr'))\n</code></pre></p>"},{"location":"classes/repository/#repositoryfetchqry-select-clsnone","title":"Repository.fetch(qry: Select, cls=None)","text":"<p>Execute the qry Select statement and return a list of records. If there is nothing to return, will return and empty list. If a record class is specified in cls, this class will be used as record_type instead of the repository definition. This is useful to e.g. return join results that may return a different record type. </p> <p>Example: <pre><code>(...)\n# fetch a list of records from a query\nfor r in repo.fetch(repo.select().where('name', 'like', 'gandalf%')):\nprint(r.name)\n</code></pre></p>"},{"location":"classes/repository/#repositoryfetch_rawqry-select","title":"Repository.fetch_raw(qry: Select)","text":"<p>Execute the qry Select statement, but no record conversion is performed on the result - it will return  the raw result dataset, a collection of dict-like structures, from the database connection. If there is nothing to return, will return and empty list. </p> <p>Example: <pre><code>(...)\n# fetch a list of records from a query\nfor r in repo.fetch_raw(repo.select().where('name', 'like', 'gandalf%')):\nprint(r['name'])\n</code></pre></p>"},{"location":"classes/repository/#repositoryfetch_by_fieldfield-value-colsnone","title":"Repository.fetch_by_field(field, value, cols=None)","text":"<p>Fetch a list of rows where field matches a value. An optional list of fields to be returned can be defined with cols. It returns a record list, or an empty list if no match is found.</p> <p>Example: <pre><code>(...)\n# fetch records where login='gandalf@lotr'\nuser = repo.fetch_by_field('login', 'gandalf@lotr')\n</code></pre></p>"},{"location":"classes/repository/#repositoryfetch_wherewhere_clauses-list-colsnone","title":"Repository.fetch_where(where_clauses: list, cols=None)","text":"<p>Fetch a list of rows that match a list of WHERE clauses. If more than one clause is present, they are concatenated with AND.  An optional list of fields to be returned can be defined with cols.  It returns a record list, or an  empty list if no match is found.</p> <p>A where clause is a list of tuples in the form of (field, operator, value). See the example below for more details.</p> <p>Example: <pre><code>(...)\n# fetch 'name' field from records matching a where clause \nfor r in repo.fetch_where([('name', 'like', 'gandalf%'), ], cols=['name']):\nprint(r.name)\n</code></pre></p>"},{"location":"classes/repository/#repositoryfetch_all","title":"Repository.fetch_all()","text":"<p>Fetch all rows; equivalent to a SELECT * FROM . It returns a record list, or an empty list if  the table is empty. <p>Example: <pre><code>(...)\n# fetch all records \nfor r in repo.fetch_all():\nprint(r.name)\n</code></pre></p>"},{"location":"classes/repository/#repositoryfetch_all_orderedcol_namestr-ordersqlsql_asc","title":"Repository.fetch_all_ordered(col_name:str, order=Sql.SQL_ASC)","text":"<p>Fetch all rows ordered by col_name and order direction; equivalent to a SELECT * FROM  ORDER BY col_name order. It returns a record list, or an empty list if the table is empty. <p>Example: <pre><code>(...)\n# fetch all records \nfor r in repo.fetch_all_ordered(Character.name,Sql.SQL_DESC):\nprint(r.name)\n</code></pre></p>"},{"location":"classes/repository/#repositoryinsertrecord-colsnone","title":"Repository.insert(record, cols=None)","text":"<p>Insert a new record, optionally returning values. If the database does not support INSERT...RETURNING, cols can only have one entry, and the primary key will be returned regardless of the actual field name.</p> <p>Example: <pre><code># insert a new record, returns None\nrepo.insert(Character(name=\"John Connor\"))\n# insert a new record, returns a record with id filled\nrecord = repo.insert(Character(name=\"Sarah Connor\"), cols=['id'])\nif record is not None:\nprint(record.id)\n</code></pre></p>"},{"location":"classes/repository/#repositoryinsert_pkrecord","title":"Repository.insert_pk(record)","text":"<p>Insert a new record and return the primary key value, or None if database doesn't return any value. If no primary key  is defined, will raise RepositoryError. </p> <p>Example: <pre><code># insert a new record, returns a record with id filled\nid = repo.insert_pk(Character(name=\"John Connor\"))\nif id is not None:\nprint(id)\n</code></pre></p>"},{"location":"classes/repository/#repositorydelete_pkpk_value","title":"Repository.delete_pk(pk_value)","text":"<p>Remove a record identified by primary key value.  If no primary key is defined, will raise RepositoryError. </p> <p>Example: <pre><code># remove record #32\nrepo.delete_pk(32)\n</code></pre></p>"},{"location":"classes/repository/#repositorydelete_wherewhere_clauses-list","title":"Repository.delete_where(where_clauses: list)","text":"<p>Remove records matching a list of WHERE clauses. If more than one clause is present, they are concatenated with AND.</p> <p>A where clause is a list of tuples in the form of (field, operator, value). See the example below for more details.</p> <p>Example: <pre><code># remove records WHERE name='gandalf' AND name='frodo'\nrepo.delete_where([('name', '=', 'gandalf'), ('name', '=', 'frodo')])\n</code></pre></p>"},{"location":"classes/repository/#repositorymap_result_idresult-list","title":"Repository.map_result_id(result: list)","text":"<p>Transform a list of records into a dict indexed by primary key. If no primary key is defined, raises RepositoryError.</p> <p>Example: <pre><code>records = [\nCharacter(id=1, name=\"John Connor\"),\nCharacter(id=2, name=\"Sarah Connor\"),\n]\n# idx_records = { 1: Character(id=1, name=\"John Connor\"), 2: Character(id=2, name=\"Sarah Connor\") } \nidx_records = repo.map_result_id(records)\n</code></pre></p>"},{"location":"classes/repository/#repositoryvalid_pkpk_value","title":"Repository.valid_pk(pk_value)","text":"<p>Returns True if a row exists with a primary key value matching pk_value, or False otherwise. If no primary key is defined, raises RepositoryError.</p> <p>Example: <pre><code>if repo.valid_pk(32):\n# record with pk=32 exists\n(...)\n</code></pre></p>"},{"location":"classes/repository/#repositoryexecsql-valuesnone-clsnone-useclstrue","title":"Repository.exec(sql, values=None, cls=None, useCls=True)","text":"<p>Execute a raw SQL query. Query values must be passed via values. If useCls is True (default), returned database rows are converted to a list of records. If a Record class is specified via cls, it will be used instead of the internal record_type for record serialization.</p> <p>Example: <pre><code>for r in repo.exec('SELECT * FROM characters WHERE id=%s', [32,]):\nprint(r.name)\n</code></pre></p>"},{"location":"classes/repository/#repositoryexistsfield-value-pk_to_skip","title":"Repository.exists(field, value, pk_to_skip)","text":"<p>Returns True if a record exists WHERE field=value AND primary_key &lt;&gt; pk_to_skip. If no primary key is defined, raises RepositoryError. This is useful to check for uniqueness.</p> <p>Example: <pre><code>can_update = repo.exists('login', 'gandalf@lotr', 32)\nif not can_update:\nprint(\"A record already exists with the same login value\")\n</code></pre></p>"},{"location":"classes/repository/#repositoryupdaterecord-pk_valuenone","title":"Repository.update(record, pk_value=None)","text":"<p>Updates a record on the database by primary key. If record contains a primary key value, it will be used instead  of pk_value. If record doesn't contain a primary key value, pk_value is required.</p> <p>Example: <pre><code>record = Character(name='T-1000')\nrepo.update(record, 2)\n</code></pre></p>"},{"location":"classes/repository/#repositoryupdate_whererecord-where_list-list","title":"Repository.update_where(record, where_list: list)","text":"<p>Updates a record matching a list of WHERE clauses defined by where_list.  If more than one clause is present,  they are concatenated with AND.</p> <p>A where clause is a list of tuples in the form of (field, value) or (field, operator, value).  See the example  below for more details. </p> <p>Example: <pre><code>record = Character(name='T-1000')\nrepo.update(record, [('name', 'John Connor')])\n</code></pre></p>"},{"location":"classes/repository/#repositorycount","title":"Repository.count()","text":"<p>Returns the number of records in the table. Equivalent of SELECT COUNT(1) FROM .  <p>Example: <pre><code>record = Character(name='T-1000')\ntotal = repo.count()\n</code></pre></p>"},{"location":"classes/repository/#repositorycount_wherewhere_list-list","title":"Repository.count_where(where_list: list)","text":"<p>Returns the number of records matching a list of WHERE clauses. If more than one clause is present,  they are concatenated with AND.</p> <p>A where clause is a list of tuples in the form of (field, value) or (field, operator, value).  See the example  below for more details. </p> <p>Example: <pre><code>total_johns = repo.count_where([('name', 'like', 'John %'), ])\n</code></pre></p>"},{"location":"classes/repository/#repositorylistqry-select-limitnone-offsetnone-clsnone","title":"Repository.list(qry: Select, limit=None, offset=None, cls=None)","text":"<p>Performs a query qry, with an optional offset and limit, and returns a tuple with the total row count for the query (without offset and limit applied), and a list of rows returned from the execution of the query with offset and limit.</p> <p>If a Record class cls is specified, it will be used instead of the predefined record_type.</p> <p>Note: The original qry object is left intact.</p> <p>Example: <pre><code>total_records, recordset = repo.list(repo.Select(), 10)\n</code></pre></p>"},{"location":"classes/select/","title":"Class rick_db.sql.Select","text":""},{"location":"classes/select/#select__init__dialect-sqldialect-none","title":"Select.__init__(dialect: SqlDialect = None)","text":"<p>Initialize a Select() object, using a database dialect. If no dialect is provided, a default dialect will be used. Check SqlDialect for more details.</p>"},{"location":"classes/select/#selectdistinctflagtrue","title":"Select.distinct(flag=True)","text":"<p>Enables or disables the usage of DISTINCT clause, based on the state of flag. The provided DISTINCT functionality is limited - it doesn't support wildcard or specific columns.</p> <p>Example:</p> <pre><code>sql, _ = Select(PgSqlDialect()).from_('test_table', 'field').distinct().assemble()\n# output: SELECT DISTINCT \"field\" FROM \"test_table\"\nprint(sql)\n</code></pre>"},{"location":"classes/select/#selectexprcolsnone","title":"Select.expr(cols=None)","text":"<p>Adds an anonymous expression to the SELECT statement. It can only be used once in a query. Possible cols values can be:</p> <ul> <li>string with contents</li> <li>a list of strings with contents</li> <li>a Literal object</li> <li>a list of Literal objects</li> </ul> <p>Example:</p> <pre><code>qry, _ = Select(PgSqlDialect()).expr('1').assemble()\n# output: SELECT 1\nprint(qry)\nqry, _ = Select(PgSqlDialect()).expr(['1', '2', '3']).assemble()\n# output: SELECT 1,2,3\nprint(qry)\nqry, _ = Select(PgSqlDialect()).expr({Literal(\"NEXTVAL('some_sequence_name')\"): \"seq_next\"}).assemble()\n# output: SELECT NEXTVAL('some_sequence_name') AS \"seq_next\"\nprint(qry)\n</code></pre>"},{"location":"classes/select/#selectfrom_table-colsnone-schemanone","title":"Select.from_(table, cols=None, schema=None)","text":"<p>Adds a FROM clause to the query. The table is a table identifier expression, cols is a column identifier and schema specifies an optional schema for table.</p> <p>Example:</p> <pre><code>qry, _ = Select(PgSqlDialect()).from_(\"foo\").assemble()\n# output: SELECT \"foo\".* FROM \"foo\"\nprint(qry)\nqry, _ = Select(PgSqlDialect()).from_(\"foo\", None, \"public\").assemble()\n# output: SELECT \"foo\".* FROM \"public\".\"foo\"\nprint(qry)\nqry, _ = Select(PgSqlDialect()).from_({\"foo\": \"bar\"}).assemble()\n# output: SELECT \"bar\".* FROM \"foo\" AS \"bar\"\nprint(qry)\nqry, _ = Select(PgSqlDialect()).from_(\"foo\", {\"field1\": None, \"field2\": \"alias\"}).assemble()\n# output: SELECT \"field1\",\"field2\" AS \"alias\" FROM \"foo\"\nprint(qry)\nqry, _ = Select(PgSqlDialect()).from_(\"foo\", \"field\").assemble()\n# output: SELECT \"field\" FROM \"foo\"\nprint(qry)\nqry, _ = Select(PgSqlDialect()).from_(\"foo\", [\"field1\", \"field2\"]).assemble()\n# output: SELECT \"field1\", \"field2\" FROM \"foo\"\nprint(qry)\nqry, _ = Select(PgSqlDialect()).from_({\"foo\": \"bar\"}, [\"field1\"]).assemble()\n# output: SELECT \"bar.field1\" FROM \"foo\" AS \"bar\"\nprint(qry)\nqry, _ = Select(PgSqlDialect()).from_(record_class_or_object, [\"field1\"]).assemble()\n# output: SELECT \"field1\" FROM \"&lt;object_table_name&gt;\"\nprint(qry)\nqry, _ = Select(PgSqlDialect()).from_({record_class_or_object: \"bar\"}, [\"field1\"]).assemble()\n# output: SELECT \"bar\".\"field1\" FROM \"&lt;object_table_name&gt;\" AS \"bar\"\nprint(qry)\n</code></pre>"},{"location":"classes/select/#table-identifier","title":"Table identifier","text":"<p>A table identifier can be a string, Record class or object, a {'table':'alias'} dict, or a {Record class or object:'alias'} dict.</p>"},{"location":"classes/select/#column-identifier","title":"Column identifier","text":"<p>A column identifier can be None ('*' will be used), a string with a field name, a list of field names, a {'field': 'alias'} dict, a {'field': None, 'other_field':'alias} dict, or a [{'field': 'alias'}, 'field', ] list of mixed string and dict values.</p>"},{"location":"classes/select/#selectlimitlimit-int-offset-int-none","title":"Select.limit(limit: int, offset: int = None)","text":"<p>Adds an LIMIT/OFFSET clause.</p> <p>Example:</p> <pre><code>qry, _ = Select(PgSqlDialect()).from_(\"foo\").limit(10).assemble()\n# output: SELECT \"foo\".* FROM \"foo\" LIMIT 10\nprint(qry)\nqry, _ = Select(PgSqlDialect()).from_(\"foo\").limit(10, 5).assemble()\n# output: SELECT \"foo\".* FROM \"foo\" LIMIT 10 OFFSET 5\nprint(qry)\n</code></pre>"},{"location":"classes/select/#selectpagepage-int-page_rows-int","title":"Select.page(page: int, page_rows: int)","text":"<p>Helper to add LIMIT/OFFSET clause for pagination purposes. page specifies which page to fetch, starting from 1, and page rows specifies the number of rows per page</p> <p>Example:</p> <pre><code>qry, _ = Select(PgSqlDialect()).from_(\"foo\").page(1, 10).assemble()\n# output: SELECT \"foo\".* FROM \"foo\" LIMIT 10 OFFSET 0\nprint(qry)\nqry, _ = Select(PgSqlDialect()).from_(\"foo\").page(10, 10).assemble()\n# output: SELECT \"foo\".* FROM \"foo\" LIMIT 10 OFFSET 10\nprint(qry)\n</code></pre>"},{"location":"classes/select/#selectfor_updateflag-bool-true","title":"Select.for_update(flag: bool = True)","text":"<p>Adds a FOR UPDATE clause if flag is True.</p>"},{"location":"classes/select/#selectorderfields-ordersqlsql_asc","title":"Select.order(fields, order=Sql.SQL_ASC)","text":"<p>Adds an ORDER BY clause with the specified fields. order is ASC by default.</p> <p>Example:</p> <pre><code>qry, _ = Select(PgSqlDialect()).from_(\"foo\").order('id').assemble()\n# output: SELECT \"foo\".* FROM \"foo\" ORDER BY id ASC\nprint(qry)\nqry, _ = Select(PgSqlDialect()).from_(\"foo\").order(['id', 'name'], Select.ORDER_DESC).assemble()\n# output: SELECT \"foo\".* FROM \"foo\" ORDER BY id DESC, a DESC\nprint(qry)\n</code></pre>"},{"location":"classes/select/#selectwherefield-operatornone-valuenone","title":"Select.where(field, operator=None, value=None)","text":"<p>Adds a WHERE clause. Multiple calls to this method are concatenated with AND. field must contain a valid Field identifier, operator can contain either a string with an operator or a Literal object, and finally value, if specified, is the operand.</p> <p>Example:</p> <pre><code># showcase multiple WHERE... AND clauses\nqry = (\nSelect(PgSqlDialect()).from_(\"foo\")\n.where('id', '&gt;', 5)\n.where('name', 'IS NOT NULL')\n.where('cp', 'IN', [100, 200, 300, 400])\n)\n# output: ('SELECT \"foo\".* FROM \"foo\" WHERE (\"id\" &gt; %s) AND (\"name\" IS NOT NULL) AND (\"cp\" IN %s)', [5, [100, 200, 300, 400]])\nprint(qry.assemble())\n</code></pre>"},{"location":"classes/select/#field-identifier","title":"Field identifier","text":"<p>A field identifier can be a string with a field name, a Literal object, a {'table':'field'} dict or {:'field'} dict."},{"location":"classes/select/#selectwhere_and","title":"Select.where_and()","text":"<p>Starts a parenthesis AND block within the WHERE clause, allowing the build of complex WHERE clauses. This method is nestable, allowing the composition of multi-level parenthesis blocks. All declared blocks need to be explicitly closed with where_end().</p> <p>Example:</p> <pre><code># showcase WHERE clause AND ( clause OR clause)\nqry = (\nSelect(PgSqlDialect())\n.from_(\"foo\")\n.where(\"id\", \"&gt;\", 5)\n.where_and()\n.where(\"name\", \"IS NOT NULL\")\n.orwhere(\"cp\", \"IN\", [100, 200, 300, 400])\n.where_end()\n)\n# output: ('SELECT \"foo\".* FROM \"foo\" WHERE (\"id\" &gt; %s) AND ( (\"name\" IS NOT NULL) OR (\"cp\" IN %s) )', [5, [100, 200, 300, 400]])\nprint(qry.assemble())\n</code></pre>"},{"location":"classes/select/#selectwhere_or","title":"Select.where_or()","text":"<p>Starts a parenthesis OR block within the WHERE clause, allowing the build of complex WHERE clauses. This method is nestable, allowing the composition of multi-level parenthesis blocks. All declared blocks need to be explicitly closed with where_end().</p> <p>Example:</p> <pre><code># showcase WHERE clause OR ( clause AND clause)\nqry = ( \nSelect(PgSqlDialect())\n.from_(\"foo\")\n.where('id', '&gt;', 5)\n.where_or()\n.where('name', 'IS NOT NULL')\n.where('cp', 'IN', [100, 200, 300, 400])\n.where_end()\n)\n# output: ('SELECT \"foo\".* FROM \"foo\" WHERE (\"id\" &gt; %s) OR ( (\"name\" IS NOT NULL) AND (\"cp\" IN %s) )', [5, [100, 200, 300, 400]])\nprint(qry.assemble())\n</code></pre>"},{"location":"classes/select/#selectwhere_end","title":"Select.where_end()","text":"<p>Closes a parenthesis AND or OR block. Please note, to allow the most freedom when building queries, Validation of open/closed blocks is only performed on assemble(). If the internal open block counter is not 0 on * assemble(), a RuntimeError* is raised.</p> <p>See where_and() and where_or() for usage examples.</p>"},{"location":"classes/select/#selectorwherefield-operatornone-valuenone","title":"Select.orwhere(field, operator=None, value=None)","text":"<p>Adds a WHERE clause to be concatenated with OR.field must contain a valid Field identifier, operator can contain either a string with an operator or a Literal object, and finally value, if specified, is the operand.</p> <p>Example:</p> <pre><code># showcase multiple WHERE... AND clauses\nqry = (\nSelect(PgSqlDialect())\n.from_(\"foo\")\n.where('id', '&gt;', 5)\n.orwhere('name', 'IS NOT NULL')\n.where('cp', 'IN', [100, 200, 300, 400])\n)\n# output: ('SELECT \"foo\".* FROM \"foo\" WHERE (\"id\" &gt; %s) OR (\"name\" IS NOT NULL) AND (\"cp\" IN %s)', [5, [100, 200, 300, 400]])\nprint(qry.assemble())\n</code></pre>"},{"location":"classes/select/#selectgroupfields","title":"Select.group(fields)","text":"<p>Adds a GROUP BY clause. fields can be either a field name, a list of field names, a Literal or a list of Literal objects.</p> <p>Example:</p> <pre><code>qry, _ = Select(PgSqlDialect()).from_(\"foo\").group(['age', 'name']).assemble()\n# output: SELECT \"foo\".* FROM \"foo\" GROUP BY \"age\", \"name\"\nprint(qry)\n</code></pre>"},{"location":"classes/select/#selecthavingfield-operatornone-valuenone-schemanone","title":"Select.having(field, operator=None, value=None, schema=None)","text":"<p>Adds a HAVING clause. field can be a field name, a Literal, a {'table':'field'} dict or a {Record class or object:'field'} dict.</p> <p>Example:</p> <pre><code># HAVING Literal condition\nqry, _ = Select(PgSqlDialect()).from_(\"foo\").having(Literal('COUNT(field) &gt; 5')).assemble()\n# output: SELECT \"foo\".* FROM \"foo\" HAVING (COUNT(field) &gt; 5)\nprint(qry)\n# HAVING condition\nqry, _ = Select(PgSqlDialect()).from_(\"foo\").having('field', '&gt;', 5, 'public').assemble()\n# output: SELECT \"foo\".* FROM \"foo\" HAVING (\"field\" &gt; %s)\nprint(qry)\n# HAVING with schema\nqry, _ = Select(PgSqlDialect()).from_(\"foo\").having({'some_table': 'field'}, '&gt;', 5, 'public').assemble()\n# output: SELECT \"foo\".* FROM \"foo\" HAVING (\"public\".\"some_table\".\"field\" &gt; %s)\nprint(qry)\n</code></pre>"},{"location":"classes/select/#selectunionqueries-list-union_type-str-sqlsql_union","title":"Select.union(queries: list, union_type: str = Sql.SQL_UNION)","text":"<p>Performs an UNION of two or more Select() or string queries. union_type can be either Sql.SQL_UNION or * Sql.SQL_UNION_ALL*.</p> <p>Example:</p> <pre><code>qry, _ = Select(PgSqlDialect()).union([\nSelect().from_('table'),\nSelect().from_('other_table')\n]).assemble()\n# output: SELECT \"table\".* FROM \"table\" UNION SELECT \"other_table\".* FROM \"other_table\"\nprint(qry)\n</code></pre>"},{"location":"classes/select/#selectjointable-field-expr_tablenone-expr_fieldnone-operatornone-colsnone-schemanone","title":"Select.**join(table, field, expr_table=None, expr_field=None, operator=None, cols=None, schema=None,","text":"<p>expr_schema=None)**</p> <p>Adds a INNER JOIN clause. The parameters must conform with join() parameters.</p> <p>Example:</p> <pre><code># simple example\nqry, _ = (\nSelect(PgSqlDialect())\n.from_('some_table')\n.join('other_table', 'fk_some_table', 'some_table', 'id')\n.assemble()\n)\n# output: SELECT \"some_table\".* FROM \"some_table\" INNER JOIN \"other_table\" ON \"some_table\".\"id\"=\"other_table\".\"fk_some_table\"\nprint(qry)\n# example w/ destination table aliasing\nqry, _ = (\nSelect(PgSqlDialect())\n.from_('some_table')\n.join({'other_table': 't2'}, 'fk_some_table', 'some_table', 'id')\n.assemble()\n)\n# output: SELECT \"some_table\".* FROM \"some_table\" INNER JOIN \"other_table\" AS \"t2\" ON \"some_table\".\"id\"=\"t2\".\"fk_some_table\"\nprint(qry)\n# example w/ source table aliasing\nqry, _ = (\nSelect(PgSqlDialect())\n.from_({'some_table': 't1'})\n.join({'other_table': 't2'}, 'fk_some_table', {'some_table': 't1'}, 'id')\n.assemble()\n)\n# output: SELECT \"t1\".* FROM \"some_table\" AS \"t1\" INNER JOIN \"other_table\" AS \"t2\" ON \"t1\".\"id\"=\"t2\".\"fk_some_table\"\nprint(qry)\n# example w/ Record objects and extra SELECT column w/alias\nqry, _ = (\nSelect(PgSqlDialect())\n.from_(Book)\n.join(Publisher, Publisher.id, Book, Book.fk_publisher, '=', [{Publisher.name: 'publisher_name'}])\n.assemble()\n)\n# output: SELECT \"book\".*,\"publisher\".\"name\" AS \"publisher_name\" FROM \"book\" INNER JOIN \"publisher\" ON \"book\".\"fk_publisher\"=\"publisher\".\"id_publisher\"\nprint(qry)\n</code></pre>"},{"location":"classes/select/#join-parameters","title":"join() parameters","text":"<p>table identifies the table to JOIN to, and must be a valid Table identifier expression.</p> <p>field is the field name or expression to join on table.</p> <p>expr_table identifies the existing table to JOIN from, and must be a valid Table identifier.</p> <p>expr_field is the field name or expression to JOIN on the existing table.</p> <p>operator is an optional join operator - if omitted, '=' is used.</p> <p>cols is an optional list of column names to add to the SELECT statement.</p> <p>schema and expr_schema can provide optional schema naming for both table to JOIN to and table to JOIN from.</p>"},{"location":"classes/select/#selectjoin_innertable-field-expr_tablenone-expr_fieldnone-operatornone-colsnone-schemanone","title":"Select.**join_inner(table, field, expr_table=None, expr_field=None, operator=None, cols=None, schema=None,","text":"<p>expr_schema=None)**</p> <p>Alias to join() .</p>"},{"location":"classes/select/#selectjoin_lefttable-field-expr_tablenone-expr_fieldnone-operatornone-colsnone-schemanone","title":"Select.**join_left(table, field, expr_table=None, expr_field=None, operator=None, cols=None, schema=None,","text":"<p>expr_schema=None)**</p> <p>Adds a LEFT JOIN clause. The parameters must conform with join() parameters.</p> <p>Example:</p> <pre><code># simple example\nqry, _ = (\nSelect(PgSqlDialect())\n.from_(\"some_table\")\n.join_left(\"other_table\", \"fk_some_table\", \"some_table\", \"id\")\n.assemble()\n)\n# output: SELECT \"some_table\".* FROM \"some_table\" LEFT JOIN \"other_table\" ON \"some_table\".\"id\"=\"other_table\".\"fk_some_table\"\nprint(qry)\n# example w/ destination table aliasing\nqry, _ = (\nSelect(PgSqlDialect())\n.from_(\"some_table\")\n.join_left({\"other_table\": \"t2\"}, \"fk_some_table\", \"some_table\", \"id\")\n.assemble()\n)\n# output: SELECT \"some_table\".* FROM \"some_table\" LEFT JOIN \"other_table\" AS \"t2\" ON \"some_table\".\"id\"=\"t2\".\"fk_some_table\"\nprint(qry)\n# example w/ source table aliasing\nqry, _ = (\nSelect(PgSqlDialect())\n.from_({\"some_table\": \"t1\"})\n.join_left({\"other_table\": \"t2\"}, \"fk_some_table\", {\"some_table\": \"t1\"}, \"id\")\n.assemble()\n)\n# output: SELECT \"t1\".* FROM \"some_table\" AS \"t1\" LEFT JOIN \"other_table\" AS \"t2\" ON \"t1\".\"id\"=\"t2\".\"fk_some_table\"\nprint(qry)\n</code></pre>"},{"location":"classes/select/#selectjoin_righttable-field-expr_tablenone-expr_fieldnone-operatornone-colsnone-schemanone","title":"Select.**join_right(table, field, expr_table=None, expr_field=None, operator=None, cols=None, schema=None,","text":"<p>expr_schema=None)**</p> <p>Adds a RIGHT JOIN clause. The parameters must conform with join() parameters.</p> <p>Example:</p> <pre><code># simple example\nqry, _ = (\nSelect(PgSqlDialect())\n.from_(\"some_table\")\n.join_right(\"other_table\", \"fk_some_table\", \"some_table\", \"id\")\n.assemble()\n)\n# output: SELECT \"some_table\".* FROM \"some_table\" RIGHT JOIN \"other_table\" ON \"some_table\".\"id\"=\"other_table\".\"fk_some_table\"\nprint(qry)\n# example w/ destination table aliasing\nqry, _ = (\nSelect(PgSqlDialect())\n.from_(\"some_table\")\n.join_right({\"other_table\": \"t2\"}, \"fk_some_table\", \"some_table\", \"id\")\n.assemble()\n)\n# output: SELECT \"some_table\".* FROM \"some_table\" RIGHT JOIN \"other_table\" AS \"t2\" ON \"some_table\".\"id\"=\"t2\".\"fk_some_table\"\nprint(qry)\n# example w/ source table aliasing\nqry, _ = (\nSelect(PgSqlDialect())\n.from_({\"some_table\": \"t1\"})\n.join_right({\"other_table\": \"t2\"}, \"fk_some_table\", {\"some_table\": \"t1\"}, \"id\")\n.assemble()\n)\n# output: SELECT \"t1\".* FROM \"some_table\" AS \"t1\" RIGHT JOIN \"other_table\" AS \"t2\" ON \"t1\".\"id\"=\"t2\".\"fk_some_table\"\nprint(qry)\n# example w/ Record objects and extra SELECT column w/alias\nqry, _ = (\nSelect(PgSqlDialect())\n.from_(Book)\n.join_right(\nPublisher,\nPublisher.id,\nBook,\nBook.fk_publisher,\n\"=\",\n[{Publisher.name: \"publisher_name\"}],\n)\n.assemble()\n)\n# output: SELECT \"book\".*,\"publisher\".\"name\" AS \"publisher_name\" FROM \"book\" RIGHT JOIN \"publisher\" ON \"book\".\"fk_publisher\"=\"publisher\".\"id_publisher\"\nprint(qry)\n# example w/ Record objects and extra SELECT column w/alias\nqry, _ = (\nSelect(PgSqlDialect())\n.from_(Book)\n.join_left(\nPublisher,\nPublisher.id,\nBook,\nBook.fk_publisher,\n\"=\",\n[{Publisher.name: \"publisher_name\"}],\n)\n.assemble()\n)\n# output: SELECT \"book\".*,\"publisher\".\"name\" AS \"publisher_name\" FROM \"book\" LEFT JOIN \"publisher\" ON \"book\".\"fk_publisher\"=\"publisher\".\"id_publisher\"\nprint(qry)\n</code></pre>"},{"location":"classes/select/#selectjoin_fulltable-field-expr_tablenone-expr_fieldnone-operatornone-colsnone-schemanone","title":"Select.**join_full(table, field, expr_table=None, expr_field=None, operator=None, cols=None, schema=None,","text":"<p>expr_schema=None)**</p> <p>Adds a FULL OUTER JOIN clause. The parameters must conform with join() parameters.</p> <p>Example:</p> <pre><code># simple example\nqry, _ = (\nSelect(PgSqlDialect())\n.from_(\"some_table\")\n.join_full(\"other_table\", \"fk_some_table\", \"some_table\", \"id\")\n.assemble()\n)\n# output: SELECT \"some_table\".* FROM \"some_table\" FULL JOIN \"other_table\" ON \"some_table\".\"id\"=\"other_table\".\"fk_some_table\"\nprint(qry)\n# example w/ destination table aliasing\nqry, _ = (\nSelect(PgSqlDialect())\n.from_(\"some_table\")\n.join_full({\"other_table\": \"t2\"}, \"fk_some_table\", \"some_table\", \"id\")\n.assemble()\n)\n# output: SELECT \"some_table\".* FROM \"some_table\" FULL JOIN \"other_table\" AS \"t2\" ON \"some_table\".\"id\"=\"t2\".\"fk_some_table\"\nprint(qry)\n# example w/ source table aliasing\nqry, _ = (\nSelect(PgSqlDialect())\n.from_({\"some_table\": \"t1\"})\n.join_full({\"other_table\": \"t2\"}, \"fk_some_table\", {\"some_table\": \"t1\"}, \"id\")\n.assemble()\n)\n# output: SELECT \"t1\".* FROM \"some_table\" AS \"t1\" FULL JOIN \"other_table\" AS \"t2\" ON \"t1\".\"id\"=\"t2\".\"fk_some_table\"\nprint(qry)\n# example w/ Record objects and extra SELECT column w/alias\nqry, _ = (\nSelect(PgSqlDialect())\n.from_(Book)\n.join_full(\nPublisher,\nPublisher.id,\nBook,\nBook.fk_publisher,\n\"=\",\n[{Publisher.name: \"publisher_name\"}],\n)\n.assemble()\n)\n# output: SELECT \"book\".*,\"publisher\".\"name\" AS \"publisher_name\" FROM \"book\" FULL JOIN \"publisher\" ON \"book\".\"fk_publisher\"=\"publisher\".\"id_publisher\"\nprint(qry)\n</code></pre>"},{"location":"classes/select/#selectjoin_crosstable-colsnone-schemanone","title":"Select.join_cross(table, cols=None, schema=None)","text":"<p>Adds a CROSS JOIN clause. table identifies the table to CROSS JOIN with, and must be a valid Table identifier expression. cols a list of field names to be SELECTed from the joined table. schema is the optional schema name for the joined table.</p> <p>Example:</p> <pre><code># simple example\nqry, _ = Select(PgSqlDialect()).from_(\"table1\").join_cross(\"table2\").assemble()\n# output: SELECT \"table1\".* FROM \"table1\" CROSS JOIN \"table2\"\nprint(qry)\n# example w/ destination table aliasing\nqry, _ = Select(PgSqlDialect()).from_(\"table1\").join_cross({\"table2\": \"t2\"}).assemble()\n# output: SELECT \"table1\".* FROM \"table1\" CROSS JOIN \"table2\" AS \"t2\"\nprint(qry)\n# example w/ destination table aliasing and extra SELECT columns\nqry, _ = (\nSelect(PgSqlDialect())\n.from_(\"table1\")\n.join_cross({\"table2\": \"t2\"}, [{\"id\": \"t2_id\"}, \"name\"])\n.assemble()\n)\n# output: SELECT \"table1\".*,\"t2\".\"id\" AS \"t2_id\",\"t2\".\"name\" FROM \"table1\" CROSS JOIN \"table2\" AS \"t2\"\nprint(qry)\n# example w/ Record objects and extra SELECT columns\nqry, _ = (\nSelect(PgSqlDialect())\n.from_(Book)\n.join_cross(Publisher, [Publisher.id, Publisher.name])\n.assemble()\n)\n# output: SELECT \"book\".*,\"publisher\".\"id_publisher\",\"publisher\".\"name\" FROM \"book\" CROSS JOIN \"publisher\"\nprint(qry)\n</code></pre>"},{"location":"classes/select/#selectjoin_naturaltable-colsnone-schemanone","title":"Select.join_natural(table, cols=None, schema=None)","text":"<p>Adds a CROSS JOIN clause. table identifies the table to CROSS JOIN with, and must be a valid Table identifier expression. cols a list of field names to be SELECTed from the joined table. schema is the optional schema name for the joined table.</p> <p>Example:</p> <pre><code># simple example\nqry, _ = Select(PgSqlDialect()).from_(\"table1\").join_natural(\"table2\").assemble()\n# output: SELECT \"table1\".* FROM \"table1\" NATURAL JOIN \"table2\"\nprint(qry)\n# example w/ destination table aliasing\nqry, _ = (\nSelect(PgSqlDialect()).from_(\"table1\").join_natural({\"table2\": \"t2\"}).assemble()\n)\n# output: SELECT \"table1\".* FROM \"table1\" NATURAL JOIN \"table2\" AS \"t2\"\nprint(qry)\n# example w/ destination table aliasing and extra SELECT columns\nqry, _ = (\nSelect(PgSqlDialect())\n.from_(\"table1\")\n.join_natural({\"table2\": \"t2\"}, [{\"id\": \"t2_id\"}, \"name\"])\n.assemble()\n)\n# output: SELECT \"table1\".*,\"t2\".\"id\" AS \"t2_id\",\"t2\".\"name\" FROM \"table1\" NATURAL JOIN \"table2\" AS \"t2\"\nprint(qry)\n# example w/ Record objects and extra SELECT columns\nqry, _ = (\nSelect(PgSqlDialect())\n.from_(Book)\n.join_natural(Publisher, [Publisher.id, Publisher.name])\n.assemble()\n)\n# output: SELECT \"book\".*,\"publisher\".\"id_publisher\",\"publisher\".\"name\" FROM \"book\" NATURAL JOIN \"publisher\"\nprint(qry)\n</code></pre>"},{"location":"classes/select/#selectassemble","title":"Select.assemble()","text":"<p>Assembles and returns the SQL query string and list of values. Returns a tuple with (sql_query, list_of_values) . If no values are present, an empty list is returned instead. It will raise RuntimeError on existing errors.</p> <p>Example:</p> <pre><code>qry, _ = Select(PgSqlDialect()).expr([1]).assemble()\n# output: SELECT 1\nprint(qry)\n</code></pre>"},{"location":"classes/select/#selectdialect","title":"Select.dialect()","text":"<p>Return the current SqlDialect object in use.</p>"},{"location":"classes/select/#selectlateralsubquery-sqlstatement-alias-str-colsnone","title":"Select.lateral(subquery: SqlStatement, alias: str, cols=None)","text":"<p>Adds a LATERAL subquery: subquery is the query object to add, alias is the alias for the subquery, and optionally it is possible to specify specific columns using cols. If cols is omitted, '*' is used instead.</p> <p>Example:</p> <pre><code>@fieldmapper(tablename=\"t_product\")\nclass ProductRecord:\nid = \"product_id\"\nprice = \"price\"\nproduct = \"product\"\n@fieldmapper(tablename=\"t_wishlist\")\nclass WishListRecord:\nid = \"wishlist_id\"\nusername = \"username\"\ndesired_price = \"desired_price\"\nqry = (\nSelect()\n.from_({WishListRecord: \"w\"})\n.lateral(\nSelect()\n.from_({ProductRecord: \"p\"})\n.where(Literal(ProductRecord.price + \"&lt;\" + WishListRecord.desired_price))\n.order(ProductRecord.price, Sql.SQL_DESC)\n.limit(3),\n\"x\",\n)\n.order([WishListRecord.id, ProductRecord.price], Sql.SQL_DESC)\n)\n# output: \n# SELECT \"w\".*,\"x\".* FROM \"t_wishlist\" AS \"w\", LATERAL (\n#   SELECT \"p\".* FROM \"t_product\" AS \"p\" WHERE (price&lt;desired_price) ORDER BY \"price\" DESC LIMIT 3\n# ) AS \"x\" ORDER BY \"wishlist_id\" DESC,\"price\" DESC\nprint(qry.assemble())\n</code></pre>"},{"location":"classes/select/#selectjoin_inner_lateralsubquery-unionsqlstatement-literal-alias-str-join_expr-literal","title":"Select.join_inner_lateral(subquery: Union[SqlStatement, Literal], alias: str, join_expr: Literal)","text":"<p>Performs a JOIN INNER LATERAL with a subquery.subquery is the query object to add, alias is the alias for the subquery, and join_expr is the ON literal expression.</p> <pre><code>@fieldmapper(tablename=\"product\")\nclass ProductRecord:\nid = \"product_id\"\nprice = \"price\"\nproduct = \"product\"\n@fieldmapper(tablename=\"wishlist\")\nclass WishListRecord:\nid = \"wishlist_id\"\nusername = \"username\"\ndesired_price = \"desired_price\"\nqry = (\nSelect()\n.from_({WishListRecord: \"w\"})\n.join_inner_lateral(\nSelect()\n.from_({ProductRecord: \"p\"})\n.where(Literal(ProductRecord.price + \"&lt;\" + WishListRecord.desired_price))\n.order(ProductRecord.price, Sql.SQL_DESC)\n.limit(3),\n\"x\",\nLiteral(\"true\"),\n)\n.order([WishListRecord.id, ProductRecord.price], Sql.SQL_DESC)\n)\n# output:\n# SELECT \"w\".* FROM \"wishlist\" AS \"w\" \n#   INNER JOIN LATERAL (\n#     SELECT \"p\".* FROM \"product\" AS \"p\" WHERE (price&lt;desired_price) ORDER BY \"price\" DESC LIMIT 3\n#   ) AS \"x\" ON (true)\n# ORDER BY \"wishlist_id\" DESC,\"price\" DESC\nprint(qry.assemble())\n</code></pre>"},{"location":"classes/select/#selectjoin_left_lateralsubquery-unionsqlstatement-literal-alias-str-join_expr-literal","title":"Select.join_left_lateral(subquery: Union[SqlStatement, Literal], alias: str, join_expr: Literal)","text":"<p>Performs a JOIN LEFT LATERAL with a subquery.subquery is the query object to add, alias is the alias for the subquery, and join_expr is the ON literal expression.</p> <pre><code>@fieldmapper(tablename=\"product\")\nclass ProductRecord:\nid = \"product_id\"\nprice = \"price\"\nproduct = \"product\"\n@fieldmapper(tablename=\"wishlist\")\nclass WishListRecord:\nid = \"wishlist_id\"\nusername = \"username\"\ndesired_price = \"desired_price\"\nqry = (\nSelect()\n.from_({WishListRecord: \"w\"})\n.join_left_lateral(\nSelect()\n.from_({ProductRecord: \"p\"})\n.where(Literal(ProductRecord.price + \"&lt;\" + WishListRecord.desired_price))\n.order(ProductRecord.price, Sql.SQL_DESC)\n.limit(3),\n\"x\",\nLiteral(\"true\"),\n)\n.order([WishListRecord.id, ProductRecord.price], Sql.SQL_DESC)\n)\n# output:\n# SELECT \"w\".* FROM \"wishlist\" AS \"w\" \n#   LEFT JOIN LATERAL (\n#     SELECT \"p\".* FROM \"product\" AS \"p\" WHERE (price&lt;desired_price) ORDER BY \"price\" DESC LIMIT 3\n#   ) AS \"x\" ON (true)\n# ORDER BY \"wishlist_id\" DESC,\"price\" DESC\nprint(qry.assemble())\n</code></pre>"},{"location":"classes/sqldialect/","title":"Class rick_db.sql.SqlDialect","text":"<p>Base Dialect Class. Implements schema, table and field quoting specifics to be used primarily within the query builder.</p>"},{"location":"classes/sqldialect/#sqldialecttabletable_name-aliasnone-schemanone","title":"SqlDialect.table(table_name, alias=None, schema=None)","text":"<p>Quotes a table name, with an optional alias and schema.</p> <p>Example: <pre><code># get dialect from a PgConnection() object\ndialect = conn.dialect()\n# output: \"tbl\"\nprint(dialect.table('tbl', None, None)) \n# output: \"schema\".\"tbl\" AS \"alias\"   \nprint(dialect.table('tbl', 'alias', 'schema'))\n</code></pre></p>"},{"location":"classes/sqldialect/#sqldialectfieldfield-field_aliasnone-tablenone-schemanone","title":"SqlDialect.field(field, field_alias=None, table=None, schema=None)","text":"<p>Quotes a field name, with an optional field_alias, table and schema. If field_alias is a list or tuple, a CAST() is performed instead, using the first item as type. If the list or tuple contains 2 items, the first one is used as type, and the second one as alias.</p> <p>Example: <pre><code># get dialect from a PgConnection() object\ndialect = conn.dialect()\n# output: \"field\"\nprint(dialect.field('field', None))\n# output: \"field\" AS \"alias\"\nprint(dialect.field('field', 'alias')) \n# output: CAST(\"field\" AS text)\nprint(dialect.field('field', ['text']))\n# output: CAST(\"field\" AS text) AS \"alias\"\nprint(dialect.field('field', ['text', 'alias']))\n# output: CAST(COUNT(*) AS int) AS \"total\"\nprint(dialect.field(Literal('COUNT(*)'), ['int', 'total'])) \n# output: \"table\".\"field\" AS \"alias\"\nprint(dialect.field('field', 'alias', 'table'))\n# output: \"public\".\"table\".\"field\" AS \"alias\"\nprint(dialect.field('field', 'alias', 'table', 'public')) \n</code></pre></p>"},{"location":"classes/update/","title":"Class rick_db.sql.Update","text":""},{"location":"classes/update/#update__init__dialect-sqldialect-none","title":"Update.__init__(dialect: SqlDialect = None)","text":"<p>Initialize a Update() object, using a database dialect. If no dialect is provided, a default dialect will be used. Check SqlDialect for more details.</p>"},{"location":"classes/update/#updatetabletable-schemanone","title":"Update.table(table, schema=None)","text":"<p>Defines the target table name and schema for update. If table is a Record object, it will also load fields and values from this object.</p> <p>Example: <pre><code># simple UPDATE example\nqry = Update(PgSqlDialect()).table('table').fields(['field']).values(['value'])\n# output: ('UPDATE \"table\" SET \"field\"=%s', ['value'])\nprint(qry.assemble())\n# UPDATE w/ Record object\nrecord = Publisher(name='some publisher name')\nqry = Update(PgSqlDialect()).table(record)\n# output: ('UPDATE \"publisher\" SET \"name\"=%s', ['some publisher name'])\nprint(qry.assemble())\n</code></pre></p>"},{"location":"classes/update/#updatefieldsfields-list","title":"Update.fields(fields: list)","text":"<p>Defines the field names to be updated. The length of fields list must match the list of provided values.</p> <p>Example: <pre><code>data = [\n['john', 'connor'],\n['sarah', 'connor']\n]\nsql = []\nqry = Update(PgSqlDialect()).table('table').fields(['name', 'surname'])\nfor v in data:\nqry.values(v)\nsql.append(qry.assemble())\n# output:\n# [('UPDATE \"table\" SET \"name\"=%s, \"surname\"=%s', ['john', 'connor']), \n# ('UPDATE \"table\" SET \"name\"=%s, \"surname\"=%s', ['sarah', 'connor'])]\nprint(sql)\n</code></pre></p>"},{"location":"classes/update/#updatevaluesvalues-unionlist-dict-object","title":"Update.values(values: Union[list, dict, object])","text":"<p>Define values of fields to be updated. This method can be called multiple times (see fields() for an example). If values is a dict, both fields and values are read from the provided dict. If values is a Record object, fields and values are read from the object.</p> <p>Example: <pre><code># simple UPDATE example\nqry = Update(PgSqlDialect()).table('table').fields(['field']).values(['value'])\n# output: ('UPDATE \"table\" SET \"field\"=%s', ['value'])\nprint(qry.assemble())\n# INSERT w/ Record object\nrecord = Publisher(name='some publisher name')\nqry = Update(PgSqlDialect()).table('tablename').values(record)\n# output: ('UPDATE \"tablename\" SET \"name\"=%s', ['some publisher name'])\nprint(qry.assemble())\n</code></pre></p>"},{"location":"classes/update/#updatewherefield-operatornone-valuenone","title":"Update.where(field, operator=None, value=None)","text":"<p>Adds a WHERE clause to the UPDATE clause. It requires a mandatory field name and an operator, and allows an optional value. Clauses generated by multiple calls to this method are concatenated with AND. </p> <p>Example:</p> <pre><code># UPDATE WHERE... common usage\nqry = (\nUpdate(PgSqlDialect()).table(\"table\").values({\"field\": \"value\"}).where(\"id\", \"=\", 7)\n)\n# output: ('UPDATE \"table\" SET \"field\"=%s WHERE \"id\" = %s', ['value', 7])\nprint(qry.assemble())\n# UPDATE WHERE... no value\nqry = (\nUpdate(PgSqlDialect())\n.table(\"table\")\n.values({\"field\": \"value\"})\n.where(\"id\", \"IS NOT NULL\")\n)\n# output: ('UPDATE \"table\" SET \"field\"=%s WHERE \"id\" IS NOT NULL', ['value'])\nprint(qry.assemble())\n# UPDATE WHERE... with multiple clauses\nqry = (\nUpdate(PgSqlDialect())\n.table(\"table\")\n.values({\"field\": \"value\"})\n.where(\"id\", \"=\", 7)\n.where(\"name\", \"ILIKE\", \"john%\")\n)\n# output: ('UPDATE \"table\" SET \"field\"=%s WHERE \"id\" = %s AND \"name\" ILIKE %s', ['value', 7, 'john%'])\nprint(qry.assemble())\n</code></pre>"},{"location":"classes/update/#updateorwherefield-operatornone-valuenone","title":"Update.orwhere(field, operator=None, value=None)","text":"<p>Adds a WHERE clause to the UPDATE clause. It requires a mandatory field name and an operator, and allows an optional value. Clauses generated by multiple calls to this method are concatenated with OR. </p> <p>Example:</p> <pre><code>qry = (\nUpdate(PgSqlDialect())\n.table(\"table\")\n.values({\"field\": \"value\"})\n.where(\"id\", \"=\", 7)\n.orwhere(\"name\", \"ILIKE\", \"john%\")\n)\n# output: ('UPDATE \"table\" SET \"field\"=%s WHERE \"id\" = %s OR \"name\" ILIKE %s', ['value', 7, 'john%'])\nprint(qry.assemble())\n</code></pre>"},{"location":"classes/update/#updatereturningfields-unionlist-str-sqlsql_all","title":"Update.returning(fields: Union[list, str] = Sql.SQL_ALL)","text":"<p>Adds a RETURNING clause to the UPDATE clause with a list of field names. If fields is empty, '*' is used.  Example:</p> <pre><code>qry = (\nUpdate(PgSqlDialect())\n.table(\"table\")\n.values({\"field\": \"value\"})\n.where(\"id\", \"=\", 7)\n.orwhere(\"name\", \"ILIKE\", \"john%\")\n.returning()\n)\n# output: ('UPDATE \"table\" SET \"field\"=%s WHERE \"id\" = %s OR \"name\" ILIKE %s RETURNING *', ['value', 7, 'john%'])\nprint(qry.assemble())\n</code></pre>"},{"location":"classes/update/#updateassemble","title":"Update.assemble()","text":"<p>Assembles UPDATE SQL string and returns a tuple with (sql_string, list_of_values). If an error occurs, SqlError is raised.</p> <p>Example:</p> <pre><code># simple UPDATE example\nqry = Update(PgSqlDialect()).table('table').fields(['field']).values(['value'])\n# output: ('UPDATE \"table\" SET \"field\"=%s', ['value'])\nprint(qry.assemble())\n</code></pre>"},{"location":"classes/with/","title":"Class rick_db.sql.With","text":"<p>A wrapper for ordinary or recursive Common Table Expressions (CTE).</p>"},{"location":"classes/with/#with__init__dialect-sqldialect-none","title":"With.__init__(dialect: SqlDialect = None)","text":"<p>Initialize the CTE wrapper object, using a database dialect. If no dialect is provided, a default dialect will be used. Check SqlDialect for more details.</p>"},{"location":"classes/with/#withrecursivestatustrue","title":"With.recursive(status=True)","text":"<p>Creates a recursive CTE if status is True, or an ordinary CTE if status is False</p> <p>Example:</p> <pre><code>union = Select().union([\nLiteral(\"VALUES(1)\"),\nSelect().from_(\"t\", cols=[Literal(\"n+1\")]).where(\"n\", \"&lt;\", 100)\n], Sql.UNION_ALL)\n# assemble a recursive CTE\nwith_qry = With()\n.clause(\"t\", union)\n.query(Select().from_(\"t\", cols={Literal(\"SUM(n)\"): \"total\"}))\n.recursive()\nsql, values = with_qry.assemble()\n# sql: WITH RECURSIVE \"t\"(\"n\") AS (VALUES(1) UNION SELECT n+1 FROM \"t\" WHERE (\"n\" &lt; %s)) SELECT SUM(n) AS \"total\" FROM \"t\"\n# values: [100]\n</code></pre>"},{"location":"classes/with/#withclausename-str-with_query-unionsqlstatement-literal-columns-list-none-materialized-bool","title":"With.**clause(name: str, with_query: Union[SqlStatement, Literal], columns: list = None, materialized: bool =","text":"<p>True)**</p> <p>Adds a CTE expression with the format WITH name(columns) AS (with_query); The columns parameter is optional. If materialized is False, WITH...NOT MATERIALIZED AS () is generated instead.</p>"},{"location":"classes/with/#withqueryquery-sqlstatement","title":"With.query(query: SqlStatement)","text":"<p>Specifies the final CTE query to be applied on the expressions.</p>"},{"location":"classes/with/#withassemble","title":"With.assemble()","text":"<p>Generates a tuple with the generated SQL string and list of values.</p>"}]}